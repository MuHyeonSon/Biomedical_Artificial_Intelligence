{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ONb-qbF5mJhv"
      },
      "source": [
        "Name : 손무현\n",
        "Student ID : **2018----**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mHAbZTalnYl"
      },
      "source": [
        "2. Preliminaries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuyvj1Jdnn-R"
      },
      "source": [
        "  2.1.Data Manipulation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2gmkOwl2qoJ"
      },
      "source": [
        "2.1.1.Getting started"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "inmAxqYhqSAl"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWxY-_r-qy4-",
        "outputId": "fa1331f0-fe4b-405b-c8f3-d64af7273cc7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "execution_count": 9,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.arange(10)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSYQw20Et3tK",
        "outputId": "a31a2f43-8fbc-40ce-a4bf-2d70796526ab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([10])"
            ]
          },
          "execution_count": 10,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVZ1ML0Nugo0",
        "outputId": "9d31080a-8fc1-4967-cf4b-f810ecbcf545"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "execution_count": 11,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.numel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDdYeMP-uocs",
        "outputId": "80991afb-1ca9-4a16-d66b-26b43c1d1b34"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0, 1, 2, 3, 4],\n",
              "        [5, 6, 7, 8, 9]])"
            ]
          },
          "execution_count": 22,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X = x.reshape(-1,5)\n",
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijPjHLGXwrg1",
        "outputId": "ad5dc638-d758-424c-af81-7c4d6f8e4009"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0.]]])"
            ]
          },
          "execution_count": 25,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.zeros(2,5,6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WFcCpFHxDNV",
        "outputId": "e4681edf-7847-4bf1-914c-5dec21ae8399"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.]],\n",
              "\n",
              "        [[1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.]],\n",
              "\n",
              "        [[1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.]]])"
            ]
          },
          "execution_count": 26,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.ones(3,4,4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihmPXM7V0ABA",
        "outputId": "98db580c-569c-412a-a1dc-eac3ceffc0a6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-0.5448, -0.9864, -2.4299],\n",
              "        [-0.2892, -0.9388, -0.9634],\n",
              "        [ 0.5472,  0.6119,  0.8954]])"
            ]
          },
          "execution_count": 28,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.randn(3,3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VA8tC7Kr1llK",
        "outputId": "4067a746-7aa2-4cc5-94e9-4b6b376bd6a1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[    1,    45,    23],\n",
              "        [   34,    12,    56],\n",
              "        [  123,   532, 54364],\n",
              "        [  123,   433,   523]])"
            ]
          },
          "execution_count": 34,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.tensor([[1,45,23],[34,12,56],[123,532,54364],[123,433,523]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOKOUhMC2VaU"
      },
      "source": [
        "2.1.2 Operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5U2El4Yn60HW",
        "outputId": "d46d03a6-935b-4eb7-ccd9-12a3505241e7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([4., 3., 5., 7.]),\n",
              " tensor([ 0., -1.,  1.,  3.]),\n",
              " tensor([ 4.,  2.,  6., 10.]),\n",
              " tensor([1.0000, 0.5000, 1.5000, 2.5000]),\n",
              " tensor([ 4.,  1.,  9., 25.]),\n",
              " tensor([0., 1., 1., 1.]))"
            ]
          },
          "execution_count": 43,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.tensor([2.0,1,3,5])\n",
        "y = torch.tensor([2,2,2,2])\n",
        "x+y,x-y,x*y,x/y,x**y,x%y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjA4CRER9p-P",
        "outputId": "9bdf964d-7237-4b65-e0de-0b1d66a24a1a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([  7.3891,   2.7183,  20.0855, 148.4132])"
            ]
          },
          "execution_count": 44,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.exp(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uu-Mu1UCDq-H",
        "outputId": "5a2fc2c1-9dbe-4662-8a5a-d635342f20a0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[ 0.,  1.,  2.,  3.],\n",
              "         [ 4.,  5.,  6.,  7.],\n",
              "         [ 8.,  9., 10., 11.],\n",
              "         [ 2.,  1.,  4.,  3.],\n",
              "         [ 1.,  1.,  1.,  1.],\n",
              "         [ 6.,  7.,  5.,  3.]]),\n",
              " tensor([[ 0.,  1.,  2.,  3.,  2.,  1.,  4.,  3.],\n",
              "         [ 4.,  5.,  6.,  7.,  1.,  1.,  1.,  1.],\n",
              "         [ 8.,  9., 10., 11.,  6.,  7.,  5.,  3.]]))"
            ]
          },
          "execution_count": 46,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X = torch.arange(12, dtype=torch.float32).reshape((3,4))\n",
        "Y = torch.tensor([[2.0,1,4,3],[1,1,1,1],[6,7,5,3]])\n",
        "torch.cat((X,Y),dim=0), torch.cat((X,Y),dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0TlXHVdEykz",
        "outputId": "f79e40ed-f640-4422-9d4e-5c100a2f139a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[False,  True, False,  True],\n",
              "        [False, False, False, False],\n",
              "        [False, False, False, False]])"
            ]
          },
          "execution_count": 47,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X == Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ly1JcobeIfkL",
        "outputId": "fb366351-4ec4-4c77-9091-77889d62a34c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(66.)"
            ]
          },
          "execution_count": 48,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3_OJ7MnJSjq"
      },
      "source": [
        "2.1.3.Broadcasting Mechanism"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0iHG_lOjKP_I",
        "outputId": "22740ce0-1730-4fc9-848d-49f9ad191483"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[0, 1, 2],\n",
              "         [3, 4, 5]]), tensor([[0, 1, 2]]))"
            ]
          },
          "execution_count": 87,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = torch.arange(6).reshape((2,3))\n",
        "b = torch.arange(3).reshape((1,3))\n",
        "a,b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsAmJnK0LMoA",
        "outputId": "b25aef8b-5acb-4215-d0a6-561f70ab3b13"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0, 2, 4],\n",
              "        [3, 5, 7]])"
            ]
          },
          "execution_count": 88,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a + b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYhExDPzd7pP"
      },
      "source": [
        "2.1.4.Indexing and Slicing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyLLz6fheqgj",
        "outputId": "26b24444-27fd-4d40-b817-e5bfaad77bd5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([4., 5., 6., 7.]), tensor([[ 0.,  1.,  2.,  3.],\n",
              "         [ 4.,  5.,  6.,  7.],\n",
              "         [ 8.,  9., 10., 11.]]), tensor([[ 8.,  9., 10., 11.]]), tensor([[0., 1., 2., 3.],\n",
              "         [4., 5., 6., 7.]]))"
            ]
          },
          "execution_count": 96,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X[-2],X[0:],X[-1:],X[0:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXgKSf4Le3tY",
        "outputId": "af807bc2-3a05-4337-9233-9419353f00cc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[  0.,   1.,   2.,   3.],\n",
              "        [  4.,   5.,   6.,   7.],\n",
              "        [  8., 500.,  10.,  11.]])"
            ]
          },
          "execution_count": 102,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X[-1,1] = 500\n",
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVKlrcYihYFN",
        "outputId": "b2811906-7cee-4d3c-a088-cfc892321df4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 12.,  12.,  12.,  12.],\n",
              "        [ 12.,  12.,  12.,  12.],\n",
              "        [400., 400., 400., 400.]])"
            ]
          },
          "execution_count": 108,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X[0:2, :] = 12\n",
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5uGIlI8eK_x"
      },
      "source": [
        "2.1.5.Saving Memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-v5fVq0iNOi",
        "outputId": "a16874be-35a0-4bd0-8f59-f7c933f48e62"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 114,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "before = id(Y)\n",
        "Y = Y + X\n",
        "id(Y) == before"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASJNOWdElEu9",
        "outputId": "8de16363-344f-44e3-ce4b-2d250dea736d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "id(Z): 140574712225872\n",
            "id(Z): 140574712225872\n"
          ]
        }
      ],
      "source": [
        "Z = torch.zeros_like(Y)\n",
        "print('id(Z):',id(Z))\n",
        "Z[:] = X + Y\n",
        "print('id(Z):',id(Z))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHuB8MgBmj_z",
        "outputId": "9a665931-5a59-483a-c78b-9e4945162c91"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 115,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "before = id(X)\n",
        "X += Y\n",
        "id(X) == before"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y__B0ssKeP-h"
      },
      "source": [
        "2.1.6. Conversion to Other Python Objects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZiM3icTm7eZ",
        "outputId": "34e26dac-edf0-479b-ed82-e3bb11650a79"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(numpy.ndarray, torch.Tensor)"
            ]
          },
          "execution_count": 116,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "A = X.numpy()\n",
        "B = torch.tensor(A)\n",
        "type(A), type(B)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjDxCePFeSlr"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKlWc6XRobpX",
        "outputId": "782fd38b-13b7-484c-f421-f7da8f8dfa90"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([0.2000]), 0.20000000298023224, 0.20000000298023224, 0)"
            ]
          },
          "execution_count": 119,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = torch.tensor([0.2])\n",
        "a, a.item(),float(a),int(a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lc9InpZzroOQ"
      },
      "source": [
        "딥러닝 연산에 근간을 이루고 있는 Linear algebra 개념들을 pytorch를 통해 여러 연산들을 진행해보면서 작년에 수강했던 선형대수 내용들과 파이썬을 리뷰할 수 있었고 broadcasting이 항상 적용될 수 있는 것이 아니라는 것을 알게 되었습니다.broadcasting 파트에서 tensor의 사이즈를 다양하게 바꿔서 더하기 연산을 한 후 결과를 확인해 보았는데 Broadcasting이 될 것이라고 예상했던 것들이 에러가 나와서 Broadcasting이 될 수 있는 조건이 정확히 무엇인지 알아봐야겠다고 생각했습니다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Tf8zyAZuB_v"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIsZtQUX1SA-"
      },
      "source": [
        "2.2. Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrPoSoY_1WKS"
      },
      "source": [
        "2.2.1. Reading the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0Z7Sxh3w1xHc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.makedirs(os.path.join('..','data'),exist_ok=True)\n",
        "data_file = os.path.join('..','data', 'house_tiny.csv')\n",
        "with open(data_file,'w') as f:\n",
        "  f.write('NumRooms,Alley,price\\n')\n",
        "  f.write('NA,Pave,150020\\n')\n",
        "  f.write('2,NA,230010\\n')\n",
        "  f.write('4,Pave,123000\\n')\n",
        "  f.write('33,NA,123120\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-byLlg4G0v9",
        "outputId": "3cda5e77-8bd2-4a9b-f667-6aabc9ee595e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   NumRooms Alley   price\n",
            "0       NaN  Pave  150020\n",
            "1       2.0   NaN  230010\n",
            "2       4.0  Pave  123000\n",
            "3      33.0   NaN  123120\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv(data_file)\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuwNbBi01ZgB"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qw0msc6WIZhH"
      },
      "source": [
        "2.2.2. Handling Missing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubh3S9HbI1RY",
        "outputId": "1fae5734-3ae1-48ff-fbb0-fd73536cb305"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   NumRooms Alley\n",
            "0      13.0  Pave\n",
            "1       2.0   NaN\n",
            "2       4.0  Pave\n",
            "3      33.0   NaN\n"
          ]
        }
      ],
      "source": [
        "inputs, outputs = data.iloc[:,0:2], data.iloc[:,2]\n",
        "inputs = inputs.fillna(inputs.mean())\n",
        "print(inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZXj-xRkPP5z"
      },
      "source": [
        "(2+4+33)/3 = 13"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afq3OXccPenm",
        "outputId": "e16e4f93-67ed-4e80-c314-9127e243a9d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0    150020\n",
            "1    230010\n",
            "2    123000\n",
            "3    123120\n",
            "Name: price, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iudtph0KRs4c",
        "outputId": "353909d6-32cb-4e76-979b-d3a72a4ffd02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   NumRooms  Alley_Pave  Alley_nan\n",
            "0      13.0           1          0\n",
            "1       2.0           0          1\n",
            "2       4.0           1          0\n",
            "3      33.0           0          1\n"
          ]
        }
      ],
      "source": [
        "inputs = pd.get_dummies(inputs, dummy_na=True)\n",
        "print(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3h2Y9qSR8Y8",
        "outputId": "d273f734-0613-48da-862e-853c9c8e1ef4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   NumRooms  Alley_Pave  Alley_nan\n",
            "0      13.0           1          0\n",
            "1       2.0           0          1\n",
            "2       4.0           1          0\n",
            "3      33.0           0          1\n"
          ]
        }
      ],
      "source": [
        "inputs = pd.get_dummies(inputs)\n",
        "print(inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUWHsj7KSw2e"
      },
      "source": [
        "2.2.3. Conversion to the Tensor Format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0pq8AsbTFH6",
        "outputId": "52e665ed-c8f9-41ee-dae2-07194c8d3cf9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[13.,  1.,  0.],\n",
              "         [ 2.,  0.,  1.],\n",
              "         [ 4.,  1.,  0.],\n",
              "         [33.,  0.,  1.]], dtype=torch.float64),\n",
              " tensor([150020, 230010, 123000, 123120]))"
            ]
          },
          "execution_count": 12,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "X, y = torch.tensor(inputs.values), torch.tensor(outputs.values)\n",
        "X, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ilJRW4oZKks"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iB-r2Ep8VFG1"
      },
      "source": [
        " os를 import하여 os.makedirs를 통해서 폴더를생성하고 새로운 dataset을 만들 수 있는 것을 알게 되었습니다. pandas 라이브러리의 read_csv()함수를 통해서 csv파일을 불러 올 수 있고 괄호안에 경로와 파일이름이 들어갑니다. fillna()라는 함수를 통해 Missing data를 여러가지 방법으로 처리할 수 있는데 NaN 값을 평균값으로 대체s를 import하여 os.makedirs를 통해서 폴더를생성하고 새로운 dataset을 만들 수 있는 것을 알게 되었습니다. pandas 라이브러리의 read_csv()함수를 통해서 csv파일을 불러 올 수 있고 괄호안에 경로와 파일이름이 들어갑니다. fillna()라는 함수를 통해 Missing data를 여러가지 방법으로 처리할 수 있는데 NaN 값을 평균값으로 대체 할 수 있는 것을 알게 되었고 get_dummies()를 통해 숫자로서의 관계성을 없애주기위해 가변수화할 수 있다는 것을 알게 되었습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLbMrbyLZSnt"
      },
      "source": [
        "2.3. Linear Algebra"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nr3BoAzrZqe6"
      },
      "source": [
        "2.3.1. Scalars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDmA9ZSgZvMB",
        "outputId": "19d39a34-b6e3-4dc0-946b-934248bd9af1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([7.]), tensor([12.]), tensor([1.3333]), tensor([64.]), tensor([1.]))"
            ]
          },
          "execution_count": 15,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "x = torch.tensor([4.0])\n",
        "y = torch.tensor([3.0])\n",
        "\n",
        "x + y, x * y, x / y, x**y, x//y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moJvZDhHd1b4"
      },
      "source": [
        "2.3.2. Vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CP9Gl5fXd2vm",
        "outputId": "71adcf98-f1f0-48e8-8996-97a0872acce1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
              "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
              "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
              "        54, 55])"
            ]
          },
          "execution_count": 19,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.arange(56)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EStVrekkfpuK",
        "outputId": "40e48f6e-bcdd-425f-cea1-7a477bc4cfec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(44)"
            ]
          },
          "execution_count": 20,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x[44]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGGNcAWTfudx"
      },
      "source": [
        "2.3.2.1. Length, Dimensionality, and Shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8PMK9aHfvGf",
        "outputId": "455317cb-4ff2-4136-ba0d-5ab234bc4849"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "56"
            ]
          },
          "execution_count": 21,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWzFUwLHf9zB",
        "outputId": "f178321b-d65e-49a4-8b1b-431a4e193ddf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([56])"
            ]
          },
          "execution_count": 22,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N78ccksTgwow"
      },
      "source": [
        "2.3.3. Matrices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7U4v0STAgzu3",
        "outputId": "9d498b44-02b6-4b9f-b968-3af1531ea8e8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0,  1,  2,  3,  4],\n",
              "        [ 5,  6,  7,  8,  9],\n",
              "        [10, 11, 12, 13, 14],\n",
              "        [15, 16, 17, 18, 19],\n",
              "        [20, 21, 22, 23, 24],\n",
              "        [25, 26, 27, 28, 29]])"
            ]
          },
          "execution_count": 24,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "A = torch.arange(30).reshape(6,5)\n",
        "A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RV9XzohIivrf",
        "outputId": "f2a2eb18-9286-4c1d-de5a-806c1c353d0c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0,  5, 10, 15, 20, 25],\n",
              "        [ 1,  6, 11, 16, 21, 26],\n",
              "        [ 2,  7, 12, 17, 22, 27],\n",
              "        [ 3,  8, 13, 18, 23, 28],\n",
              "        [ 4,  9, 14, 19, 24, 29]])"
            ]
          },
          "execution_count": 25,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "A.T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hECkWAWi-Dq",
        "outputId": "29f39d4b-bc2b-4224-ec09-8de61cf43d71"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1, 6, 7, 2],\n",
              "        [5, 5, 6, 1],\n",
              "        [2, 2, 6, 5],\n",
              "        [2, 3, 2, 7]])"
            ]
          },
          "execution_count": 28,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "B = torch.tensor([[1,6,7,2],[5,5,6,1],[2,2,6,5],[2,3,2,7]])\n",
        "B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzUZd95cjmC_",
        "outputId": "4d08973a-b84a-413c-ed80-cd45d9c8ec2a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ True, False, False,  True],\n",
              "        [False,  True, False, False],\n",
              "        [False, False,  True, False],\n",
              "        [ True, False, False,  True]])"
            ]
          },
          "execution_count": 29,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "B == B.T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pj7DTekNjzfk"
      },
      "source": [
        "2.3.4. Tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvz_kLCHj0Dr",
        "outputId": "b2bbcf68-43bf-45ad-cfa2-c67904014ec1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[ 0,  1,  2,  3,  4],\n",
              "         [ 5,  6,  7,  8,  9],\n",
              "         [10, 11, 12, 13, 14]],\n",
              "\n",
              "        [[15, 16, 17, 18, 19],\n",
              "         [20, 21, 22, 23, 24],\n",
              "         [25, 26, 27, 28, 29]]])"
            ]
          },
          "execution_count": 32,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X = torch.arange(30).reshape(2,3,5)\n",
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiHBRYAxkNqF"
      },
      "source": [
        "2.3.5. Basic Properties of Tensor Arithmetic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_GkL2cKkOq-",
        "outputId": "f4eea9df-d625-4410-b92d-df11f9a79be8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[ 0.,  1.,  2.,  3.,  4.],\n",
              "         [ 5.,  6.,  7.,  8.,  9.],\n",
              "         [10., 11., 12., 13., 14.],\n",
              "         [15., 16., 17., 18., 19.],\n",
              "         [20., 21., 22., 23., 24.],\n",
              "         [25., 26., 27., 28., 29.]]), tensor([[ 0.,  2.,  4.,  6.,  8.],\n",
              "         [10., 12., 14., 16., 18.],\n",
              "         [20., 22., 24., 26., 28.],\n",
              "         [30., 32., 34., 36., 38.],\n",
              "         [40., 42., 44., 46., 48.],\n",
              "         [50., 52., 54., 56., 58.]]), tensor([[ 0.,  1.,  2.,  3.,  4.],\n",
              "         [ 5.,  6.,  7.,  8.,  9.],\n",
              "         [10., 11., 12., 13., 14.],\n",
              "         [15., 16., 17., 18., 19.],\n",
              "         [20., 21., 22., 23., 24.],\n",
              "         [25., 26., 27., 28., 29.]]))"
            ]
          },
          "execution_count": 34,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "A = torch.arange(30, dtype=torch.float32).reshape(6,5)\n",
        "B = A.clone()\n",
        "A , A+B , B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUShDwvdlVYJ",
        "outputId": "331f2ae6-3032-4dcb-f00c-2320bc23897a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[  0.,   1.,   4.,   9.,  16.],\n",
              "        [ 25.,  36.,  49.,  64.,  81.],\n",
              "        [100., 121., 144., 169., 196.],\n",
              "        [225., 256., 289., 324., 361.],\n",
              "        [400., 441., 484., 529., 576.],\n",
              "        [625., 676., 729., 784., 841.]])"
            ]
          },
          "execution_count": 35,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "A * B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOAxJjF9ln0O",
        "outputId": "7e483034-9fc6-4729-c28e-8c3c9c066561"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[[10, 11],\n",
              "          [12, 13],\n",
              "          [14, 15],\n",
              "          [16, 17],\n",
              "          [18, 19],\n",
              "          [20, 21]],\n",
              " \n",
              "         [[22, 23],\n",
              "          [24, 25],\n",
              "          [26, 27],\n",
              "          [28, 29],\n",
              "          [30, 31],\n",
              "          [32, 33]]]), torch.Size([2, 6, 2]))"
            ]
          },
          "execution_count": 38,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = 10\n",
        "X = torch.arange(24).reshape(2,6,2)\n",
        "a + X, (a * X).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bz1EjQydnXK3"
      },
      "source": [
        "2.3.6. Reduction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCyQ3YHnnae6",
        "outputId": "2b38fc9a-bd2a-49e4-c89d-4675334a43aa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.]), tensor(45.))"
            ]
          },
          "execution_count": 40,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.arange(10,dtype=torch.float32)\n",
        "x, x.sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gO3HbvAny9b",
        "outputId": "a513bedf-8a8d-40b7-f8ec-b2aef495724e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([6, 5]), tensor(435.))"
            ]
          },
          "execution_count": 41,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "A.shape, A.sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxrAnUIqoxz3",
        "outputId": "d5e8078f-4633-41c2-f13f-9d6df7d3c97b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.,  1.,  2.,  3.,  4.],\n",
              "        [ 5.,  6.,  7.,  8.,  9.],\n",
              "        [10., 11., 12., 13., 14.],\n",
              "        [15., 16., 17., 18., 19.],\n",
              "        [20., 21., 22., 23., 24.],\n",
              "        [25., 26., 27., 28., 29.]])"
            ]
          },
          "execution_count": 42,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySY5MCC-o0hQ",
        "outputId": "b4c02636-447a-491c-841e-ac73867fa6f4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([75., 81., 87., 93., 99.]), torch.Size([5]))"
            ]
          },
          "execution_count": 45,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "A_sum_axis0 = A.sum(axis=0)\n",
        "A_sum_axis0, A_sum_axis0.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_ZkDPVlp6MK",
        "outputId": "00fa1159-7284-4251-837c-73bfbd72dfdb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([ 10.,  35.,  60.,  85., 110., 135.]), torch.Size([6]))"
            ]
          },
          "execution_count": 46,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "A_sum_axis1 = A.sum(axis=1)\n",
        "A_sum_axis1, A_sum_axis1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0wNJQg-qT-I",
        "outputId": "1d81d118-cdb0-41a1-8d12-56fa3cb15454"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(435.)"
            ]
          },
          "execution_count": 49,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "A.sum(axis=[0,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSiJF8Mwq0f6",
        "outputId": "f29d569e-b7e3-4b1e-e6df-f750fa42af06"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(14.5000), tensor(435.), 30, tensor(14.5000))"
            ]
          },
          "execution_count": 51,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "A.mean(), A.sum(), A.numel(), A.sum() / A.numel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2tK4C2JrggT",
        "outputId": "b5a6ee91-a905-4e46-be5d-f85419a9c4ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([12.5000, 13.5000, 14.5000, 15.5000, 16.5000]),\n",
              " tensor([75., 81., 87., 93., 99.]),\n",
              " 6,\n",
              " tensor([12.5000, 13.5000, 14.5000, 15.5000, 16.5000]))"
            ]
          },
          "execution_count": 52,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "A.mean(axis=0), A.sum(axis=0),A.shape[0],A.sum(axis=0)/A.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzDaBAqTtDGP"
      },
      "source": [
        "2.3.6.1. Non-Reduction Sum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ed3Rx57vWca",
        "outputId": "780d893a-aefe-42cf-89a1-d50ebc7a145e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 10.,  35.,  60.,  85., 110., 135.])"
            ]
          },
          "execution_count": 58,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sum_A = A.sum(axis=1)\n",
        "sum_A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhpjHpZotELB",
        "outputId": "81578178-529f-4d65-de3d-58ff5f47dd02"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 10.],\n",
              "        [ 35.],\n",
              "        [ 60.],\n",
              "        [ 85.],\n",
              "        [110.],\n",
              "        [135.]])"
            ]
          },
          "execution_count": 63,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sum_A = A.sum(axis=1,keepdims=True)\n",
        "sum_A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkL9kBAmwjv9",
        "outputId": "a471c896-7e15-4350-ed22-de086cb53acc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.1000, 0.2000, 0.3000, 0.4000],\n",
              "        [0.1429, 0.1714, 0.2000, 0.2286, 0.2571],\n",
              "        [0.1667, 0.1833, 0.2000, 0.2167, 0.2333],\n",
              "        [0.1765, 0.1882, 0.2000, 0.2118, 0.2235],\n",
              "        [0.1818, 0.1909, 0.2000, 0.2091, 0.2182],\n",
              "        [0.1852, 0.1926, 0.2000, 0.2074, 0.2148]])"
            ]
          },
          "execution_count": 64,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "A / sum_A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuBfWR3-xR_O",
        "outputId": "cfca324f-de0c-41b2-cd84-9568572ed5e1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[  0.,   1.,   3.,   6.,  10.],\n",
              "        [  5.,  11.,  18.,  26.,  35.],\n",
              "        [ 10.,  21.,  33.,  46.,  60.],\n",
              "        [ 15.,  31.,  48.,  66.,  85.],\n",
              "        [ 20.,  41.,  63.,  86., 110.],\n",
              "        [ 25.,  51.,  78., 106., 135.]])"
            ]
          },
          "execution_count": 71,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "A.cumsum(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vk3MEbhaz2D5",
        "outputId": "95b39898-dbfc-4717-d53a-56c121abba33"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.,  1.,  2.,  3.,  4.],\n",
              "        [ 5.,  6.,  7.,  8.,  9.],\n",
              "        [10., 11., 12., 13., 14.],\n",
              "        [15., 16., 17., 18., 19.],\n",
              "        [20., 21., 22., 23., 24.],\n",
              "        [25., 26., 27., 28., 29.]])"
            ]
          },
          "execution_count": 66,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKo4WICt1Z-l",
        "outputId": "f773c728-5bea-495f-bff0-122e87b3b382"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0,  1,  3],\n",
              "        [ 3,  7, 12],\n",
              "        [ 6, 13, 21]])"
            ]
          },
          "execution_count": 80,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "b = torch.arange(9).reshape(3,3)\n",
        "b.cumsum(axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQJka_7F88Xg"
      },
      "source": [
        "2.3.7. Dot Products"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nr_ExlCW8-6N",
        "outputId": "e54a38ee-2efc-4ccb-8b59-3790d76e8463"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([0., 1., 2., 3., 4.]), tensor([1., 1., 1., 1., 1.]), tensor(10.))"
            ]
          },
          "execution_count": 91,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.arange(5,dtype=torch.float32)\n",
        "y = torch.ones(5, dtype=torch.float32)\n",
        "x, y, torch.dot(x, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gxu219tq-nJi",
        "outputId": "36239f55-c0fb-4eaa-e3d2-06926d95e262"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(10.)"
            ]
          },
          "execution_count": 92,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.sum(x*y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IF9ysvX-vSP"
      },
      "source": [
        "2.3.8. Matrix-Vector Products"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sck9KpG-yJC",
        "outputId": "9f4c3cae-d643-426b-f5ed-55676047387f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([6, 5]),\n",
              " torch.Size([5]),\n",
              " tensor([ 30.,  80., 130., 180., 230., 280.]))"
            ]
          },
          "execution_count": 93,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "A.shape, x.shape, torch.mv(A,x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPLRCsDrBT2w"
      },
      "source": [
        "2.3.9. Matrix-Matrix Multiplication"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRn6d4kjBUtP",
        "outputId": "3cfe5d4c-94ae-46f1-8072-1b6416b435a9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 10.,  10.,  10.],\n",
              "        [ 35.,  35.,  35.],\n",
              "        [ 60.,  60.,  60.],\n",
              "        [ 85.,  85.,  85.],\n",
              "        [110., 110., 110.],\n",
              "        [135., 135., 135.]])"
            ]
          },
          "execution_count": 95,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "B = torch.ones(5,3)\n",
        "torch.mm(A,B)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6-J1H1GB6OU"
      },
      "source": [
        "2.3.10. Norms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9y8hGFAVB8Kj",
        "outputId": "b99a1649-e9ab-493f-8631-f5656bdf1b1f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(5.)"
            ]
          },
          "execution_count": 96,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "u = torch.tensor([3.0, -4.0])\n",
        "torch.norm(u)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsiX80IrC5cT",
        "outputId": "15bb857c-58ca-4144-f4b3-1fa6b28fa8d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(7.)"
            ]
          },
          "execution_count": 97,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.abs(u).sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38rONRo4EQZV",
        "outputId": "ec5d812f-6546-4312-96e8-11ee076645fc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(6.)"
            ]
          },
          "execution_count": 107,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.norm(torch.ones((4,9))) #(4*9)^(1/2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTXBn0VhHHI1",
        "outputId": "fa66002c-6d1d-4ec2-e721-7bf45bc6fc90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1.],\n",
            "        [1.]])\n"
          ]
        }
      ],
      "source": [
        "a = torch.ones(2,1)\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0aPhVDjNoiF"
      },
      "source": [
        "Linear Algebra에 대한 Tensor의 여러가지 연산들을 각각에 해당하는 함수들을 통해 실습을 해볼 수 있었습니다. 실습 중에서 한 가지 계속해서 헷갈리는 부분이 있었는데\n",
        "cumsum(axis=0)함수의 역할에 대해 좀더 자세히 알고 싶습니다.axis=0일 때 같은 column 끼리의 누적 합을 하고 axis=1일 때 같은 row끼리의 누적 합을 한다고 알고 있는데 axis=0일 때 발견한 규칙은 1행1열에 해당하는 element 그리고 2행1열에 대해 해당하는 것의 차이가 4이면 그 다음 1행2열과 2행2열에 해당하는 element끼리의 차는 5였습니다. 마찬가지 방식으로 다음의 경우는 차이가 6이었는데 이러한 관계가 있다는 것만 알게 되었고\n",
        "정확히 cumsum(axis=0)이라는 함수가 어떤 기능을 하는지 정확히 알고싶습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5iCM4dtPIhK"
      },
      "source": [
        "2.4. Calculus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHxVb4KLauqS"
      },
      "source": [
        "2.4.1. Derivatives and Differentiation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4d5bLNW0JDj",
        "outputId": "769206cf-ce57-4bb5-a3e1-3db762dfaf44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting d2l==0.16.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/1f/13de7e8cafaba15739caee0596032412aaf51a22726649b317bdb53c4f9a/d2l-0.16.2-py3-none-any.whl (77kB)\n",
            "\r\u001b[K     |████▎                           | 10kB 12.0MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 20kB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 30kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 40kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 51kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 61kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 71kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 3.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from d2l==0.16.2) (1.1.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from d2l==0.16.2) (3.2.2)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.7/dist-packages (from d2l==0.16.2) (1.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from d2l==0.16.2) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from d2l==0.16.2) (2.23.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->d2l==0.16.2) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->d2l==0.16.2) (2018.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->d2l==0.16.2) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->d2l==0.16.2) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->d2l==0.16.2) (2.4.7)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l==0.16.2) (7.6.3)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l==0.16.2) (5.3.1)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l==0.16.2) (5.0.3)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l==0.16.2) (5.2.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l==0.16.2) (5.6.1)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l==0.16.2) (4.10.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->d2l==0.16.2) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->d2l==0.16.2) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->d2l==0.16.2) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->d2l==0.16.2) (1.24.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->d2l==0.16.2) (1.15.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->d2l==0.16.2) (5.0.5)\n",
            "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->d2l==0.16.2) (5.5.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->d2l==0.16.2) (3.5.1)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->d2l==0.16.2) (1.0.0)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->d2l==0.16.2) (5.1.2)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->d2l==0.16.2) (0.9.2)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->d2l==0.16.2) (0.2.0)\n",
            "Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->d2l==0.16.2) (4.7.1)\n",
            "Requirement already satisfied: jupyter-client>=5.2.0 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->d2l==0.16.2) (5.3.5)\n",
            "Requirement already satisfied: tornado>=4 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->d2l==0.16.2) (5.1.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->d2l==0.16.2) (2.11.3)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->d2l==0.16.2) (1.5.0)\n",
            "Requirement already satisfied: pyzmq>=17.1 in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->d2l==0.16.2) (22.0.3)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->d2l==0.16.2) (2.6.1)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->d2l==0.16.2) (1.9.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-console->jupyter->d2l==0.16.2) (1.0.18)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l==0.16.2) (0.3)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l==0.16.2) (0.8.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l==0.16.2) (1.4.3)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l==0.16.2) (0.4.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l==0.16.2) (0.7.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l==0.16.2) (3.3.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->d2l==0.16.2) (0.8.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->d2l==0.16.2) (54.1.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->d2l==0.16.2) (4.4.2)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->d2l==0.16.2) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->d2l==0.16.2) (0.7.5)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter->d2l==0.16.2) (2.6.0)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter->d2l==0.16.2) (0.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook->jupyter->d2l==0.16.2) (1.1.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.0->jupyter-console->jupyter->d2l==0.16.2) (0.2.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter->d2l==0.16.2) (20.9)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter->d2l==0.16.2) (0.5.1)\n",
            "Installing collected packages: d2l\n",
            "Successfully installed d2l-0.16.2\n"
          ]
        }
      ],
      "source": [
        "!pip install d2l==0.16.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "hEKa_9HuQIH3"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "from IPython import display\n",
        "from d2l import torch as d2l\n",
        "\n",
        "def f(x):\n",
        "  return 1 * x ** 3 - 3 * x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLFNbfat0dtD",
        "outputId": "fb4eb0e8-bc8f-4551-d64f-a37eef0b038c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "h=0.10000, numerical limit=0.310000\n",
            "h=0.01000, numerical limit=0.030100\n",
            "h=0.00100, numerical limit=0.003001\n",
            "h=0.00010, numerical limit=0.000300\n",
            "h=0.00001, numerical limit=0.000030\n"
          ]
        }
      ],
      "source": [
        "def numerical_lim(f,x,h):\n",
        "  return (f(x+h) - f(x)) / h\n",
        "\n",
        "h = 0.1\n",
        "for i in range(5):\n",
        "  print(f'h={h:.5f}, numerical limit={numerical_lim(f,1,h):5f}')\n",
        "  h *= 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "F1s82LmA3DpZ"
      },
      "outputs": [],
      "source": [
        "def use_svg_display():\n",
        "  \"\"\"Use the svg format to display a plot in Jupyter.\"\"\"\n",
        "  display.set_matplotlib_formats('svg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "kKWu4FG73fzk"
      },
      "outputs": [],
      "source": [
        "def set_figsize(figsize=(3.5,2.5)):\n",
        "  \"\"\"Set the figure size for matplotlib.\"\"\"\n",
        "  use_svg_display()\n",
        "  d2l.plt.rcParams['figure.figsize'] = figsize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "rFTiEg19368Y"
      },
      "outputs": [],
      "source": [
        "def set_axes(axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend):\n",
        "  \"\"\"Set the axes for matplotlib.\"\"\"\n",
        "  axes.set_xlabel(xlabel)\n",
        "  axes.set_ylabel(ylabel)\n",
        "  axes.set_xscale(xscale)\n",
        "  axes.set_yscale(yscale)\n",
        "  axes.set_xlim(xlim)\n",
        "  axes.set_ylim(ylim)\n",
        "  if legend:\n",
        "    axes.legend(legend)\n",
        "    axes.grid()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "2sSp3gWB46tB"
      },
      "outputs": [],
      "source": [
        "#@save\n",
        "def plot(X, Y=None, xlabel=None, ylabel=None, legend=None, xlim=None,\n",
        "         ylim=None, xscale='linear', yscale='linear',\n",
        "         fmts=('-', 'm--', 'g-.', 'r:'), figsize=(3.5, 2.5), axes=None):\n",
        "    \"\"\"Plot data points.\"\"\"\n",
        "    if legend is None:\n",
        "        legend = []\n",
        "\n",
        "    set_figsize(figsize)\n",
        "    axes = axes if axes else d2l.plt.gca()\n",
        "\n",
        "    # Return True if `X` (tensor or list) has 1 axis\n",
        "    def has_one_axis(X):\n",
        "        return (hasattr(X, \"ndim\") and X.ndim == 1 or\n",
        "                isinstance(X, list) and not hasattr(X[0], \"__len__\"))\n",
        "\n",
        "    if has_one_axis(X):\n",
        "        X = [X]\n",
        "    if Y is None:\n",
        "        X, Y = [[]] * len(X), X\n",
        "    elif has_one_axis(Y):\n",
        "        Y = [Y]\n",
        "    if len(X) != len(Y):\n",
        "        X = X * len(Y)\n",
        "    axes.cla()\n",
        "    for x, y, fmt in zip(X, Y, fmts):\n",
        "        if len(x):\n",
        "            axes.plot(x, y, fmt)\n",
        "        else:\n",
        "            axes.plot(y, fmt)\n",
        "    set_axes(axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "Cphz7SkS_Tnf",
        "outputId": "b393eca4-d1e2-4f4f-d2bf-ddf1ed7d1926"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  \n"
          ]
        },
        {
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"180.65625pt\" version=\"1.1\" viewBox=\"0 0 251.909047 180.65625\" width=\"251.909047pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M -0 180.65625 \nL 251.909047 180.65625 \nL 251.909047 0 \nL -0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 48.982813 143.1 \nL 244.282813 143.1 \nL 244.282813 7.2 \nL 48.982813 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path clip-path=\"url(#p5d03175f40)\" d=\"M 57.860085 143.1 \nL 57.860085 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_2\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m64a9ca6dc1\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"57.860085\" xlink:href=\"#m64a9ca6dc1\" y=\"143.1\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(54.678835 157.698438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_3\">\n      <path clip-path=\"url(#p5d03175f40)\" d=\"M 119.082656 143.1 \nL 119.082656 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"119.082656\" xlink:href=\"#m64a9ca6dc1\" y=\"143.1\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 1 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <g transform=\"translate(115.901406 157.698438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_5\">\n      <path clip-path=\"url(#p5d03175f40)\" d=\"M 180.305226 143.1 \nL 180.305226 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"180.305226\" xlink:href=\"#m64a9ca6dc1\" y=\"143.1\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 2 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(177.123976 157.698438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_7\">\n      <path clip-path=\"url(#p5d03175f40)\" d=\"M 241.527797 143.1 \nL 241.527797 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"241.527797\" xlink:href=\"#m64a9ca6dc1\" y=\"143.1\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 3 -->\n      <defs>\n       <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n      </defs>\n      <g transform=\"translate(238.346547 157.698438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_5\">\n     <!-- x -->\n     <defs>\n      <path d=\"M 54.890625 54.6875 \nL 35.109375 28.078125 \nL 55.90625 0 \nL 45.3125 0 \nL 29.390625 21.484375 \nL 13.484375 0 \nL 2.875 0 \nL 24.125 28.609375 \nL 4.6875 54.6875 \nL 15.28125 54.6875 \nL 29.78125 35.203125 \nL 44.28125 54.6875 \nz\n\" id=\"DejaVuSans-120\"/>\n     </defs>\n     <g transform=\"translate(143.673438 171.376563)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-120\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_9\">\n      <path clip-path=\"url(#p5d03175f40)\" d=\"M 48.982813 136.926356 \nL 244.282813 136.926356 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_10\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m82954a5f48\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"48.982813\" xlink:href=\"#m82954a5f48\" y=\"136.926356\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- −10 -->\n      <defs>\n       <path d=\"M 10.59375 35.5 \nL 73.1875 35.5 \nL 73.1875 27.203125 \nL 10.59375 27.203125 \nz\n\" id=\"DejaVuSans-8722\"/>\n      </defs>\n      <g transform=\"translate(20.878125 140.725575)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_11\">\n      <path clip-path=\"url(#p5d03175f40)\" d=\"M 48.982813 100.635539 \nL 244.282813 100.635539 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"48.982813\" xlink:href=\"#m82954a5f48\" y=\"100.635539\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0 -->\n      <g transform=\"translate(35.620313 104.434758)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_13\">\n      <path clip-path=\"url(#p5d03175f40)\" d=\"M 48.982813 64.344722 \nL 244.282813 64.344722 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"48.982813\" xlink:href=\"#m82954a5f48\" y=\"64.344722\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 10 -->\n      <g transform=\"translate(29.257813 68.143941)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_15\">\n      <path clip-path=\"url(#p5d03175f40)\" d=\"M 48.982813 28.053905 \nL 244.282813 28.053905 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_16\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"48.982813\" xlink:href=\"#m82954a5f48\" y=\"28.053905\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 20 -->\n      <g transform=\"translate(29.257813 31.853124)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_10\">\n     <!-- f(x) -->\n     <defs>\n      <path d=\"M 37.109375 75.984375 \nL 37.109375 68.5 \nL 28.515625 68.5 \nQ 23.6875 68.5 21.796875 66.546875 \nQ 19.921875 64.59375 19.921875 59.515625 \nL 19.921875 54.6875 \nL 34.71875 54.6875 \nL 34.71875 47.703125 \nL 19.921875 47.703125 \nL 19.921875 0 \nL 10.890625 0 \nL 10.890625 47.703125 \nL 2.296875 47.703125 \nL 2.296875 54.6875 \nL 10.890625 54.6875 \nL 10.890625 58.5 \nQ 10.890625 67.625 15.140625 71.796875 \nQ 19.390625 75.984375 28.609375 75.984375 \nz\n\" id=\"DejaVuSans-102\"/>\n      <path d=\"M 31 75.875 \nQ 24.46875 64.65625 21.28125 53.65625 \nQ 18.109375 42.671875 18.109375 31.390625 \nQ 18.109375 20.125 21.3125 9.0625 \nQ 24.515625 -2 31 -13.1875 \nL 23.1875 -13.1875 \nQ 15.875 -1.703125 12.234375 9.375 \nQ 8.59375 20.453125 8.59375 31.390625 \nQ 8.59375 42.28125 12.203125 53.3125 \nQ 15.828125 64.359375 23.1875 75.875 \nz\n\" id=\"DejaVuSans-40\"/>\n      <path d=\"M 8.015625 75.875 \nL 15.828125 75.875 \nQ 23.140625 64.359375 26.78125 53.3125 \nQ 30.421875 42.28125 30.421875 31.390625 \nQ 30.421875 20.453125 26.78125 9.375 \nQ 23.140625 -1.703125 15.828125 -13.1875 \nL 8.015625 -13.1875 \nQ 14.5 -2 17.703125 9.0625 \nQ 20.90625 20.125 20.90625 31.390625 \nQ 20.90625 42.671875 17.703125 53.65625 \nQ 14.5 64.65625 8.015625 75.875 \nz\n\" id=\"DejaVuSans-41\"/>\n     </defs>\n     <g transform=\"translate(14.798438 83.771094)rotate(-90)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-102\"/>\n      <use x=\"35.205078\" xlink:href=\"#DejaVuSans-40\"/>\n      <use x=\"74.21875\" xlink:href=\"#DejaVuSans-120\"/>\n      <use x=\"133.398438\" xlink:href=\"#DejaVuSans-41\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_17\">\n    <path clip-path=\"url(#p5d03175f40)\" d=\"M 63.982342 136.922727 \nL 70.104599 118.751915 \nL 76.226856 112.634493 \nL 82.349113 109.475982 \nL 88.47137 107.440067 \nL 94.593628 105.900127 \nL 100.715885 104.575167 \nL 106.838142 103.313802 \nL 112.960399 102.022252 \nL 119.082656 100.635539 \nL 125.204913 99.104397 \nL 131.32717 97.388721 \nL 137.449427 95.454048 \nL 143.571684 93.26954 \nL 149.693941 90.806776 \nL 155.816198 88.038997 \nL 161.938455 84.940615 \nL 168.060712 81.486891 \nL 174.182969 77.653711 \nL 180.305226 73.417426 \nL 186.427483 68.754748 \nL 192.54974 63.64266 \nL 198.671997 58.058364 \nL 204.794255 51.979231 \nL 210.916512 45.38277 \nL 217.038769 38.2466 \nL 223.161026 30.548428 \nL 229.283283 22.266038 \nL 235.40554 13.377273 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_18\">\n    <path clip-path=\"url(#p5d03175f40)\" d=\"M 57.860085 107.893703 \nL 63.982342 107.167886 \nL 70.104599 106.44207 \nL 76.226856 105.716254 \nL 82.349113 104.990437 \nL 88.47137 104.264621 \nL 94.593628 103.538805 \nL 100.715885 102.812988 \nL 106.838142 102.087172 \nL 112.960399 101.361356 \nL 119.082656 100.635539 \nL 125.204913 99.909723 \nL 131.32717 99.183907 \nL 137.449427 98.45809 \nL 143.571684 97.732274 \nL 149.693941 97.006457 \nL 155.816198 96.280641 \nL 161.938455 95.554825 \nL 168.060712 94.829008 \nL 174.182969 94.103192 \nL 180.305226 93.377376 \nL 186.427483 92.651559 \nL 192.54974 91.925743 \nL 198.671997 91.199927 \nL 204.794255 90.47411 \nL 210.916512 89.748294 \nL 217.038769 89.022478 \nL 223.161026 88.296661 \nL 229.283283 87.570845 \nL 235.40554 86.845029 \n\" style=\"fill:none;stroke:#bf00bf;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 48.982813 143.1 \nL 48.982813 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 244.282813 143.1 \nL 244.282813 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 48.982813 143.1 \nL 244.282813 143.1 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 48.982813 7.2 \nL 244.282813 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 55.982813 44.55625 \nL 180.532813 44.55625 \nQ 182.532813 44.55625 182.532813 42.55625 \nL 182.532813 14.2 \nQ 182.532813 12.2 180.532813 12.2 \nL 55.982813 12.2 \nQ 53.982813 12.2 53.982813 14.2 \nL 53.982813 42.55625 \nQ 53.982813 44.55625 55.982813 44.55625 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"line2d_19\">\n     <path d=\"M 57.982813 20.298437 \nL 77.982813 20.298437 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_20\"/>\n    <g id=\"text_11\">\n     <!-- f(x) = x ** 3 -1 /x -->\n     <defs>\n      <path id=\"DejaVuSans-32\"/>\n      <path d=\"M 10.59375 45.40625 \nL 73.1875 45.40625 \nL 73.1875 37.203125 \nL 10.59375 37.203125 \nz\nM 10.59375 25.484375 \nL 73.1875 25.484375 \nL 73.1875 17.1875 \nL 10.59375 17.1875 \nz\n\" id=\"DejaVuSans-61\"/>\n      <path d=\"M 47.015625 60.890625 \nL 29.5 51.421875 \nL 47.015625 41.890625 \nL 44.1875 37.109375 \nL 27.78125 47.015625 \nL 27.78125 28.609375 \nL 22.21875 28.609375 \nL 22.21875 47.015625 \nL 5.8125 37.109375 \nL 2.984375 41.890625 \nL 20.515625 51.421875 \nL 2.984375 60.890625 \nL 5.8125 65.71875 \nL 22.21875 55.8125 \nL 22.21875 74.21875 \nL 27.78125 74.21875 \nL 27.78125 55.8125 \nL 44.1875 65.71875 \nz\n\" id=\"DejaVuSans-42\"/>\n      <path d=\"M 4.890625 31.390625 \nL 31.203125 31.390625 \nL 31.203125 23.390625 \nL 4.890625 23.390625 \nz\n\" id=\"DejaVuSans-45\"/>\n      <path d=\"M 25.390625 72.90625 \nL 33.6875 72.90625 \nL 8.296875 -9.28125 \nL 0 -9.28125 \nz\n\" id=\"DejaVuSans-47\"/>\n     </defs>\n     <g transform=\"translate(85.982813 23.798437)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-102\"/>\n      <use x=\"35.205078\" xlink:href=\"#DejaVuSans-40\"/>\n      <use x=\"74.21875\" xlink:href=\"#DejaVuSans-120\"/>\n      <use x=\"133.398438\" xlink:href=\"#DejaVuSans-41\"/>\n      <use x=\"172.412109\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"204.199219\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"287.988281\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"319.775391\" xlink:href=\"#DejaVuSans-120\"/>\n      <use x=\"378.955078\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"410.742188\" xlink:href=\"#DejaVuSans-42\"/>\n      <use x=\"460.742188\" xlink:href=\"#DejaVuSans-42\"/>\n      <use x=\"510.742188\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"542.529297\" xlink:href=\"#DejaVuSans-51\"/>\n      <use x=\"606.152344\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"637.939453\" xlink:href=\"#DejaVuSans-45\"/>\n      <use x=\"674.023438\" xlink:href=\"#DejaVuSans-49\"/>\n      <use x=\"737.646484\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"769.433594\" xlink:href=\"#DejaVuSans-47\"/>\n      <use x=\"803.125\" xlink:href=\"#DejaVuSans-120\"/>\n     </g>\n    </g>\n    <g id=\"line2d_21\">\n     <path d=\"M 57.982813 34.976562 \nL 77.982813 34.976562 \n\" style=\"fill:none;stroke:#bf00bf;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_22\"/>\n    <g id=\"text_12\">\n     <!-- Tangent line (x=1) -->\n     <defs>\n      <path d=\"M -0.296875 72.90625 \nL 61.375 72.90625 \nL 61.375 64.59375 \nL 35.5 64.59375 \nL 35.5 0 \nL 25.59375 0 \nL 25.59375 64.59375 \nL -0.296875 64.59375 \nz\n\" id=\"DejaVuSans-84\"/>\n      <path d=\"M 34.28125 27.484375 \nQ 23.390625 27.484375 19.1875 25 \nQ 14.984375 22.515625 14.984375 16.5 \nQ 14.984375 11.71875 18.140625 8.90625 \nQ 21.296875 6.109375 26.703125 6.109375 \nQ 34.1875 6.109375 38.703125 11.40625 \nQ 43.21875 16.703125 43.21875 25.484375 \nL 43.21875 27.484375 \nz\nM 52.203125 31.203125 \nL 52.203125 0 \nL 43.21875 0 \nL 43.21875 8.296875 \nQ 40.140625 3.328125 35.546875 0.953125 \nQ 30.953125 -1.421875 24.3125 -1.421875 \nQ 15.921875 -1.421875 10.953125 3.296875 \nQ 6 8.015625 6 15.921875 \nQ 6 25.140625 12.171875 29.828125 \nQ 18.359375 34.515625 30.609375 34.515625 \nL 43.21875 34.515625 \nL 43.21875 35.40625 \nQ 43.21875 41.609375 39.140625 45 \nQ 35.0625 48.390625 27.6875 48.390625 \nQ 23 48.390625 18.546875 47.265625 \nQ 14.109375 46.140625 10.015625 43.890625 \nL 10.015625 52.203125 \nQ 14.9375 54.109375 19.578125 55.046875 \nQ 24.21875 56 28.609375 56 \nQ 40.484375 56 46.34375 49.84375 \nQ 52.203125 43.703125 52.203125 31.203125 \nz\n\" id=\"DejaVuSans-97\"/>\n      <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-110\"/>\n      <path d=\"M 45.40625 27.984375 \nQ 45.40625 37.75 41.375 43.109375 \nQ 37.359375 48.484375 30.078125 48.484375 \nQ 22.859375 48.484375 18.828125 43.109375 \nQ 14.796875 37.75 14.796875 27.984375 \nQ 14.796875 18.265625 18.828125 12.890625 \nQ 22.859375 7.515625 30.078125 7.515625 \nQ 37.359375 7.515625 41.375 12.890625 \nQ 45.40625 18.265625 45.40625 27.984375 \nz\nM 54.390625 6.78125 \nQ 54.390625 -7.171875 48.1875 -13.984375 \nQ 42 -20.796875 29.203125 -20.796875 \nQ 24.46875 -20.796875 20.265625 -20.09375 \nQ 16.0625 -19.390625 12.109375 -17.921875 \nL 12.109375 -9.1875 \nQ 16.0625 -11.328125 19.921875 -12.34375 \nQ 23.78125 -13.375 27.78125 -13.375 \nQ 36.625 -13.375 41.015625 -8.765625 \nQ 45.40625 -4.15625 45.40625 5.171875 \nL 45.40625 9.625 \nQ 42.625 4.78125 38.28125 2.390625 \nQ 33.9375 0 27.875 0 \nQ 17.828125 0 11.671875 7.65625 \nQ 5.515625 15.328125 5.515625 27.984375 \nQ 5.515625 40.671875 11.671875 48.328125 \nQ 17.828125 56 27.875 56 \nQ 33.9375 56 38.28125 53.609375 \nQ 42.625 51.21875 45.40625 46.390625 \nL 45.40625 54.6875 \nL 54.390625 54.6875 \nz\n\" id=\"DejaVuSans-103\"/>\n      <path d=\"M 56.203125 29.59375 \nL 56.203125 25.203125 \nL 14.890625 25.203125 \nQ 15.484375 15.921875 20.484375 11.0625 \nQ 25.484375 6.203125 34.421875 6.203125 \nQ 39.59375 6.203125 44.453125 7.46875 \nQ 49.3125 8.734375 54.109375 11.28125 \nL 54.109375 2.78125 \nQ 49.265625 0.734375 44.1875 -0.34375 \nQ 39.109375 -1.421875 33.890625 -1.421875 \nQ 20.796875 -1.421875 13.15625 6.1875 \nQ 5.515625 13.8125 5.515625 26.8125 \nQ 5.515625 40.234375 12.765625 48.109375 \nQ 20.015625 56 32.328125 56 \nQ 43.359375 56 49.78125 48.890625 \nQ 56.203125 41.796875 56.203125 29.59375 \nz\nM 47.21875 32.234375 \nQ 47.125 39.59375 43.09375 43.984375 \nQ 39.0625 48.390625 32.421875 48.390625 \nQ 24.90625 48.390625 20.390625 44.140625 \nQ 15.875 39.890625 15.1875 32.171875 \nz\n\" id=\"DejaVuSans-101\"/>\n      <path d=\"M 18.3125 70.21875 \nL 18.3125 54.6875 \nL 36.8125 54.6875 \nL 36.8125 47.703125 \nL 18.3125 47.703125 \nL 18.3125 18.015625 \nQ 18.3125 11.328125 20.140625 9.421875 \nQ 21.96875 7.515625 27.59375 7.515625 \nL 36.8125 7.515625 \nL 36.8125 0 \nL 27.59375 0 \nQ 17.1875 0 13.234375 3.875 \nQ 9.28125 7.765625 9.28125 18.015625 \nL 9.28125 47.703125 \nL 2.6875 47.703125 \nL 2.6875 54.6875 \nL 9.28125 54.6875 \nL 9.28125 70.21875 \nz\n\" id=\"DejaVuSans-116\"/>\n      <path d=\"M 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 0 \nL 9.421875 0 \nz\n\" id=\"DejaVuSans-108\"/>\n      <path d=\"M 9.421875 54.6875 \nL 18.40625 54.6875 \nL 18.40625 0 \nL 9.421875 0 \nz\nM 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 64.59375 \nL 9.421875 64.59375 \nz\n\" id=\"DejaVuSans-105\"/>\n     </defs>\n     <g transform=\"translate(85.982813 38.476562)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-84\"/>\n      <use x=\"44.583984\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"105.863281\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"169.242188\" xlink:href=\"#DejaVuSans-103\"/>\n      <use x=\"232.71875\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"294.242188\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"357.621094\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"396.830078\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"428.617188\" xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"456.400391\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"484.183594\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"547.5625\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"609.085938\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"640.873047\" xlink:href=\"#DejaVuSans-40\"/>\n      <use x=\"679.886719\" xlink:href=\"#DejaVuSans-120\"/>\n      <use x=\"739.066406\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"822.855469\" xlink:href=\"#DejaVuSans-49\"/>\n      <use x=\"886.478516\" xlink:href=\"#DejaVuSans-41\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p5d03175f40\">\n   <rect height=\"135.9\" width=\"195.3\" x=\"48.982813\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
            "text/plain": [
              "<Figure size 252x180 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light",
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "x = np.arange(0,3,0.1)\n",
        "plot(x, [x**3-1/x, 2*x-2], 'x', 'f(x)', legend=['f(x) = x ** 3 -1 /x', 'Tangent line (x=1)'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UF4bJ649RiEC"
      },
      "source": [
        "Calculus의 내용 중 도함수의 정의에 대해 코드를 짜봤고 그래프에 대한 시각화를 위해 그래프의 크기를 지정하는alculus의 내용 중 도함수의 정의에 대해 코드를 짜봤고 그래프에 대한 시각화를 위해 그래프의 크기를 지정하는 set_figsize라는 함수를 사용할 수 있는 것을 알게 되었습니다.\n",
        "해당 내용을 통해 실제로 앞으로 다뤄야할 데이터들은 하나의 변수가 아닌 여러 개의 변수를 갖고 있기 때문에 Partial Derivatives를 될 것이고 그것에 대해 pytorch로 어떻게 연산을 할 수 있는지 알아야 겠다고 생각했습니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOlpysqAa_6E"
      },
      "source": [
        "2.5. Automatic Differentiation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHaklgiNbCPW"
      },
      "source": [
        "2.5.1. A Simple Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mSsAWDIbPmX",
        "outputId": "60929764-f498-4af8-c495-904e46ca8e8c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0., 1., 2., 3.])"
            ]
          },
          "execution_count": 3,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "x = torch.arange(4.0)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3Y2A7ToRcYIA"
      },
      "outputs": [],
      "source": [
        "x.requires_grad_(True)  # Same as `x = torch.arange(4.0, requires_grad=True)`\n",
        "x.grad  # The default value is None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUxlFEd_wtbU"
      },
      "source": [
        "x = [ x1 , x2, x3, x4]\n",
        "y = 2 * (x1^2 + x2^2 + x3^2 + x4^2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaH1itPCcqki",
        "outputId": "d70ae957-1eee-4d5b-fb44-53a074d88ded"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(213.0443, grad_fn=<DotBackward>)"
            ]
          },
          "execution_count": 7,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y = torch.dot(x**2,torch.exp(x))\n",
        "y  # y를 x에 대한 함수로 정의 실제로 연산은 backpropagation이라는 과정에서 벌어짐                            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLhw63p1ddRz",
        "outputId": "f8161727-fd98-49bc-c38e-39101897e513"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([  0.0000,  11.1548,  71.1124, 328.2831])"
            ]
          },
          "execution_count": 8,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.backward()\n",
        "x.grad #y가 갖고있는 gradient를 계산해야되는 변수들에 대해서 gradient를 계산한다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCiH6sDQ-Y2G",
        "outputId": "80146061-04e7-4384-9ecc-30dd5d050208"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ True, False, False, False])"
            ]
          },
          "execution_count": 15,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.grad == (2*x*torch.exp(x)) + (x**2 * torch.exp(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68FahVRd-rDO",
        "outputId": "c42ec88f-33dd-45c6-8615-a01100923877"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1., 1., 1., 1.])"
            ]
          },
          "execution_count": 16,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.grad.zero_()\n",
        "y = x.sum()\n",
        "y.backward()\n",
        "x.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuVwkptSbHjc"
      },
      "source": [
        "2.5.2. Backward for Non-Scalar Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTvDVSXRADUL",
        "outputId": "16f16ed9-f91a-4840-83a9-f8fc06dcaebf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0., 2., 4., 6.])"
            ]
          },
          "execution_count": 45,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.grad.zero_()\n",
        "y = x * x\n",
        "\n",
        "y.sum().backward()\n",
        "x.grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDUUDd04ARXO",
        "outputId": "ed1416d2-4cfa-4f78-81f8-2fcbc1841f72"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([True, True, True, True])"
            ]
          },
          "execution_count": 112,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.grad.zero_()\n",
        "y = x * x\n",
        "u = y.detach()\n",
        "z = u * x\n",
        "\n",
        "z.sum().backward()\n",
        "x.grad == u"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73aJNwglAV7i",
        "outputId": "7c88625c-1df3-43f9-f240-b1c67cfed266"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([True, True, True, True])"
            ]
          },
          "execution_count": 111,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.grad.zero_()\n",
        "y.sum().backward()\n",
        "x.grad == 2 * x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCstkbrUbI44"
      },
      "source": [
        "2.5.3. Detaching Computation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKPGDIThAbl-",
        "outputId": "55de50b0-931b-4cdf-ad73-743da388d96e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([True, True, True, True])"
            ]
          },
          "execution_count": 110,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.grad.zero_()\n",
        "y = x * x\n",
        "u = y.detach()\n",
        "z = u * x\n",
        "\n",
        "z.sum().backward()\n",
        "x.grad == u"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kiJeQWGAjIm",
        "outputId": "0773c155-2b7a-4511-9dcb-a8d2622f421e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([False, False, False, False])"
            ]
          },
          "execution_count": 17,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.grad.zero_()\n",
        "y.sum().backward()\n",
        "x.grad == 2 * x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRwJaK3_bLiv"
      },
      "source": [
        "2.5.4. Computing the Gradient of Python Control Flow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Wv0ET3XoAmM0"
      },
      "outputs": [],
      "source": [
        "def f(a):\n",
        "    b = a * 2\n",
        "    while b.norm() < 1000:\n",
        "        b = b * 2\n",
        "    if b.sum() > 0:\n",
        "        c = b\n",
        "    else:\n",
        "        c = 100 * b\n",
        "    return c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "et68d7rJAo24"
      },
      "outputs": [],
      "source": [
        "a = torch.randn(size=(), requires_grad=True)\n",
        "d = f(a)\n",
        "d.backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OddWeIjQArn7",
        "outputId": "1f1ee5d0-23c3-499c-dfd7-1df48889dd37"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(True)"
            ]
          },
          "execution_count": 116,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a.grad == d / a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnLroYRg59QN"
      },
      "source": [
        "이 단원을 통해서 chainRule과 연관된 backpropagate전반적인 내용들에 대해 좀 더 잘 이해하고 싶다는 생각을 했습니다.\n",
        "미적분 시간에 배운 gradient연산을 직접 손으로 계산하는 것은 어렵지 않게 느껴졌지만 pytorch를 이용해서 연산하는 것은 조금 더 복잡하다고 느껴졌습니다. gradient를 계산하기 위한 y를 정의할 때 다른 수식을 적용해보려고 torch.dot을 사용하지 않고 수식을 적었을 때는 에러가 발생했고 왜 에러가 발생하는지 검색해보았지만 아직 정확한 원인을 찾아내지 못했습니다. 또한 gradient가 맞게 연산되었는지 확인 하는 과정에서도 제가 의도했던 정답과 다르게 나와서 해당부분에 대해서 꼭 정확히 알고 넘어가고 싶습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywv0O3RWA9MK"
      },
      "source": [
        "2.6. Probability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMljw_eaBOYY",
        "outputId": "b9b0ea03-ef20-4b30-942b-2931eea586bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting d2l==0.16.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/1f/13de7e8cafaba15739caee0596032412aaf51a22726649b317bdb53c4f9a/d2l-0.16.2-py3-none-any.whl (77kB)\n",
            "\r\u001b[K     |████▎                           | 10kB 16.3MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 20kB 15.1MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 30kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 40kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 51kB 4.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 61kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 71kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 3.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from d2l==0.16.2) (1.1.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from d2l==0.16.2) (2.23.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from d2l==0.16.2) (3.2.2)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.7/dist-packages (from d2l==0.16.2) (1.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from d2l==0.16.2) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->d2l==0.16.2) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->d2l==0.16.2) (2018.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->d2l==0.16.2) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->d2l==0.16.2) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->d2l==0.16.2) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->d2l==0.16.2) (2.10)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->d2l==0.16.2) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->d2l==0.16.2) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->d2l==0.16.2) (1.3.1)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l==0.16.2) (5.3.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l==0.16.2) (5.6.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l==0.16.2) (7.6.3)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l==0.16.2) (5.2.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l==0.16.2) (4.10.1)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l==0.16.2) (5.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->d2l==0.16.2) (1.15.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->d2l==0.16.2) (5.1.2)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->d2l==0.16.2) (0.9.2)\n",
            "Requirement already satisfied: tornado>=4 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->d2l==0.16.2) (5.1.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->d2l==0.16.2) (0.2.0)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->d2l==0.16.2) (1.5.0)\n",
            "Requirement already satisfied: traitlets>=4.2.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->d2l==0.16.2) (5.0.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->d2l==0.16.2) (2.11.3)\n",
            "Requirement already satisfied: jupyter-client>=5.2.0 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->d2l==0.16.2) (5.3.5)\n",
            "Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->d2l==0.16.2) (4.7.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l==0.16.2) (3.3.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l==0.16.2) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l==0.16.2) (0.3)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l==0.16.2) (0.4.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l==0.16.2) (1.4.3)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l==0.16.2) (0.8.4)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l==0.16.2) (2.6.1)\n",
            "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->d2l==0.16.2) (5.5.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->d2l==0.16.2) (1.0.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->d2l==0.16.2) (3.5.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-console->jupyter->d2l==0.16.2) (1.0.18)\n",
            "Requirement already satisfied: pyzmq>=17.1 in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->d2l==0.16.2) (22.0.3)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->d2l==0.16.2) (1.9.0)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook->jupyter->d2l==0.16.2) (2.6.0)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter->d2l==0.16.2) (0.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook->jupyter->d2l==0.16.2) (1.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter->d2l==0.16.2) (20.9)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter->d2l==0.16.2) (0.5.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->d2l==0.16.2) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->d2l==0.16.2) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->d2l==0.16.2) (54.1.2)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->d2l==0.16.2) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->d2l==0.16.2) (0.8.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.0->jupyter-console->jupyter->d2l==0.16.2) (0.2.5)\n",
            "Installing collected packages: d2l\n",
            "Successfully installed d2l-0.16.2\n"
          ]
        }
      ],
      "source": [
        "!pip install d2l==0.16.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYfy44SPBDx1"
      },
      "source": [
        "2.6.1. Basic Probability Theory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "cyEGZdodBZM2"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import torch\n",
        "from torch.distributions import multinomial\n",
        "from d2l import torch as d2l\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dm4K6ecLBduE",
        "outputId": "f003728e-f9c8-4349-88fb-06cf6a5975d3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0., 0., 1., 0., 1., 0.])"
            ]
          },
          "execution_count": 8,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fair_probs = torch.ones([6]) / 6\n",
        "multinomial.Multinomial(2, fair_probs).sample()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TDEEYfjBiIe",
        "outputId": "4bed17a4-645c-4ecb-df90-90aab9f4c5a8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1., 1., 2., 3., 3., 0.])"
            ]
          },
          "execution_count": 9,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multinomial.Multinomial(10, fair_probs).sample()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9UgRE00BmHh",
        "outputId": "30dddf53-1b16-4442-ccea-180bd652e68a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0.1683, 0.1680, 0.1683, 0.1655, 0.1650, 0.1648])"
            ]
          },
          "execution_count": 15,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Store the results as 32-bit floats for division\n",
        "counts = multinomial.Multinomial(100000, fair_probs).sample()\n",
        "counts / 100000  # Relative frequency as the estimate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "HMAsdRrdBqHy",
        "outputId": "3beb40cb-d7ca-44b1-a75a-39d43a1819ee"
      },
      "outputs": [
        {
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"289.37625pt\" version=\"1.1\" viewBox=\"0 0 392.14375 289.37625\" width=\"392.14375pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 289.37625 \nL 392.14375 289.37625 \nL 392.14375 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 50.14375 251.82 \nL 384.94375 251.82 \nL 384.94375 7.2 \nL 50.14375 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m37529f8b9f\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"65.361932\" xlink:href=\"#m37529f8b9f\" y=\"251.82\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(62.180682 266.418437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"126.356649\" xlink:href=\"#m37529f8b9f\" y=\"251.82\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 100 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <g transform=\"translate(116.812899 266.418437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"187.351365\" xlink:href=\"#m37529f8b9f\" y=\"251.82\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 200 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(177.807615 266.418437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"248.346082\" xlink:href=\"#m37529f8b9f\" y=\"251.82\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 300 -->\n      <defs>\n       <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n      </defs>\n      <g transform=\"translate(238.802332 266.418437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"309.340799\" xlink:href=\"#m37529f8b9f\" y=\"251.82\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 400 -->\n      <defs>\n       <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n      </defs>\n      <g transform=\"translate(299.797049 266.418437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"370.335515\" xlink:href=\"#m37529f8b9f\" y=\"251.82\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 500 -->\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(360.791765 266.418437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_7\">\n     <!-- Groups of experiments -->\n     <defs>\n      <path d=\"M 59.515625 10.40625 \nL 59.515625 29.984375 \nL 43.40625 29.984375 \nL 43.40625 38.09375 \nL 69.28125 38.09375 \nL 69.28125 6.78125 \nQ 63.578125 2.734375 56.6875 0.65625 \nQ 49.8125 -1.421875 42 -1.421875 \nQ 24.90625 -1.421875 15.25 8.5625 \nQ 5.609375 18.5625 5.609375 36.375 \nQ 5.609375 54.25 15.25 64.234375 \nQ 24.90625 74.21875 42 74.21875 \nQ 49.125 74.21875 55.546875 72.453125 \nQ 61.96875 70.703125 67.390625 67.28125 \nL 67.390625 56.78125 \nQ 61.921875 61.421875 55.765625 63.765625 \nQ 49.609375 66.109375 42.828125 66.109375 \nQ 29.4375 66.109375 22.71875 58.640625 \nQ 16.015625 51.171875 16.015625 36.375 \nQ 16.015625 21.625 22.71875 14.15625 \nQ 29.4375 6.6875 42.828125 6.6875 \nQ 48.046875 6.6875 52.140625 7.59375 \nQ 56.25 8.5 59.515625 10.40625 \nz\n\" id=\"DejaVuSans-71\"/>\n      <path d=\"M 41.109375 46.296875 \nQ 39.59375 47.171875 37.8125 47.578125 \nQ 36.03125 48 33.890625 48 \nQ 26.265625 48 22.1875 43.046875 \nQ 18.109375 38.09375 18.109375 28.8125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 20.953125 51.171875 25.484375 53.578125 \nQ 30.03125 56 36.53125 56 \nQ 37.453125 56 38.578125 55.875 \nQ 39.703125 55.765625 41.0625 55.515625 \nz\n\" id=\"DejaVuSans-114\"/>\n      <path d=\"M 30.609375 48.390625 \nQ 23.390625 48.390625 19.1875 42.75 \nQ 14.984375 37.109375 14.984375 27.296875 \nQ 14.984375 17.484375 19.15625 11.84375 \nQ 23.34375 6.203125 30.609375 6.203125 \nQ 37.796875 6.203125 41.984375 11.859375 \nQ 46.1875 17.53125 46.1875 27.296875 \nQ 46.1875 37.015625 41.984375 42.703125 \nQ 37.796875 48.390625 30.609375 48.390625 \nz\nM 30.609375 56 \nQ 42.328125 56 49.015625 48.375 \nQ 55.71875 40.765625 55.71875 27.296875 \nQ 55.71875 13.875 49.015625 6.21875 \nQ 42.328125 -1.421875 30.609375 -1.421875 \nQ 18.84375 -1.421875 12.171875 6.21875 \nQ 5.515625 13.875 5.515625 27.296875 \nQ 5.515625 40.765625 12.171875 48.375 \nQ 18.84375 56 30.609375 56 \nz\n\" id=\"DejaVuSans-111\"/>\n      <path d=\"M 8.5 21.578125 \nL 8.5 54.6875 \nL 17.484375 54.6875 \nL 17.484375 21.921875 \nQ 17.484375 14.15625 20.5 10.265625 \nQ 23.53125 6.390625 29.59375 6.390625 \nQ 36.859375 6.390625 41.078125 11.03125 \nQ 45.3125 15.671875 45.3125 23.6875 \nL 45.3125 54.6875 \nL 54.296875 54.6875 \nL 54.296875 0 \nL 45.3125 0 \nL 45.3125 8.40625 \nQ 42.046875 3.421875 37.71875 1 \nQ 33.40625 -1.421875 27.6875 -1.421875 \nQ 18.265625 -1.421875 13.375 4.4375 \nQ 8.5 10.296875 8.5 21.578125 \nz\nM 31.109375 56 \nz\n\" id=\"DejaVuSans-117\"/>\n      <path d=\"M 18.109375 8.203125 \nL 18.109375 -20.796875 \nL 9.078125 -20.796875 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.390625 \nQ 20.953125 51.265625 25.265625 53.625 \nQ 29.59375 56 35.59375 56 \nQ 45.5625 56 51.78125 48.09375 \nQ 58.015625 40.1875 58.015625 27.296875 \nQ 58.015625 14.40625 51.78125 6.484375 \nQ 45.5625 -1.421875 35.59375 -1.421875 \nQ 29.59375 -1.421875 25.265625 0.953125 \nQ 20.953125 3.328125 18.109375 8.203125 \nz\nM 48.6875 27.296875 \nQ 48.6875 37.203125 44.609375 42.84375 \nQ 40.53125 48.484375 33.40625 48.484375 \nQ 26.265625 48.484375 22.1875 42.84375 \nQ 18.109375 37.203125 18.109375 27.296875 \nQ 18.109375 17.390625 22.1875 11.75 \nQ 26.265625 6.109375 33.40625 6.109375 \nQ 40.53125 6.109375 44.609375 11.75 \nQ 48.6875 17.390625 48.6875 27.296875 \nz\n\" id=\"DejaVuSans-112\"/>\n      <path d=\"M 44.28125 53.078125 \nL 44.28125 44.578125 \nQ 40.484375 46.53125 36.375 47.5 \nQ 32.28125 48.484375 27.875 48.484375 \nQ 21.1875 48.484375 17.84375 46.4375 \nQ 14.5 44.390625 14.5 40.28125 \nQ 14.5 37.15625 16.890625 35.375 \nQ 19.28125 33.59375 26.515625 31.984375 \nL 29.59375 31.296875 \nQ 39.15625 29.25 43.1875 25.515625 \nQ 47.21875 21.78125 47.21875 15.09375 \nQ 47.21875 7.46875 41.1875 3.015625 \nQ 35.15625 -1.421875 24.609375 -1.421875 \nQ 20.21875 -1.421875 15.453125 -0.5625 \nQ 10.6875 0.296875 5.421875 2 \nL 5.421875 11.28125 \nQ 10.40625 8.6875 15.234375 7.390625 \nQ 20.0625 6.109375 24.8125 6.109375 \nQ 31.15625 6.109375 34.5625 8.28125 \nQ 37.984375 10.453125 37.984375 14.40625 \nQ 37.984375 18.0625 35.515625 20.015625 \nQ 33.0625 21.96875 24.703125 23.78125 \nL 21.578125 24.515625 \nQ 13.234375 26.265625 9.515625 29.90625 \nQ 5.8125 33.546875 5.8125 39.890625 \nQ 5.8125 47.609375 11.28125 51.796875 \nQ 16.75 56 26.8125 56 \nQ 31.78125 56 36.171875 55.265625 \nQ 40.578125 54.546875 44.28125 53.078125 \nz\n\" id=\"DejaVuSans-115\"/>\n      <path id=\"DejaVuSans-32\"/>\n      <path d=\"M 37.109375 75.984375 \nL 37.109375 68.5 \nL 28.515625 68.5 \nQ 23.6875 68.5 21.796875 66.546875 \nQ 19.921875 64.59375 19.921875 59.515625 \nL 19.921875 54.6875 \nL 34.71875 54.6875 \nL 34.71875 47.703125 \nL 19.921875 47.703125 \nL 19.921875 0 \nL 10.890625 0 \nL 10.890625 47.703125 \nL 2.296875 47.703125 \nL 2.296875 54.6875 \nL 10.890625 54.6875 \nL 10.890625 58.5 \nQ 10.890625 67.625 15.140625 71.796875 \nQ 19.390625 75.984375 28.609375 75.984375 \nz\n\" id=\"DejaVuSans-102\"/>\n      <path d=\"M 56.203125 29.59375 \nL 56.203125 25.203125 \nL 14.890625 25.203125 \nQ 15.484375 15.921875 20.484375 11.0625 \nQ 25.484375 6.203125 34.421875 6.203125 \nQ 39.59375 6.203125 44.453125 7.46875 \nQ 49.3125 8.734375 54.109375 11.28125 \nL 54.109375 2.78125 \nQ 49.265625 0.734375 44.1875 -0.34375 \nQ 39.109375 -1.421875 33.890625 -1.421875 \nQ 20.796875 -1.421875 13.15625 6.1875 \nQ 5.515625 13.8125 5.515625 26.8125 \nQ 5.515625 40.234375 12.765625 48.109375 \nQ 20.015625 56 32.328125 56 \nQ 43.359375 56 49.78125 48.890625 \nQ 56.203125 41.796875 56.203125 29.59375 \nz\nM 47.21875 32.234375 \nQ 47.125 39.59375 43.09375 43.984375 \nQ 39.0625 48.390625 32.421875 48.390625 \nQ 24.90625 48.390625 20.390625 44.140625 \nQ 15.875 39.890625 15.1875 32.171875 \nz\n\" id=\"DejaVuSans-101\"/>\n      <path d=\"M 54.890625 54.6875 \nL 35.109375 28.078125 \nL 55.90625 0 \nL 45.3125 0 \nL 29.390625 21.484375 \nL 13.484375 0 \nL 2.875 0 \nL 24.125 28.609375 \nL 4.6875 54.6875 \nL 15.28125 54.6875 \nL 29.78125 35.203125 \nL 44.28125 54.6875 \nz\n\" id=\"DejaVuSans-120\"/>\n      <path d=\"M 9.421875 54.6875 \nL 18.40625 54.6875 \nL 18.40625 0 \nL 9.421875 0 \nz\nM 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 64.59375 \nL 9.421875 64.59375 \nz\n\" id=\"DejaVuSans-105\"/>\n      <path d=\"M 52 44.1875 \nQ 55.375 50.25 60.0625 53.125 \nQ 64.75 56 71.09375 56 \nQ 79.640625 56 84.28125 50.015625 \nQ 88.921875 44.046875 88.921875 33.015625 \nL 88.921875 0 \nL 79.890625 0 \nL 79.890625 32.71875 \nQ 79.890625 40.578125 77.09375 44.375 \nQ 74.3125 48.1875 68.609375 48.1875 \nQ 61.625 48.1875 57.5625 43.546875 \nQ 53.515625 38.921875 53.515625 30.90625 \nL 53.515625 0 \nL 44.484375 0 \nL 44.484375 32.71875 \nQ 44.484375 40.625 41.703125 44.40625 \nQ 38.921875 48.1875 33.109375 48.1875 \nQ 26.21875 48.1875 22.15625 43.53125 \nQ 18.109375 38.875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.1875 51.21875 25.484375 53.609375 \nQ 29.78125 56 35.6875 56 \nQ 41.65625 56 45.828125 52.96875 \nQ 50 49.953125 52 44.1875 \nz\n\" id=\"DejaVuSans-109\"/>\n      <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-110\"/>\n      <path d=\"M 18.3125 70.21875 \nL 18.3125 54.6875 \nL 36.8125 54.6875 \nL 36.8125 47.703125 \nL 18.3125 47.703125 \nL 18.3125 18.015625 \nQ 18.3125 11.328125 20.140625 9.421875 \nQ 21.96875 7.515625 27.59375 7.515625 \nL 36.8125 7.515625 \nL 36.8125 0 \nL 27.59375 0 \nQ 17.1875 0 13.234375 3.875 \nQ 9.28125 7.765625 9.28125 18.015625 \nL 9.28125 47.703125 \nL 2.6875 47.703125 \nL 2.6875 54.6875 \nL 9.28125 54.6875 \nL 9.28125 70.21875 \nz\n\" id=\"DejaVuSans-116\"/>\n     </defs>\n     <g transform=\"translate(160.397656 280.096562)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-71\"/>\n      <use x=\"77.490234\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"116.353516\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"177.535156\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"240.914062\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"304.390625\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"356.490234\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"388.277344\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"449.458984\" xlink:href=\"#DejaVuSans-102\"/>\n      <use x=\"484.664062\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"516.451172\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"576.224609\" xlink:href=\"#DejaVuSans-120\"/>\n      <use x=\"635.404297\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"698.880859\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"760.404297\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"801.517578\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"829.300781\" xlink:href=\"#DejaVuSans-109\"/>\n      <use x=\"926.712891\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"988.236328\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"1051.615234\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1090.824219\" xlink:href=\"#DejaVuSans-115\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"mea1259dfd7\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#mea1259dfd7\" y=\"240.700909\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.00 -->\n      <defs>\n       <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n      </defs>\n      <g transform=\"translate(20.878125 244.500128)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#mea1259dfd7\" y=\"212.903182\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.05 -->\n      <g transform=\"translate(20.878125 216.702401)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#mea1259dfd7\" y=\"185.105455\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.10 -->\n      <g transform=\"translate(20.878125 188.904674)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#mea1259dfd7\" y=\"157.307729\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.15 -->\n      <g transform=\"translate(20.878125 161.106947)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#mea1259dfd7\" y=\"129.510002\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.20 -->\n      <g transform=\"translate(20.878125 133.30922)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#mea1259dfd7\" y=\"101.712275\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 0.25 -->\n      <g transform=\"translate(20.878125 105.511494)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#mea1259dfd7\" y=\"73.914548\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 0.30 -->\n      <g transform=\"translate(20.878125 77.713767)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#mea1259dfd7\" y=\"46.116821\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 0.35 -->\n      <g transform=\"translate(20.878125 49.91604)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_9\">\n     <g id=\"line2d_15\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#mea1259dfd7\" y=\"18.319094\"/>\n      </g>\n     </g>\n     <g id=\"text_16\">\n      <!-- 0.40 -->\n      <g transform=\"translate(20.878125 22.118313)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_17\">\n     <!-- Estimated probability -->\n     <defs>\n      <path d=\"M 9.8125 72.90625 \nL 55.90625 72.90625 \nL 55.90625 64.59375 \nL 19.671875 64.59375 \nL 19.671875 43.015625 \nL 54.390625 43.015625 \nL 54.390625 34.71875 \nL 19.671875 34.71875 \nL 19.671875 8.296875 \nL 56.78125 8.296875 \nL 56.78125 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-69\"/>\n      <path d=\"M 34.28125 27.484375 \nQ 23.390625 27.484375 19.1875 25 \nQ 14.984375 22.515625 14.984375 16.5 \nQ 14.984375 11.71875 18.140625 8.90625 \nQ 21.296875 6.109375 26.703125 6.109375 \nQ 34.1875 6.109375 38.703125 11.40625 \nQ 43.21875 16.703125 43.21875 25.484375 \nL 43.21875 27.484375 \nz\nM 52.203125 31.203125 \nL 52.203125 0 \nL 43.21875 0 \nL 43.21875 8.296875 \nQ 40.140625 3.328125 35.546875 0.953125 \nQ 30.953125 -1.421875 24.3125 -1.421875 \nQ 15.921875 -1.421875 10.953125 3.296875 \nQ 6 8.015625 6 15.921875 \nQ 6 25.140625 12.171875 29.828125 \nQ 18.359375 34.515625 30.609375 34.515625 \nL 43.21875 34.515625 \nL 43.21875 35.40625 \nQ 43.21875 41.609375 39.140625 45 \nQ 35.0625 48.390625 27.6875 48.390625 \nQ 23 48.390625 18.546875 47.265625 \nQ 14.109375 46.140625 10.015625 43.890625 \nL 10.015625 52.203125 \nQ 14.9375 54.109375 19.578125 55.046875 \nQ 24.21875 56 28.609375 56 \nQ 40.484375 56 46.34375 49.84375 \nQ 52.203125 43.703125 52.203125 31.203125 \nz\n\" id=\"DejaVuSans-97\"/>\n      <path d=\"M 45.40625 46.390625 \nL 45.40625 75.984375 \nL 54.390625 75.984375 \nL 54.390625 0 \nL 45.40625 0 \nL 45.40625 8.203125 \nQ 42.578125 3.328125 38.25 0.953125 \nQ 33.9375 -1.421875 27.875 -1.421875 \nQ 17.96875 -1.421875 11.734375 6.484375 \nQ 5.515625 14.40625 5.515625 27.296875 \nQ 5.515625 40.1875 11.734375 48.09375 \nQ 17.96875 56 27.875 56 \nQ 33.9375 56 38.25 53.625 \nQ 42.578125 51.265625 45.40625 46.390625 \nz\nM 14.796875 27.296875 \nQ 14.796875 17.390625 18.875 11.75 \nQ 22.953125 6.109375 30.078125 6.109375 \nQ 37.203125 6.109375 41.296875 11.75 \nQ 45.40625 17.390625 45.40625 27.296875 \nQ 45.40625 37.203125 41.296875 42.84375 \nQ 37.203125 48.484375 30.078125 48.484375 \nQ 22.953125 48.484375 18.875 42.84375 \nQ 14.796875 37.203125 14.796875 27.296875 \nz\n\" id=\"DejaVuSans-100\"/>\n      <path d=\"M 48.6875 27.296875 \nQ 48.6875 37.203125 44.609375 42.84375 \nQ 40.53125 48.484375 33.40625 48.484375 \nQ 26.265625 48.484375 22.1875 42.84375 \nQ 18.109375 37.203125 18.109375 27.296875 \nQ 18.109375 17.390625 22.1875 11.75 \nQ 26.265625 6.109375 33.40625 6.109375 \nQ 40.53125 6.109375 44.609375 11.75 \nQ 48.6875 17.390625 48.6875 27.296875 \nz\nM 18.109375 46.390625 \nQ 20.953125 51.265625 25.265625 53.625 \nQ 29.59375 56 35.59375 56 \nQ 45.5625 56 51.78125 48.09375 \nQ 58.015625 40.1875 58.015625 27.296875 \nQ 58.015625 14.40625 51.78125 6.484375 \nQ 45.5625 -1.421875 35.59375 -1.421875 \nQ 29.59375 -1.421875 25.265625 0.953125 \nQ 20.953125 3.328125 18.109375 8.203125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 75.984375 \nL 18.109375 75.984375 \nz\n\" id=\"DejaVuSans-98\"/>\n      <path d=\"M 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 0 \nL 9.421875 0 \nz\n\" id=\"DejaVuSans-108\"/>\n      <path d=\"M 32.171875 -5.078125 \nQ 28.375 -14.84375 24.75 -17.8125 \nQ 21.140625 -20.796875 15.09375 -20.796875 \nL 7.90625 -20.796875 \nL 7.90625 -13.28125 \nL 13.1875 -13.28125 \nQ 16.890625 -13.28125 18.9375 -11.515625 \nQ 21 -9.765625 23.484375 -3.21875 \nL 25.09375 0.875 \nL 2.984375 54.6875 \nL 12.5 54.6875 \nL 29.59375 11.921875 \nL 46.6875 54.6875 \nL 56.203125 54.6875 \nz\n\" id=\"DejaVuSans-121\"/>\n     </defs>\n     <g transform=\"translate(14.798438 183.033437)rotate(-90)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"63.183594\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"115.283203\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"154.492188\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"182.275391\" xlink:href=\"#DejaVuSans-109\"/>\n      <use x=\"279.6875\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"340.966797\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"380.175781\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"441.699219\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"505.175781\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"536.962891\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"600.439453\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"639.302734\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"700.484375\" xlink:href=\"#DejaVuSans-98\"/>\n      <use x=\"763.960938\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"825.240234\" xlink:href=\"#DejaVuSans-98\"/>\n      <use x=\"888.716797\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"916.5\" xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"944.283203\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"972.066406\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1011.275391\" xlink:href=\"#DejaVuSans-121\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_16\">\n    <path clip-path=\"url(#pc07f75842b)\" d=\"M 65.361932 129.51 \nL 65.971879 185.105455 \nL 66.581826 166.573634 \nL 67.191773 157.307725 \nL 67.80172 140.629088 \nL 68.411668 157.307725 \nL 69.021615 153.336622 \nL 69.631562 143.408867 \nL 70.241509 154.219089 \nL 71.461403 159.834797 \nL 72.681298 155.169439 \nL 73.901192 159.160914 \nL 74.511139 160.782446 \nL 75.121086 155.672565 \nL 75.731034 154.219089 \nL 76.340981 147.066457 \nL 76.950928 146.188637 \nL 77.560875 148.041817 \nL 78.170822 139.618263 \nL 79.390717 138.775908 \nL 80.000664 140.629088 \nL 80.610611 140.201433 \nL 81.220558 143.923641 \nL 81.830505 143.408867 \nL 82.440452 144.846677 \nL 83.0504 144.335457 \nL 83.660347 145.650617 \nL 84.270294 141.67151 \nL 85.490188 140.956122 \nL 86.100135 137.452207 \nL 86.710083 137.231594 \nL 87.32003 140.028058 \nL 87.929977 141.214304 \nL 88.539924 140.914195 \nL 89.149871 142.018982 \nL 89.759819 141.713885 \nL 90.979713 138.560424 \nL 91.58966 140.881803 \nL 92.809554 137.970179 \nL 94.029449 137.617671 \nL 94.639396 135.183011 \nL 95.249343 137.293363 \nL 95.85929 137.140748 \nL 96.469237 135.92486 \nL 97.079185 136.8528 \nL 97.689132 135.687272 \nL 98.299079 136.585787 \nL 98.909026 134.473877 \nL 99.518973 134.386792 \nL 100.12892 135.261257 \nL 100.738868 133.279189 \nL 101.348815 134.142958 \nL 101.958762 135.889809 \nL 102.568709 135.786908 \nL 103.178656 136.56974 \nL 104.398551 139.773777 \nL 105.008498 139.618263 \nL 105.618445 140.297175 \nL 106.838339 139.984507 \nL 107.448286 141.423311 \nL 108.668181 141.092392 \nL 109.278128 139.410566 \nL 110.498022 140.629088 \nL 111.107969 138.288232 \nL 113.547758 140.629088 \nL 114.157705 140.491816 \nL 114.767652 139.679899 \nL 115.3776 139.557373 \nL 115.987547 138.775908 \nL 117.207441 141.146257 \nL 117.817388 139.734451 \nL 118.427335 138.986497 \nL 120.257177 138.674085 \nL 120.867124 137.970179 \nL 121.477071 137.879208 \nL 122.087018 137.198739 \nL 122.696966 138.288232 \nL 123.306913 138.775908 \nL 123.91686 138.107236 \nL 124.526807 138.586809 \nL 125.136754 139.618263 \nL 125.746701 139.517185 \nL 126.356649 139.968551 \nL 126.966596 140.956122 \nL 128.18649 141.805154 \nL 128.796437 142.747012 \nL 129.406384 142.09765 \nL 131.236226 141.751206 \nL 131.846173 142.650748 \nL 133.676015 142.301876 \nL 134.285962 141.701989 \nL 134.895909 140.629088 \nL 135.505856 141.012506 \nL 136.115803 140.914195 \nL 136.72575 141.759847 \nL 137.335698 141.189716 \nL 137.945645 141.555687 \nL 138.555592 142.375069 \nL 139.775486 142.16588 \nL 140.385433 142.960517 \nL 140.995381 142.408148 \nL 141.605328 142.305778 \nL 142.215275 141.767269 \nL 142.825222 141.67151 \nL 143.435169 142.008204 \nL 144.045116 142.767375 \nL 145.265011 142.566512 \nL 145.874958 142.886355 \nL 146.484905 143.616307 \nL 147.094852 142.688185 \nL 147.704799 142.182499 \nL 148.314747 142.901607 \nL 148.924694 142.401703 \nL 149.534641 142.70892 \nL 150.754535 144.09888 \nL 151.97443 144.672399 \nL 153.194324 144.46326 \nL 153.804271 145.122422 \nL 154.414218 144.259812 \nL 155.024165 144.535798 \nL 155.634113 144.061832 \nL 156.24406 144.335457 \nL 156.854007 143.869088 \nL 157.463954 144.506148 \nL 158.073901 144.408127 \nL 158.683848 145.033406 \nL 159.293796 144.215897 \nL 159.903743 144.121629 \nL 160.51369 144.382669 \nL 161.123637 144.992283 \nL 161.733584 144.894908 \nL 163.563426 145.639549 \nL 165.393267 145.346282 \nL 166.003214 145.585792 \nL 166.613162 145.156628 \nL 167.223109 145.394414 \nL 167.833056 145.300428 \nL 168.443003 145.534578 \nL 169.662897 145.348237 \nL 170.272845 145.899413 \nL 173.932528 147.213579 \nL 175.152422 148.24659 \nL 175.762369 148.449109 \nL 176.372316 148.345621 \nL 176.982263 148.545399 \nL 177.592211 148.442507 \nL 178.202158 148.639617 \nL 178.812105 148.537321 \nL 179.422052 148.73183 \nL 180.031999 148.630131 \nL 180.641946 148.236889 \nL 183.081735 148.997071 \nL 183.691682 148.61203 \nL 184.301629 148.798221 \nL 185.521524 148.041817 \nL 186.131471 148.50744 \nL 187.351365 148.318415 \nL 188.57126 148.680848 \nL 189.181207 148.58687 \nL 189.791154 148.765009 \nL 190.401101 149.211304 \nL 191.011048 148.847554 \nL 191.620995 149.021866 \nL 193.450837 147.953994 \nL 194.670731 148.824855 \nL 195.280678 148.994387 \nL 196.500573 148.813978 \nL 198.330414 149.311123 \nL 198.940361 149.726534 \nL 200.160256 150.045259 \nL 200.770203 149.95317 \nL 201.990097 150.759819 \nL 202.600044 150.665791 \nL 203.819939 150.967897 \nL 204.429886 151.359739 \nL 205.64978 151.651912 \nL 206.259727 152.035744 \nL 206.869675 151.461853 \nL 207.479622 151.36804 \nL 208.089569 151.511608 \nL 208.699516 151.889525 \nL 209.309463 152.02968 \nL 209.91941 151.701461 \nL 210.529358 151.841227 \nL 211.139305 151.516538 \nL 212.359199 151.79413 \nL 212.969146 152.160001 \nL 214.798988 152.561776 \nL 216.018882 153.272575 \nL 216.628829 153.177139 \nL 217.238776 152.637711 \nL 217.848724 152.545572 \nL 218.458671 152.01292 \nL 219.068618 151.704237 \nL 219.678565 151.616853 \nL 220.288512 151.748185 \nL 220.898459 151.444149 \nL 221.508407 151.791446 \nL 222.728301 152.048701 \nL 223.338248 151.748185 \nL 223.948195 151.875988 \nL 224.558142 151.366226 \nL 225.16809 150.648957 \nL 225.778037 150.568889 \nL 226.387984 150.909003 \nL 228.217825 151.291799 \nL 228.827773 151.624176 \nL 229.43772 151.748185 \nL 230.047667 151.66612 \nL 231.267561 151.911097 \nL 231.877508 151.829347 \nL 232.487456 152.152512 \nL 233.70735 151.587618 \nL 234.317297 151.508204 \nL 234.927244 151.628625 \nL 236.147139 152.262586 \nL 237.367033 152.494698 \nL 238.586927 152.333401 \nL 239.196874 152.447982 \nL 241.026716 152.209873 \nL 241.636663 151.939894 \nL 242.24661 152.053862 \nL 242.856557 151.97666 \nL 243.466505 152.27947 \nL 244.076452 152.391127 \nL 244.686399 151.748185 \nL 245.296346 151.673054 \nL 245.906293 151.785622 \nL 246.51624 152.083992 \nL 247.126188 151.822562 \nL 247.736135 151.748185 \nL 248.346082 151.859005 \nL 248.956029 151.600914 \nL 249.565976 151.711485 \nL 250.175923 151.272696 \nL 251.395818 151.493822 \nL 252.005765 151.42222 \nL 252.615712 151.712082 \nL 253.225659 151.820151 \nL 253.835606 152.106865 \nL 254.445554 152.212971 \nL 255.055501 151.962013 \nL 255.665448 152.067904 \nL 256.275395 151.819008 \nL 256.885342 151.748185 \nL 257.495289 151.150004 \nL 258.715184 151.0139 \nL 259.325131 150.772212 \nL 260.545025 151.332517 \nL 261.154972 151.092088 \nL 261.76492 151.197391 \nL 262.374867 151.130453 \nL 262.984814 150.721802 \nL 264.204708 151.27214 \nL 265.424603 151.477808 \nL 266.03455 151.242772 \nL 267.254444 151.446758 \nL 267.864391 151.380889 \nL 268.474338 151.648309 \nL 269.084286 151.416272 \nL 270.30418 151.616207 \nL 270.914127 151.386316 \nL 271.524074 151.649783 \nL 272.134021 151.584668 \nL 272.743969 151.846007 \nL 273.353916 151.780693 \nL 274.57381 152.297671 \nL 275.183757 152.231619 \nL 277.013599 151.556477 \nL 277.623546 151.493308 \nL 278.233493 151.748185 \nL 278.84344 151.684826 \nL 279.453387 151.779773 \nL 280.673282 152.282154 \nL 281.283229 152.061401 \nL 281.893176 151.99805 \nL 282.503123 152.090785 \nL 283.11307 151.561828 \nL 283.723018 151.500408 \nL 284.332965 151.748185 \nL 284.942912 151.686583 \nL 285.552859 151.471744 \nL 286.162806 150.951776 \nL 287.382701 150.834287 \nL 287.992648 150.624121 \nL 288.602595 150.718074 \nL 289.212542 150.660448 \nL 289.822489 150.904455 \nL 291.652331 150.731925 \nL 292.872225 151.21304 \nL 293.482172 151.155165 \nL 294.092119 150.949738 \nL 294.702067 151.187806 \nL 295.921961 151.366789 \nL 296.531908 151.016667 \nL 298.36175 151.283681 \nL 299.581644 151.170566 \nL 300.191591 150.970424 \nL 300.801538 150.914968 \nL 302.021433 150.519083 \nL 302.63138 150.46521 \nL 303.241327 150.553803 \nL 304.461221 150.446711 \nL 305.071168 150.252467 \nL 306.291063 150.428494 \nL 306.90101 150.655883 \nL 307.510957 150.742438 \nL 308.120904 150.549884 \nL 308.730851 150.497287 \nL 309.340799 150.583594 \nL 309.950746 150.392871 \nL 310.560693 150.479003 \nL 311.17064 150.702325 \nL 311.780587 150.375457 \nL 312.390534 150.461001 \nL 313.000482 150.272921 \nL 313.610429 150.3583 \nL 314.830323 150.798995 \nL 315.44027 150.611926 \nL 316.050217 150.695648 \nL 316.660165 150.644351 \nL 317.880059 151.078361 \nL 318.490006 151.026509 \nL 319.099953 151.241555 \nL 320.319848 151.403199 \nL 320.929795 151.218706 \nL 322.149689 151.642791 \nL 322.759636 151.721899 \nL 323.369583 151.407267 \nL 323.979531 151.486557 \nL 324.589478 151.43497 \nL 325.199425 151.51382 \nL 325.809372 151.462416 \nL 326.419319 151.281651 \nL 327.029266 151.360311 \nL 328.249161 151.259151 \nL 328.859108 151.337314 \nL 329.469055 151.287019 \nL 330.079002 150.981351 \nL 330.688949 151.187126 \nL 331.298897 151.137528 \nL 331.908844 150.834287 \nL 332.518791 150.659072 \nL 334.348632 150.892866 \nL 334.95858 150.719101 \nL 336.178474 150.873646 \nL 336.788421 151.075055 \nL 337.398368 151.151189 \nL 338.008315 151.102883 \nL 339.22821 151.253998 \nL 339.838157 151.08252 \nL 340.448104 150.788789 \nL 341.667998 150.93997 \nL 342.277946 150.770679 \nL 342.887893 150.724055 \nL 343.49784 150.799285 \nL 344.107787 150.510028 \nL 344.717734 150.585399 \nL 345.327681 150.418726 \nL 345.937629 150.011583 \nL 347.157523 150.16317 \nL 347.76747 149.998841 \nL 348.377417 149.954785 \nL 348.987365 150.149517 \nL 349.597312 149.986274 \nL 350.207259 150.180103 \nL 350.817206 150.254572 \nL 351.427153 150.210432 \nL 352.0371 150.28452 \nL 352.647048 150.240513 \nL 353.256995 150.431758 \nL 355.086836 150.650291 \nL 356.306731 150.561839 \nL 356.916678 150.633954 \nL 357.526625 150.589948 \nL 358.136572 150.777282 \nL 359.356466 150.689219 \nL 360.576361 150.945778 \nL 361.796255 151.314382 \nL 362.406202 151.269697 \nL 363.016149 151.338888 \nL 364.236044 151.249972 \nL 364.845991 150.979793 \nL 365.455938 151.049009 \nL 366.065885 150.892866 \nL 367.28578 151.030825 \nL 367.895727 150.875659 \nL 369.725568 151.303422 \nL 369.725568 151.303422 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_17\">\n    <path clip-path=\"url(#pc07f75842b)\" d=\"M 65.361932 240.700909 \nL 66.581826 129.51 \nL 68.411668 129.51 \nL 69.021615 137.452207 \nL 69.631562 150.3583 \nL 70.241509 148.041817 \nL 70.851456 157.307725 \nL 72.071351 161.940684 \nL 72.681298 159.446012 \nL 73.291245 161.278829 \nL 73.901192 148.041817 \nL 74.511139 153.833013 \nL 75.121086 152.402244 \nL 75.731034 154.219089 \nL 76.340981 158.770769 \nL 77.560875 155.984024 \nL 78.170822 159.834797 \nL 78.780769 158.516323 \nL 79.390717 154.99125 \nL 80.610611 144.478006 \nL 81.220558 148.041817 \nL 81.830505 145.394414 \nL 82.440452 148.680848 \nL 83.0504 146.188637 \nL 84.270294 145.146223 \nL 85.490188 147.496763 \nL 86.100135 145.394414 \nL 86.710083 141.864545 \nL 87.32003 141.530643 \nL 88.539924 138.063146 \nL 89.759819 137.645921 \nL 90.979713 139.85334 \nL 91.58966 137.091199 \nL 92.199607 138.158184 \nL 92.809554 140.387375 \nL 93.419502 140.155943 \nL 94.029449 141.092392 \nL 94.639396 139.721412 \nL 95.85929 139.320962 \nL 96.469237 141.27058 \nL 97.079185 142.09765 \nL 97.689132 140.835005 \nL 98.299079 140.629088 \nL 98.909026 141.423311 \nL 99.518973 140.238953 \nL 100.738868 141.759847 \nL 101.348815 140.629088 \nL 101.958762 140.446816 \nL 102.568709 139.373708 \nL 103.178656 139.217142 \nL 103.788603 139.934146 \nL 104.398551 138.918466 \nL 105.008498 140.460618 \nL 105.618445 138.637617 \nL 106.228392 139.320962 \nL 107.448286 139.040652 \nL 108.668181 140.320231 \nL 109.888075 140.028058 \nL 110.498022 141.370365 \nL 111.107969 141.945831 \nL 111.717917 141.062303 \nL 112.327864 138.775908 \nL 112.937811 138.658618 \nL 113.547758 139.239203 \nL 114.157705 139.119088 \nL 115.3776 140.227197 \nL 115.987547 139.437763 \nL 116.597494 140.629088 \nL 117.207441 139.85334 \nL 117.817388 139.734451 \nL 118.427335 138.986497 \nL 119.037283 139.504693 \nL 119.64723 140.629088 \nL 120.257177 140.506902 \nL 120.867124 140.99167 \nL 121.477071 140.270408 \nL 122.087018 140.155943 \nL 124.526807 137.452207 \nL 125.136754 136.248845 \nL 125.746701 136.737407 \nL 126.356649 136.1154 \nL 126.966596 136.050641 \nL 127.576543 137.066669 \nL 128.18649 136.459433 \nL 128.796437 136.39325 \nL 130.016332 137.30376 \nL 130.626279 137.231594 \nL 131.846173 136.080374 \nL 132.45612 136.021182 \nL 133.066067 136.459433 \nL 134.285962 138.288232 \nL 135.505856 138.136885 \nL 136.115803 137.587971 \nL 136.72575 137.990666 \nL 137.335698 138.853773 \nL 137.945645 139.239203 \nL 138.555592 138.699336 \nL 139.165539 139.079713 \nL 139.775486 139.905896 \nL 140.385433 139.373708 \nL 140.995381 139.739563 \nL 141.605328 138.334675 \nL 142.215275 138.702948 \nL 144.045116 138.490802 \nL 144.655064 137.997857 \nL 145.874958 137.87022 \nL 146.484905 137.392941 \nL 147.094852 137.334544 \nL 148.314747 138.843542 \nL 150.144588 138.643541 \nL 150.754535 137.790176 \nL 151.364482 138.123382 \nL 151.97443 137.674369 \nL 153.194324 137.56176 \nL 153.804271 136.364238 \nL 154.414218 136.317605 \nL 155.024165 136.647257 \nL 155.634113 137.345604 \nL 156.854007 137.978182 \nL 157.463954 137.556715 \nL 158.073901 137.504117 \nL 158.683848 136.730191 \nL 159.293796 136.683608 \nL 159.903743 137.350384 \nL 160.51369 137.300446 \nL 161.123637 136.547397 \nL 161.733584 136.503142 \nL 162.953479 135.725645 \nL 163.563426 136.030452 \nL 165.393267 135.911903 \nL 166.003214 135.538427 \nL 167.223109 136.128506 \nL 168.443003 136.050641 \nL 169.05295 136.662632 \nL 169.662897 136.944276 \nL 170.272845 136.901305 \nL 171.492739 138.087585 \nL 172.102686 138.038848 \nL 172.712633 138.30476 \nL 173.32258 138.880018 \nL 173.932528 138.517088 \nL 175.152422 139.031879 \nL 176.372316 138.927811 \nL 177.592211 139.427027 \nL 178.202158 139.373708 \nL 178.812105 139.618263 \nL 179.422052 139.268779 \nL 180.031999 139.511303 \nL 180.641946 139.458665 \nL 181.251894 138.824422 \nL 181.861841 139.065472 \nL 182.471788 138.7279 \nL 183.691682 138.633359 \nL 184.301629 138.303161 \nL 184.911577 138.540732 \nL 186.131471 138.449977 \nL 188.57126 139.369293 \nL 189.181207 139.866015 \nL 189.791154 139.5443 \nL 190.401101 139.495596 \nL 191.011048 139.984507 \nL 192.230943 139.884274 \nL 192.84089 140.364353 \nL 193.450837 140.049423 \nL 194.060784 139.999708 \nL 194.670731 140.472489 \nL 195.280678 140.681048 \nL 197.11052 140.526611 \nL 197.720467 139.966024 \nL 198.330414 139.664423 \nL 198.940361 139.870969 \nL 199.550309 139.572525 \nL 200.160256 139.777629 \nL 200.770203 140.230204 \nL 201.38015 140.182346 \nL 201.990097 139.393641 \nL 202.600044 139.595903 \nL 203.209992 140.041296 \nL 203.819939 140.238953 \nL 204.429886 139.463776 \nL 205.039833 139.662212 \nL 205.64978 139.377594 \nL 206.259727 139.335062 \nL 208.089569 139.919367 \nL 208.699516 139.875252 \nL 210.529358 140.442997 \nL 211.139305 140.397441 \nL 211.749252 140.582953 \nL 212.359199 140.996666 \nL 212.969146 140.720606 \nL 213.579093 140.218962 \nL 214.189041 139.948329 \nL 214.798988 139.905896 \nL 216.018882 139.373708 \nL 216.628829 138.887549 \nL 217.848724 139.255822 \nL 218.458671 139.658376 \nL 220.288512 140.193049 \nL 221.508407 140.109915 \nL 222.118354 140.284318 \nL 222.728301 140.672026 \nL 224.558142 140.544215 \nL 225.778037 141.30298 \nL 226.387984 141.46827 \nL 226.997931 141.423311 \nL 228.217825 141.749301 \nL 228.827773 141.497125 \nL 229.43772 141.658637 \nL 230.047667 141.61381 \nL 230.657614 141.978098 \nL 232.487456 141.842086 \nL 233.097403 142.200269 \nL 233.70735 141.953751 \nL 234.317297 141.90899 \nL 234.927244 142.063817 \nL 235.537191 142.018982 \nL 236.757086 142.324559 \nL 237.97698 141.842798 \nL 238.586927 141.994593 \nL 239.196874 141.75655 \nL 239.806822 141.90759 \nL 240.416769 141.478468 \nL 241.026716 141.821797 \nL 241.636663 141.971048 \nL 242.24661 141.928226 \nL 242.856557 142.266494 \nL 243.466505 142.033206 \nL 244.076452 141.61241 \nL 244.686399 141.382933 \nL 245.296346 141.34282 \nL 246.51624 141.636526 \nL 247.126188 141.967842 \nL 247.736135 141.926321 \nL 250.785871 142.634171 \nL 252.615712 141.964827 \nL 253.225659 142.104443 \nL 253.835606 142.063817 \nL 254.445554 141.844687 \nL 255.665448 141.765869 \nL 256.275395 141.903895 \nL 256.885342 142.217533 \nL 258.105237 142.488117 \nL 258.715184 142.09765 \nL 259.325131 142.23247 \nL 260.545025 141.460425 \nL 261.154972 141.595974 \nL 261.76492 141.902793 \nL 262.984814 141.826536 \nL 263.594761 141.618217 \nL 264.204708 141.071134 \nL 265.424603 141.000858 \nL 266.03455 141.30298 \nL 266.644497 141.267349 \nL 267.254444 141.566846 \nL 267.864391 141.530643 \nL 268.474338 141.661105 \nL 269.694233 142.250629 \nL 270.914127 142.175241 \nL 271.524074 141.973882 \nL 272.134021 141.937223 \nL 272.743969 142.063817 \nL 273.353916 142.027109 \nL 274.57381 142.277562 \nL 275.183757 142.240555 \nL 275.793704 142.525123 \nL 276.403652 142.647832 \nL 278.84344 142.498116 \nL 279.453387 142.303276 \nL 280.063335 142.267032 \nL 283.11307 142.865338 \nL 283.723018 142.673273 \nL 284.332965 142.791135 \nL 284.942912 142.754352 \nL 287.992648 143.332916 \nL 289.212542 142.955637 \nL 289.822489 142.919203 \nL 290.432436 143.03322 \nL 292.262278 142.477306 \nL 292.872225 142.442636 \nL 293.482172 142.556405 \nL 294.702067 142.192258 \nL 295.312014 141.864545 \nL 295.921961 141.978637 \nL 297.141855 141.91319 \nL 297.751802 141.589644 \nL 298.36175 141.848415 \nL 298.971697 141.67151 \nL 299.581644 141.928724 \nL 300.191591 141.752523 \nL 300.801538 141.720885 \nL 301.411485 141.832708 \nL 302.021433 142.086864 \nL 302.63138 141.912064 \nL 303.241327 142.16472 \nL 304.461221 142.100318 \nL 305.071168 142.209472 \nL 305.681116 142.177321 \nL 306.291063 142.00494 \nL 306.90101 141.693389 \nL 307.510957 141.523088 \nL 309.340799 142.265069 \nL 310.560693 142.477679 \nL 311.17064 142.7208 \nL 311.780587 142.688185 \nL 312.390534 142.792659 \nL 313.000482 143.03322 \nL 313.610429 143.136336 \nL 314.830323 143.06987 \nL 316.050217 143.273923 \nL 316.660165 142.836757 \nL 317.880059 143.308394 \nL 318.490006 143.408867 \nL 319.099953 143.37553 \nL 319.7099 143.209363 \nL 320.319848 143.176664 \nL 321.539742 143.375854 \nL 322.149689 143.211251 \nL 322.759636 142.915997 \nL 323.369583 143.0155 \nL 324.589478 142.691084 \nL 325.199425 142.790414 \nL 325.809372 142.759389 \nL 326.419319 142.858097 \nL 327.029266 142.827056 \nL 327.639214 142.925142 \nL 328.249161 142.636706 \nL 328.859108 142.734784 \nL 329.469055 142.704314 \nL 330.079002 142.801788 \nL 330.688949 142.771302 \nL 331.298897 142.868179 \nL 331.908844 143.091542 \nL 332.518791 142.933957 \nL 333.128738 143.15616 \nL 333.738685 142.999147 \nL 334.95858 143.189248 \nL 335.568527 143.158439 \nL 336.178474 143.252698 \nL 336.788421 143.097234 \nL 337.398368 143.066838 \nL 338.008315 142.912476 \nL 338.618263 143.006445 \nL 339.22821 142.852911 \nL 339.838157 142.946599 \nL 340.448104 142.916866 \nL 341.058051 142.76455 \nL 341.667998 142.735356 \nL 342.277946 142.950658 \nL 342.887893 143.043104 \nL 343.49784 143.013495 \nL 344.717734 143.196903 \nL 345.327681 143.046285 \nL 345.937629 143.258116 \nL 346.547576 143.348697 \nL 347.157523 143.198734 \nL 347.76747 143.169233 \nL 348.987365 142.871998 \nL 350.817206 142.786528 \nL 352.0371 143.202304 \nL 352.647048 143.173292 \nL 353.256995 143.261943 \nL 355.086836 142.357688 \nL 356.916678 142.625422 \nL 357.526625 142.482277 \nL 358.136572 142.455303 \nL 358.746519 142.543788 \nL 359.356466 142.516806 \nL 359.966414 142.375069 \nL 360.576361 142.463173 \nL 361.186308 142.436514 \nL 361.796255 142.638288 \nL 362.406202 142.497462 \nL 363.626097 142.784838 \nL 364.845991 142.617875 \nL 365.455938 142.704058 \nL 366.675832 142.650748 \nL 368.505674 142.23667 \nL 369.725568 142.408148 \nL 369.725568 142.408148 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_18\">\n    <path clip-path=\"url(#pc07f75842b)\" d=\"M 65.361932 185.105455 \nL 66.581826 185.105455 \nL 67.191773 171.206592 \nL 67.80172 162.867274 \nL 68.411668 157.307725 \nL 69.021615 137.452207 \nL 69.631562 129.51 \nL 70.241509 141.864545 \nL 71.461403 139.618263 \nL 72.071351 134.142958 \nL 72.681298 142.339719 \nL 73.291245 141.423311 \nL 73.901192 144.335457 \nL 75.121086 142.591282 \nL 75.731034 144.953181 \nL 76.340981 149.992537 \nL 76.950928 151.748185 \nL 78.170822 149.726534 \nL 78.780769 146.430358 \nL 79.390717 148.041817 \nL 80.000664 145.076725 \nL 80.610611 146.616292 \nL 81.220558 143.923641 \nL 81.830505 145.394414 \nL 82.440452 144.846677 \nL 83.0504 148.041817 \nL 84.270294 150.3583 \nL 85.490188 149.131924 \nL 86.710083 154.219089 \nL 87.32003 150.546123 \nL 88.539924 152.31839 \nL 89.149871 151.748185 \nL 89.759819 152.561776 \nL 90.369766 152.01292 \nL 92.199607 154.219089 \nL 92.809554 153.681939 \nL 93.419502 151.984762 \nL 94.639396 153.336622 \nL 95.249343 151.748185 \nL 97.079185 153.636333 \nL 97.689132 153.189549 \nL 98.299079 151.748185 \nL 98.909026 153.336622 \nL 99.518973 153.893969 \nL 100.12892 151.556477 \nL 101.348815 152.674775 \nL 101.958762 152.29502 \nL 102.568709 153.720925 \nL 103.178656 154.219089 \nL 104.398551 150.037554 \nL 105.618445 151.084359 \nL 106.228392 149.949508 \nL 106.838339 150.459013 \nL 107.448286 149.365518 \nL 109.278128 150.834287 \nL 110.498022 150.265639 \nL 111.107969 150.724055 \nL 111.717917 149.726534 \nL 112.327864 150.180103 \nL 112.937811 151.325939 \nL 113.547758 151.748185 \nL 114.157705 150.787273 \nL 115.3776 151.614219 \nL 115.987547 152.674775 \nL 117.817388 151.875988 \nL 118.427335 152.253598 \nL 119.64723 150.512729 \nL 120.257177 149.060048 \nL 120.867124 149.451849 \nL 121.477071 150.433025 \nL 122.087018 150.801878 \nL 122.696966 149.992537 \nL 125.136754 149.164962 \nL 125.746701 148.412459 \nL 126.356649 148.225299 \nL 126.966596 148.58687 \nL 127.576543 147.322137 \nL 128.18649 147.150866 \nL 128.796437 147.512338 \nL 129.406384 146.818017 \nL 130.626279 148.556591 \nL 131.236226 147.871805 \nL 131.846173 148.210288 \nL 132.45612 149.043538 \nL 133.676015 149.681807 \nL 134.285962 149.504861 \nL 134.895909 149.814431 \nL 135.505856 148.680848 \nL 136.115803 148.516992 \nL 136.72575 148.827067 \nL 138.555592 148.348131 \nL 139.165539 149.105124 \nL 139.775486 148.493812 \nL 140.385433 148.789067 \nL 140.995381 147.745311 \nL 141.605328 148.483051 \nL 142.825222 147.31792 \nL 143.435169 148.041817 \nL 144.045116 147.899268 \nL 144.655064 148.607681 \nL 145.265011 148.884171 \nL 145.874958 147.902482 \nL 146.484905 148.180116 \nL 147.704799 147.08798 \nL 148.924694 147.638956 \nL 149.534641 146.708597 \nL 150.144588 146.982859 \nL 150.754535 146.858942 \nL 151.364482 147.128283 \nL 153.194324 146.763762 \nL 155.024165 148.667891 \nL 155.634113 148.539318 \nL 156.24406 148.041817 \nL 156.854007 148.287274 \nL 157.463954 148.163738 \nL 158.073901 148.405186 \nL 158.683848 147.921486 \nL 159.293796 148.161377 \nL 159.903743 147.329055 \nL 162.343531 148.273464 \nL 162.953479 148.847554 \nL 163.563426 148.041817 \nL 164.173373 147.587055 \nL 164.78332 147.476823 \nL 166.003214 147.930185 \nL 166.613162 148.485693 \nL 167.833056 148.261129 \nL 169.05295 147.391577 \nL 169.662897 147.610847 \nL 170.272845 147.184857 \nL 170.882792 147.083274 \nL 172.102686 146.251813 \nL 172.712633 146.157231 \nL 173.32258 146.376037 \nL 174.542475 146.188637 \nL 175.152422 145.78933 \nL 176.372316 146.826616 \nL 177.592211 146.639414 \nL 178.202158 145.949517 \nL 179.422052 146.366071 \nL 180.031999 146.865196 \nL 180.641946 146.773853 \nL 182.471788 147.369681 \nL 183.081735 146.991044 \nL 183.691682 147.471612 \nL 184.301629 147.096322 \nL 184.911577 146.442627 \nL 185.521524 146.357108 \nL 186.131471 145.713702 \nL 187.351365 145.552472 \nL 187.961312 144.922603 \nL 188.57126 145.12055 \nL 189.181207 145.58908 \nL 189.791154 145.510644 \nL 190.401101 145.97273 \nL 191.011048 145.8932 \nL 191.620995 146.081727 \nL 192.230943 145.736426 \nL 192.84089 145.923902 \nL 193.450837 146.37308 \nL 194.060784 146.555775 \nL 195.280678 145.876888 \nL 195.890626 146.059343 \nL 196.500573 145.982729 \nL 197.720467 145.321553 \nL 198.330414 145.503213 \nL 198.940361 144.925105 \nL 200.770203 144.717731 \nL 201.38015 143.90525 \nL 201.990097 143.841278 \nL 203.819939 142.921183 \nL 205.039833 142.804564 \nL 205.64978 143.228359 \nL 206.869675 143.587817 \nL 207.479622 143.290069 \nL 208.699516 143.173292 \nL 209.309463 143.584802 \nL 209.91941 143.52566 \nL 210.529358 143.932257 \nL 211.749252 144.273937 \nL 212.359199 143.983197 \nL 212.969146 143.923641 \nL 213.579093 144.092418 \nL 214.189041 144.486738 \nL 214.798988 144.199858 \nL 215.408935 144.365471 \nL 216.018882 144.305567 \nL 216.628829 144.692695 \nL 217.238776 144.409585 \nL 217.848724 143.907229 \nL 219.678565 145.050464 \nL 220.288512 144.989524 \nL 220.898459 145.146223 \nL 221.508407 145.085383 \nL 222.118354 145.240499 \nL 222.728301 145.609071 \nL 223.338248 145.760981 \nL 223.948195 146.124731 \nL 224.558142 146.273518 \nL 225.16809 146.209778 \nL 225.778037 145.93593 \nL 228.217825 146.52055 \nL 228.827773 146.870664 \nL 229.43772 146.806369 \nL 230.047667 147.152838 \nL 230.657614 147.292371 \nL 231.267561 147.227231 \nL 233.097403 147.638956 \nL 233.70735 147.974921 \nL 234.317297 147.908496 \nL 235.537191 148.174193 \nL 236.147139 147.712074 \nL 236.757086 147.844674 \nL 237.367033 147.779882 \nL 237.97698 147.911313 \nL 238.586927 147.651673 \nL 239.196874 147.199462 \nL 239.806822 147.33154 \nL 240.416769 147.269664 \nL 241.026716 147.400582 \nL 241.636663 147.14718 \nL 243.466505 147.535832 \nL 244.076452 147.47452 \nL 244.686399 147.790544 \nL 245.296346 147.916607 \nL 245.906293 147.667438 \nL 246.51624 147.046823 \nL 247.736135 147.300548 \nL 248.346082 147.241439 \nL 248.956029 146.998641 \nL 249.565976 146.940915 \nL 250.175923 147.249342 \nL 250.785871 147.008897 \nL 252.005765 146.170527 \nL 252.615712 146.116439 \nL 253.225659 146.242618 \nL 253.835606 146.009297 \nL 254.445554 146.313772 \nL 255.665448 146.56164 \nL 256.275395 146.507336 \nL 256.885342 146.276882 \nL 257.495289 146.575691 \nL 258.105237 146.521859 \nL 258.715184 146.818017 \nL 259.325131 146.763762 \nL 259.935078 146.883579 \nL 260.545025 147.175844 \nL 261.154972 147.293639 \nL 261.76492 147.238581 \nL 262.374867 146.840683 \nL 264.814655 147.307325 \nL 265.424603 147.591197 \nL 266.03455 147.704875 \nL 269.084286 147.433313 \nL 269.694233 147.710898 \nL 270.30418 147.656884 \nL 270.914127 147.932165 \nL 272.134021 147.823797 \nL 272.743969 147.117944 \nL 273.353916 147.391577 \nL 273.963863 147.015276 \nL 275.183757 146.591506 \nL 275.793704 146.863498 \nL 276.403652 146.973705 \nL 277.013599 147.243038 \nL 278.233493 147.141704 \nL 278.84344 147.249864 \nL 280.063335 147.14935 \nL 280.673282 146.628379 \nL 281.283229 146.736764 \nL 281.893176 147.000704 \nL 283.11307 146.90299 \nL 283.723018 147.009402 \nL 284.332965 146.960798 \nL 286.162806 147.735511 \nL 286.772753 147.68544 \nL 287.382701 147.787959 \nL 288.602595 147.688348 \nL 289.212542 147.941104 \nL 290.432436 147.54096 \nL 291.042384 147.492356 \nL 291.652331 147.593467 \nL 292.262278 147.395943 \nL 292.872225 147.050816 \nL 294.092119 147.253228 \nL 294.702067 146.911233 \nL 295.312014 147.159349 \nL 296.531908 147.066457 \nL 297.141855 147.312221 \nL 298.36175 147.219262 \nL 298.971697 147.028357 \nL 299.581644 146.69405 \nL 300.191591 146.937593 \nL 301.411485 147.134331 \nL 302.021433 146.803188 \nL 302.63138 146.616292 \nL 303.241327 146.572543 \nL 303.851274 146.670845 \nL 305.681116 147.384999 \nL 306.291063 147.480253 \nL 306.90101 147.294948 \nL 307.510957 147.389945 \nL 308.120904 147.345135 \nL 309.340799 147.533463 \nL 309.950746 147.212038 \nL 310.560693 147.444017 \nL 311.780587 147.630001 \nL 313.000482 147.54096 \nL 314.220376 147.72465 \nL 317.270112 147.504667 \nL 317.880059 147.193373 \nL 318.490006 147.28451 \nL 319.7099 147.199462 \nL 320.319848 147.289936 \nL 321.539742 147.205468 \nL 324.589478 147.650306 \nL 325.199425 147.347421 \nL 325.809372 147.435641 \nL 326.419319 147.393855 \nL 327.029266 147.481553 \nL 327.639214 147.310862 \nL 328.249161 147.398353 \nL 328.859108 147.61383 \nL 330.079002 147.786211 \nL 330.688949 147.616779 \nL 331.908844 147.787959 \nL 332.518791 147.999608 \nL 333.128738 147.831228 \nL 333.738685 148.041817 \nL 334.348632 147.99989 \nL 335.568527 148.167035 \nL 337.398368 148.041817 \nL 338.008315 148.124553 \nL 338.618263 148.330734 \nL 339.22821 148.412459 \nL 340.448104 148.32882 \nL 341.058051 148.532732 \nL 342.887893 148.041817 \nL 343.49784 148.001265 \nL 344.107787 148.203669 \nL 344.717734 148.284068 \nL 345.937629 148.685007 \nL 346.547576 148.523163 \nL 347.157523 148.60218 \nL 347.76747 148.800665 \nL 348.377417 148.878737 \nL 348.987365 148.837174 \nL 349.597312 148.91484 \nL 350.207259 148.873377 \nL 350.817206 149.06917 \nL 351.427153 149.027557 \nL 352.0371 149.104154 \nL 352.647048 149.298216 \nL 353.256995 149.138841 \nL 353.866942 149.214718 \nL 354.476889 149.056196 \nL 355.086836 149.248725 \nL 356.306731 149.398755 \nL 356.916678 149.241161 \nL 357.526625 149.315878 \nL 358.746519 148.772324 \nL 359.966414 148.692728 \nL 360.576361 148.88244 \nL 361.186308 148.613786 \nL 361.796255 148.57456 \nL 362.406202 148.763344 \nL 363.016149 148.496587 \nL 363.626097 148.571304 \nL 364.236044 148.758937 \nL 364.845991 148.719809 \nL 365.455938 148.90639 \nL 366.065885 148.867122 \nL 366.675832 148.7157 \nL 367.28578 148.901154 \nL 367.895727 148.862143 \nL 368.505674 149.046553 \nL 369.725568 148.968407 \nL 369.725568 148.968407 \n\" style=\"fill:none;stroke:#2ca02c;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_19\">\n    <path clip-path=\"url(#pc07f75842b)\" d=\"M 65.361932 73.914541 \nL 65.971879 73.914541 \nL 66.581826 110.978183 \nL 67.191773 129.51 \nL 67.80172 140.629088 \nL 68.411668 129.51 \nL 69.021615 137.452207 \nL 69.631562 136.459433 \nL 70.241509 141.864545 \nL 71.461403 149.726534 \nL 72.071351 152.674775 \nL 73.291245 149.365518 \nL 73.901192 151.748185 \nL 74.511139 150.3583 \nL 75.121086 152.402244 \nL 75.731034 151.130453 \nL 76.340981 152.918617 \nL 77.560875 150.689219 \nL 78.780769 158.516323 \nL 80.000664 160.643459 \nL 81.220558 158.337273 \nL 82.440452 156.349182 \nL 83.0504 157.307725 \nL 83.660347 159.997834 \nL 84.270294 160.782446 \nL 84.880241 158.15008 \nL 86.100135 156.513511 \nL 86.710083 157.307725 \nL 87.32003 159.561595 \nL 89.149871 157.307725 \nL 89.759819 159.341712 \nL 90.369766 159.955128 \nL 90.979713 157.954188 \nL 91.58966 159.834797 \nL 92.199607 157.925457 \nL 92.809554 157.307725 \nL 93.419502 157.899171 \nL 94.029449 157.307725 \nL 95.249343 160.643459 \nL 95.85929 160.032992 \nL 96.469237 158.376873 \nL 98.909026 160.286055 \nL 99.518973 160.721481 \nL 100.12892 159.224811 \nL 100.738868 159.663468 \nL 101.958762 162.320431 \nL 102.568709 162.687934 \nL 103.178656 162.161296 \nL 103.788603 162.519802 \nL 104.398551 163.722585 \nL 105.008498 161.519506 \nL 107.448286 162.867274 \nL 108.058234 162.39745 \nL 108.668181 161.168522 \nL 109.278128 160.734844 \nL 110.498022 158.419637 \nL 111.107969 158.039251 \nL 111.717917 159.112773 \nL 112.937811 158.363336 \nL 113.547758 155.91784 \nL 115.3776 156.972813 \nL 115.987547 156.645879 \nL 117.207441 157.307725 \nL 117.817388 158.266268 \nL 118.427335 158.571265 \nL 119.037283 157.620062 \nL 119.64723 157.925457 \nL 120.257177 158.835073 \nL 120.867124 159.120627 \nL 121.477071 157.606625 \nL 122.087018 157.307725 \nL 122.696966 157.600337 \nL 123.306913 158.465971 \nL 123.91686 158.740598 \nL 124.526807 157.87503 \nL 125.136754 158.15008 \nL 126.356649 156.482055 \nL 127.576543 155.958326 \nL 128.18649 156.77316 \nL 130.626279 155.763411 \nL 131.236226 156.542656 \nL 133.066067 157.307725 \nL 133.676015 156.569737 \nL 136.72575 157.778874 \nL 137.335698 158.475697 \nL 137.945645 158.234323 \nL 138.555592 158.456394 \nL 139.165539 159.130526 \nL 139.775486 159.341712 \nL 140.385433 158.652784 \nL 141.605328 159.07266 \nL 142.215275 159.715403 \nL 143.435169 159.247104 \nL 144.045116 158.5907 \nL 144.655064 158.793104 \nL 145.265011 158.571265 \nL 145.874958 159.188774 \nL 146.484905 158.552402 \nL 147.094852 159.160914 \nL 147.704799 159.351678 \nL 148.314747 158.728047 \nL 149.534641 159.107579 \nL 150.144588 158.499059 \nL 150.754535 158.293466 \nL 151.364482 158.482283 \nL 151.97443 159.057235 \nL 152.584377 158.852047 \nL 153.194324 159.033102 \nL 153.804271 158.830889 \nL 154.414218 159.009633 \nL 155.024165 158.810311 \nL 155.634113 158.240537 \nL 156.24406 158.049002 \nL 156.854007 158.596367 \nL 157.463954 157.673488 \nL 158.073901 157.126041 \nL 158.683848 157.307725 \nL 159.293796 157.845745 \nL 160.51369 157.484787 \nL 161.733584 158.531525 \nL 162.953479 158.171014 \nL 165.393267 158.823972 \nL 166.003214 158.647382 \nL 166.613162 157.474183 \nL 167.223109 157.638653 \nL 168.443003 157.307725 \nL 169.05295 156.820049 \nL 169.662897 156.661271 \nL 170.272845 156.182965 \nL 170.882792 156.029671 \nL 171.492739 156.513511 \nL 172.102686 156.044193 \nL 173.932528 156.531256 \nL 174.542475 156.381135 \nL 175.152422 155.61836 \nL 175.762369 155.780378 \nL 176.372316 155.33303 \nL 178.812105 155.969866 \nL 179.422052 155.533404 \nL 180.031999 155.395718 \nL 180.641946 154.966869 \nL 181.251894 155.124662 \nL 181.861841 154.412131 \nL 182.471788 154.859222 \nL 183.691682 155.169439 \nL 184.301629 155.605826 \nL 184.911577 155.473359 \nL 185.521524 155.623016 \nL 187.351365 155.23327 \nL 187.961312 155.381154 \nL 188.57126 154.70597 \nL 189.181207 154.582458 \nL 189.791154 154.731353 \nL 191.011048 154.487668 \nL 191.620995 154.634873 \nL 192.230943 155.046673 \nL 193.450837 154.804612 \nL 194.060784 153.636333 \nL 194.670731 154.045084 \nL 196.500573 153.704323 \nL 197.11052 153.849026 \nL 197.720467 153.737378 \nL 198.330414 153.880615 \nL 198.940361 153.51713 \nL 199.550309 153.408497 \nL 200.160256 153.050422 \nL 201.38015 152.840239 \nL 201.990097 153.230731 \nL 202.600044 153.371764 \nL 203.209992 153.266652 \nL 203.819939 153.650135 \nL 204.429886 153.544717 \nL 205.039833 153.92366 \nL 206.869675 154.325137 \nL 207.479622 154.219089 \nL 208.089569 154.350521 \nL 208.699516 154.245268 \nL 209.309463 153.671741 \nL 209.91941 153.570216 \nL 210.529358 153.702169 \nL 211.139305 153.601365 \nL 211.749252 153.270711 \nL 212.359199 153.631992 \nL 213.579093 153.889976 \nL 214.189041 153.790464 \nL 214.798988 154.143759 \nL 215.408935 153.818946 \nL 216.018882 153.720925 \nL 216.628829 153.846964 \nL 217.848724 154.539031 \nL 218.458671 154.43971 \nL 219.068618 154.780662 \nL 219.678565 154.243412 \nL 220.288512 154.146419 \nL 220.898459 153.833013 \nL 221.508407 153.305721 \nL 222.118354 152.998006 \nL 222.728301 152.478005 \nL 223.338248 152.389669 \nL 223.948195 152.088996 \nL 224.558142 152.002822 \nL 225.16809 152.128686 \nL 225.778037 151.832421 \nL 226.997931 150.828562 \nL 227.607878 150.748718 \nL 228.827773 151.004158 \nL 231.877508 150.611926 \nL 232.487456 150.130861 \nL 234.317297 150.508289 \nL 234.927244 150.433025 \nL 236.757086 150.801878 \nL 237.367033 150.530192 \nL 237.97698 150.847691 \nL 238.586927 150.772825 \nL 239.196874 151.087258 \nL 239.806822 151.205791 \nL 240.416769 151.516538 \nL 241.026716 151.632759 \nL 241.636663 151.939894 \nL 242.24661 152.053862 \nL 242.856557 151.78626 \nL 244.686399 152.125099 \nL 245.296346 152.424347 \nL 246.51624 152.270556 \nL 247.126188 151.822562 \nL 247.736135 151.748185 \nL 248.346082 151.304897 \nL 248.956029 151.600914 \nL 250.175923 151.821336 \nL 250.785871 151.748185 \nL 251.395818 151.857191 \nL 252.005765 152.146589 \nL 252.615712 152.253598 \nL 253.225659 151.820151 \nL 253.835606 151.568845 \nL 254.445554 151.855443 \nL 255.665448 151.712662 \nL 256.275395 151.287839 \nL 256.885342 151.042208 \nL 258.105237 150.906361 \nL 258.715184 150.66425 \nL 259.935078 150.879503 \nL 260.545025 151.159324 \nL 261.76492 151.025266 \nL 262.984814 151.234993 \nL 263.594761 150.997812 \nL 264.814655 150.866795 \nL 266.03455 150.400418 \nL 266.644497 150.337299 \nL 267.254444 150.10711 \nL 267.864391 150.379168 \nL 268.474338 150.15023 \nL 269.084286 150.088619 \nL 269.694233 149.696445 \nL 270.30418 149.801516 \nL 270.914127 149.412515 \nL 271.524074 149.517801 \nL 272.134021 149.458957 \nL 272.743969 149.563498 \nL 273.353916 149.342297 \nL 273.963863 149.28448 \nL 274.57381 149.388607 \nL 275.183757 149.330989 \nL 277.013599 148.680848 \nL 278.233493 149.206674 \nL 278.84344 149.150564 \nL 279.453387 148.936819 \nL 280.673282 148.827067 \nL 281.283229 148.616048 \nL 281.893176 148.718542 \nL 282.503123 148.664735 \nL 283.11307 148.921824 \nL 283.723018 148.867752 \nL 284.332965 148.505112 \nL 284.942912 148.606504 \nL 285.552859 148.400174 \nL 287.992648 148.801319 \nL 288.602595 149.051731 \nL 289.822489 148.945807 \nL 290.432436 148.743022 \nL 291.042384 148.841035 \nL 291.652331 149.087967 \nL 292.262278 149.184529 \nL 293.482172 148.783094 \nL 294.702067 148.97578 \nL 295.312014 149.218446 \nL 296.531908 149.407321 \nL 297.141855 149.646938 \nL 297.751802 149.739764 \nL 298.36175 149.541785 \nL 298.971697 149.634395 \nL 299.581644 149.29332 \nL 300.801538 149.191082 \nL 301.411485 148.853784 \nL 302.63138 149.039686 \nL 304.461221 148.466208 \nL 305.071168 148.559209 \nL 306.291063 148.462994 \nL 306.90101 148.555299 \nL 308.120904 149.017177 \nL 308.730851 148.82942 \nL 309.340799 148.365321 \nL 309.950746 148.456715 \nL 310.560693 148.13379 \nL 311.780587 148.041817 \nL 312.390534 148.270043 \nL 313.000482 148.223949 \nL 313.610429 148.314348 \nL 314.220376 147.99651 \nL 314.830323 147.951418 \nL 315.44027 148.177092 \nL 316.050217 147.861897 \nL 316.660165 148.086693 \nL 318.490006 147.952727 \nL 319.099953 147.775176 \nL 320.929795 147.644706 \nL 322.149689 147.295279 \nL 322.759636 147.384659 \nL 325.199425 147.217216 \nL 325.809372 147.045953 \nL 326.419319 147.13467 \nL 327.029266 147.352267 \nL 328.249161 147.527043 \nL 328.859108 147.357039 \nL 329.469055 147.315916 \nL 330.079002 147.14718 \nL 330.688949 147.361753 \nL 331.298897 147.19368 \nL 331.908844 147.15331 \nL 333.128738 147.325815 \nL 333.738685 147.285421 \nL 334.95858 147.456162 \nL 335.568527 147.415742 \nL 336.178474 147.250577 \nL 337.398368 147.171196 \nL 338.008315 147.255871 \nL 338.618263 146.844883 \nL 339.22821 146.682816 \nL 340.448104 146.852828 \nL 341.058051 146.814546 \nL 342.887893 147.066457 \nL 343.49784 147.271354 \nL 344.107787 147.353957 \nL 344.717734 147.315079 \nL 345.327681 147.397235 \nL 345.937629 147.59963 \nL 346.547576 147.44014 \nL 347.157523 147.521484 \nL 348.377417 147.922257 \nL 348.987365 147.882749 \nL 349.597312 147.962453 \nL 350.207259 147.68544 \nL 350.817206 147.646686 \nL 352.0371 147.215559 \nL 352.647048 147.06026 \nL 356.306731 147.537812 \nL 357.526625 147.462698 \nL 358.136572 147.656544 \nL 358.746519 147.618892 \nL 359.356466 147.696508 \nL 359.966414 147.888664 \nL 360.576361 147.850771 \nL 361.186308 148.041817 \nL 361.796255 147.889608 \nL 362.406202 147.965866 \nL 364.236044 147.513415 \nL 365.455938 147.778689 \nL 366.065885 147.85425 \nL 366.675832 148.041817 \nL 367.28578 147.780279 \nL 369.725568 148.078881 \nL 369.725568 148.078881 \n\" style=\"fill:none;stroke:#d62728;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_20\">\n    <path clip-path=\"url(#pc07f75842b)\" d=\"M 65.361932 240.700909 \nL 65.971879 157.307725 \nL 66.581826 185.105455 \nL 67.191773 185.105455 \nL 67.80172 173.986366 \nL 68.411668 175.839546 \nL 69.021615 185.105455 \nL 69.631562 178.156025 \nL 70.241509 160.396361 \nL 70.851456 146.188637 \nL 72.071351 152.674775 \nL 72.681298 146.616292 \nL 73.291245 145.394414 \nL 73.901192 148.041817 \nL 74.511139 143.408867 \nL 75.121086 149.131924 \nL 75.731034 148.041817 \nL 76.340981 144.140385 \nL 77.560875 148.041817 \nL 78.170822 147.199462 \nL 78.780769 144.013162 \nL 79.390717 145.725342 \nL 80.610611 153.031152 \nL 81.220558 150.100913 \nL 81.830505 153.336622 \nL 82.440452 148.680848 \nL 83.0504 151.748185 \nL 83.660347 149.237417 \nL 84.270294 150.3583 \nL 84.880241 153.095952 \nL 85.490188 150.767084 \nL 86.100135 151.748185 \nL 86.710083 151.130453 \nL 87.32003 149.043538 \nL 87.929977 149.992537 \nL 88.539924 149.467341 \nL 89.149871 151.748185 \nL 90.979713 150.19668 \nL 91.58966 148.462994 \nL 93.419502 154.350521 \nL 94.029449 153.833013 \nL 94.639396 155.605826 \nL 97.079185 153.636333 \nL 97.689132 154.219089 \nL 98.299079 153.769836 \nL 98.909026 152.343848 \nL 99.518973 151.943257 \nL 100.12892 153.473562 \nL 101.348815 152.674775 \nL 101.958762 150.472218 \nL 103.788603 146.883579 \nL 106.838339 145.624629 \nL 107.448286 144.6002 \nL 108.058234 144.387657 \nL 109.278128 147.026377 \nL 110.498022 148.041817 \nL 111.107969 149.261019 \nL 111.717917 148.282494 \nL 112.327864 149.467341 \nL 112.937811 149.214718 \nL 114.767652 150.527798 \nL 115.3776 149.604746 \nL 115.987547 150.689219 \nL 116.597494 149.785991 \nL 117.207441 149.550226 \nL 117.817388 149.958902 \nL 118.427335 149.726534 \nL 119.037283 150.124043 \nL 119.64723 149.895005 \nL 120.257177 150.281927 \nL 120.867124 149.451849 \nL 121.477071 150.433025 \nL 122.696966 151.162969 \nL 123.306913 150.3583 \nL 125.746701 153.972 \nL 126.356649 154.280253 \nL 126.966596 153.492351 \nL 127.576543 153.799279 \nL 128.796437 152.277664 \nL 129.406384 152.587358 \nL 130.626279 151.130453 \nL 131.236226 151.442152 \nL 131.846173 151.242772 \nL 132.45612 150.546123 \nL 133.066067 149.365518 \nL 134.285962 149.017177 \nL 134.895909 149.330989 \nL 135.505856 150.118658 \nL 136.115803 150.417691 \nL 136.72575 149.298216 \nL 137.335698 149.131924 \nL 137.945645 148.505112 \nL 138.555592 148.348131 \nL 139.775486 147.137827 \nL 140.385433 146.995667 \nL 141.605328 147.600583 \nL 142.215275 147.458142 \nL 142.825222 147.752262 \nL 143.435169 147.610847 \nL 144.045116 147.899268 \nL 144.655064 147.334497 \nL 146.484905 148.180116 \nL 147.094852 148.865457 \nL 147.704799 148.72314 \nL 148.314747 148.177092 \nL 149.534641 149.508365 \nL 150.754535 149.2247 \nL 151.364482 148.694352 \nL 152.584377 148.427901 \nL 153.194324 148.680848 \nL 155.024165 148.292253 \nL 155.634113 148.912446 \nL 156.24406 148.783094 \nL 156.854007 148.287274 \nL 157.463954 148.529501 \nL 158.073901 148.405186 \nL 158.683848 148.643502 \nL 159.293796 148.161377 \nL 160.51369 147.923781 \nL 161.123637 148.159107 \nL 161.733584 146.99285 \nL 163.563426 147.698637 \nL 164.173373 148.269206 \nL 164.78332 148.154816 \nL 165.393267 148.378759 \nL 166.613162 149.484415 \nL 167.223109 148.703672 \nL 169.05295 149.342297 \nL 169.662897 148.580533 \nL 170.882792 149.00036 \nL 171.492739 148.888985 \nL 172.102686 149.410643 \nL 173.32258 148.562373 \nL 173.932528 148.766525 \nL 174.542475 148.041817 \nL 175.152422 148.553749 \nL 175.762369 148.14364 \nL 176.982263 147.941104 \nL 177.592211 148.141991 \nL 178.202158 148.639617 \nL 178.812105 148.537321 \nL 179.422052 149.027557 \nL 180.031999 148.630131 \nL 180.641946 149.114717 \nL 181.251894 149.303145 \nL 183.081735 148.997071 \nL 183.691682 148.61203 \nL 184.301629 148.514573 \nL 185.521524 149.445744 \nL 186.131471 149.624943 \nL 187.351365 150.53117 \nL 187.961312 150.427102 \nL 188.57126 150.597934 \nL 189.181207 149.676977 \nL 189.791154 149.578609 \nL 190.401101 150.020944 \nL 191.011048 149.921863 \nL 191.620995 149.55644 \nL 192.230943 149.726534 \nL 192.84089 149.100783 \nL 193.450837 149.271416 \nL 194.060784 149.702692 \nL 195.280678 148.994387 \nL 196.500573 149.328752 \nL 197.11052 149.237417 \nL 197.720467 149.656979 \nL 198.940361 149.979241 \nL 199.550309 149.886613 \nL 200.160256 150.045259 \nL 200.770203 149.95317 \nL 201.38015 150.1101 \nL 201.990097 150.512729 \nL 202.600044 150.173799 \nL 203.209992 150.327681 \nL 203.819939 150.236379 \nL 204.429886 150.388646 \nL 205.039833 149.814431 \nL 206.259727 149.160115 \nL 206.869675 149.075781 \nL 207.479622 149.229754 \nL 208.089569 149.618995 \nL 209.309463 148.980137 \nL 209.91941 149.131924 \nL 210.529358 148.351975 \nL 211.139305 148.736759 \nL 212.969146 147.813036 \nL 213.579093 147.738021 \nL 214.189041 147.890536 \nL 214.798988 148.267814 \nL 215.408935 148.416958 \nL 216.018882 148.340717 \nL 216.628829 148.041817 \nL 217.848724 148.337146 \nL 218.458671 148.262438 \nL 219.678565 147.677023 \nL 220.288512 147.823797 \nL 220.898459 148.186603 \nL 221.508407 148.330254 \nL 222.118354 147.826332 \nL 222.728301 147.54096 \nL 223.338248 147.68544 \nL 223.948195 147.402794 \nL 224.558142 147.758889 \nL 225.16809 147.689507 \nL 227.607878 148.250044 \nL 228.827773 147.284013 \nL 229.43772 147.012277 \nL 230.047667 147.152838 \nL 230.657614 146.679187 \nL 231.267561 146.819939 \nL 231.877508 147.162572 \nL 232.487456 147.098385 \nL 233.097403 147.236087 \nL 234.317297 147.108566 \nL 236.147139 146.327135 \nL 236.757086 145.873201 \nL 237.367033 146.208279 \nL 238.586927 146.481249 \nL 239.196874 146.810685 \nL 239.806822 146.362981 \nL 240.416769 146.690545 \nL 241.026716 146.438717 \nL 244.076452 146.150819 \nL 244.686399 146.282871 \nL 245.296346 146.038383 \nL 245.906293 145.982729 \nL 246.51624 146.114011 \nL 247.126188 146.058481 \nL 247.736135 145.818002 \nL 248.346082 145.948523 \nL 248.956029 146.262277 \nL 249.565976 146.023504 \nL 250.785871 146.279781 \nL 251.395818 146.588341 \nL 252.005765 146.713808 \nL 252.615712 147.018962 \nL 253.835606 146.905997 \nL 254.445554 146.492532 \nL 255.055501 146.616292 \nL 255.665448 146.384024 \nL 256.275395 146.68439 \nL 258.105237 147.047999 \nL 258.715184 147.342508 \nL 259.935078 147.578522 \nL 260.545025 147.349045 \nL 261.154972 147.293639 \nL 261.76492 147.066457 \nL 262.374867 147.183863 \nL 262.984814 147.471612 \nL 263.594761 147.416513 \nL 264.204708 147.531773 \nL 264.814655 147.307325 \nL 265.424603 147.253228 \nL 266.03455 147.367933 \nL 266.644497 147.14602 \nL 267.254444 147.0929 \nL 267.864391 146.873149 \nL 269.084286 146.769487 \nL 269.694233 146.552652 \nL 270.30418 146.832026 \nL 270.914127 146.945265 \nL 271.524074 146.893827 \nL 272.134021 147.006221 \nL 272.743969 146.954908 \nL 273.963863 146.529017 \nL 274.57381 146.479542 \nL 275.183757 146.591506 \nL 275.793704 146.542131 \nL 276.403652 146.813485 \nL 277.013599 146.923518 \nL 277.623546 146.873621 \nL 278.233493 146.347481 \nL 278.84344 146.141118 \nL 280.063335 146.361879 \nL 280.673282 146.314278 \nL 281.283229 146.423548 \nL 281.893176 146.0637 \nL 282.503123 145.861603 \nL 284.332965 146.188637 \nL 284.942912 145.988428 \nL 285.552859 145.942914 \nL 287.382701 146.264795 \nL 287.992648 146.52282 \nL 289.212542 146.128211 \nL 291.042384 146.443389 \nL 291.652331 146.098967 \nL 292.262278 146.054496 \nL 293.482172 146.262765 \nL 295.921961 146.085952 \nL 296.531908 146.334939 \nL 297.751802 146.246851 \nL 298.36175 146.057992 \nL 298.971697 146.159683 \nL 299.581644 146.40524 \nL 300.801538 146.317931 \nL 302.63138 146.616292 \nL 303.241327 146.430358 \nL 305.681116 146.259012 \nL 306.291063 146.076326 \nL 306.90101 146.174636 \nL 307.510957 145.993076 \nL 308.120904 145.673092 \nL 309.340799 145.315191 \nL 309.950746 145.552472 \nL 310.560693 145.374706 \nL 311.17064 145.335438 \nL 311.780587 145.570913 \nL 312.390534 145.257482 \nL 313.000482 145.355387 \nL 313.610429 145.180288 \nL 314.220376 145.277903 \nL 315.44027 145.201173 \nL 316.050217 145.298034 \nL 316.660165 145.529027 \nL 317.270112 145.22176 \nL 318.490006 145.41351 \nL 319.099953 145.375369 \nL 319.7099 145.470415 \nL 322.759636 145.281764 \nL 323.369583 145.506808 \nL 323.979531 145.469164 \nL 324.589478 145.562206 \nL 325.199425 145.52462 \nL 325.809372 145.617098 \nL 326.419319 145.579553 \nL 327.029266 145.283594 \nL 327.639214 145.246994 \nL 328.249161 145.467955 \nL 328.859108 145.302706 \nL 329.469055 145.266313 \nL 330.688949 145.449066 \nL 331.298897 145.285367 \nL 331.908844 145.249355 \nL 332.518791 145.340144 \nL 333.128738 145.304164 \nL 333.738685 145.14228 \nL 334.348632 145.106914 \nL 336.178474 145.37657 \nL 336.788421 145.340997 \nL 338.008315 145.518514 \nL 338.618263 145.482858 \nL 339.22821 145.570913 \nL 339.838157 145.412027 \nL 340.448104 145.499841 \nL 341.667998 145.429408 \nL 342.277946 145.516609 \nL 342.887893 145.4815 \nL 343.49784 145.203244 \nL 344.717734 145.134865 \nL 345.327681 145.342621 \nL 345.937629 145.187678 \nL 346.547576 145.394414 \nL 347.76747 145.565586 \nL 348.377417 145.291937 \nL 348.987365 145.25807 \nL 349.597312 145.343399 \nL 350.207259 145.547153 \nL 350.817206 145.631496 \nL 351.427153 145.597199 \nL 352.0371 145.445007 \nL 352.647048 145.41124 \nL 353.256995 145.260092 \nL 353.866942 145.226863 \nL 354.476889 145.427858 \nL 355.086836 145.277621 \nL 356.306731 145.211645 \nL 357.526625 145.377871 \nL 358.136572 145.229299 \nL 358.746519 145.312026 \nL 359.966414 145.591334 \nL 361.186308 145.52515 \nL 361.796255 145.720587 \nL 362.406202 145.687366 \nL 363.016149 145.767973 \nL 363.626097 145.62134 \nL 364.236044 145.701756 \nL 364.845991 145.668842 \nL 365.455938 145.410527 \nL 366.065885 145.603421 \nL 366.675832 145.570913 \nL 368.505674 145.809072 \nL 369.725568 145.521488 \nL 369.725568 145.521488 \n\" style=\"fill:none;stroke:#9467bd;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_21\">\n    <path clip-path=\"url(#pc07f75842b)\" d=\"M 65.361932 18.319091 \nL 65.971879 101.712275 \nL 66.581826 110.978183 \nL 67.191773 115.611142 \nL 67.80172 140.629088 \nL 68.411668 138.775908 \nL 69.021615 137.452207 \nL 69.631562 150.3583 \nL 70.241509 141.864545 \nL 70.851456 140.629088 \nL 71.461403 129.51 \nL 72.071351 129.51 \nL 72.681298 133.786573 \nL 73.291245 133.481104 \nL 73.901192 136.922728 \nL 75.121086 136.050641 \nL 76.950928 135.069548 \nL 77.560875 134.804805 \nL 78.170822 137.091199 \nL 78.780769 141.595974 \nL 79.390717 141.092392 \nL 80.610611 144.478006 \nL 81.830505 143.408867 \nL 82.440452 144.846677 \nL 83.0504 140.629088 \nL 83.660347 138.477008 \nL 84.270294 139.934146 \nL 84.880241 139.618263 \nL 86.100135 145.394414 \nL 87.32003 147.54096 \nL 87.929977 147.066457 \nL 88.539924 149.467341 \nL 89.759819 145.781841 \nL 90.369766 146.718116 \nL 90.979713 148.903764 \nL 92.199607 148.041817 \nL 92.809554 146.430358 \nL 94.639396 145.394414 \nL 95.249343 143.964822 \nL 96.469237 145.547153 \nL 97.079185 143.146625 \nL 97.689132 144.953181 \nL 100.12892 147.722305 \nL 100.738868 148.355919 \nL 101.348815 147.115227 \nL 101.958762 146.826616 \nL 104.398551 149.182243 \nL 106.228392 150.767084 \nL 106.838339 150.459013 \nL 107.448286 150.953963 \nL 108.058234 150.651931 \nL 108.668181 149.586139 \nL 109.888075 150.546123 \nL 110.498022 149.524362 \nL 111.107969 149.992537 \nL 111.717917 151.170566 \nL 112.327864 151.605628 \nL 112.937811 150.622199 \nL 114.157705 151.473641 \nL 114.767652 150.527798 \nL 115.987547 150.027373 \nL 116.597494 148.477865 \nL 117.207441 148.25731 \nL 117.817388 148.680848 \nL 119.037283 150.748718 \nL 119.64723 150.512729 \nL 122.087018 151.984762 \nL 122.696966 151.748185 \nL 124.526807 152.769325 \nL 125.136754 151.972807 \nL 125.746701 152.304141 \nL 126.356649 153.179351 \nL 127.576543 152.719751 \nL 128.18649 153.031152 \nL 128.796437 152.807143 \nL 129.406384 153.636333 \nL 130.016332 153.41085 \nL 131.236226 153.992404 \nL 131.846173 153.264423 \nL 132.45612 153.050422 \nL 133.066067 153.336622 \nL 134.285962 152.918617 \nL 134.895909 153.198496 \nL 135.505856 152.994287 \nL 136.115803 153.268739 \nL 137.335698 151.935056 \nL 137.945645 152.21148 \nL 138.555592 152.023864 \nL 139.165539 150.927925 \nL 140.385433 151.479175 \nL 140.995381 152.192948 \nL 142.215275 152.711251 \nL 142.825222 153.398672 \nL 143.435169 152.782513 \nL 144.045116 152.603496 \nL 144.655064 152.851605 \nL 146.484905 152.329027 \nL 147.704799 152.811036 \nL 148.924694 151.667611 \nL 150.144588 151.351074 \nL 150.754535 151.984762 \nL 151.364482 151.43497 \nL 151.97443 151.281651 \nL 152.584377 151.902614 \nL 153.194324 151.748185 \nL 154.414218 152.202028 \nL 155.024165 151.297408 \nL 155.634113 151.151189 \nL 156.24406 151.377551 \nL 156.854007 151.232732 \nL 158.073901 152.402244 \nL 158.683848 152.614606 \nL 159.903743 153.743914 \nL 160.51369 153.58956 \nL 161.123637 152.73342 \nL 161.733584 153.286675 \nL 162.343531 153.13807 \nL 162.953479 152.645995 \nL 164.173373 152.362123 \nL 164.78332 152.561776 \nL 166.003214 151.614219 \nL 169.05295 152.593497 \nL 169.662897 153.105745 \nL 170.272845 153.290718 \nL 171.492739 151.748185 \nL 172.102686 151.937715 \nL 172.712633 151.811005 \nL 173.32258 151.061046 \nL 173.932528 150.94065 \nL 174.542475 151.130453 \nL 175.152422 151.011009 \nL 175.762369 150.587396 \nL 176.372316 150.776023 \nL 177.592211 149.945084 \nL 178.202158 149.835225 \nL 178.812105 149.429225 \nL 180.031999 149.218446 \nL 180.641946 149.699933 \nL 181.251894 149.594225 \nL 181.861841 149.779181 \nL 182.471788 149.386096 \nL 184.301629 149.932823 \nL 184.911577 150.393575 \nL 185.521524 150.288098 \nL 186.131471 150.463064 \nL 187.351365 149.701383 \nL 187.961312 149.876655 \nL 188.57126 149.776323 \nL 189.791154 150.121003 \nL 190.401101 148.941425 \nL 191.011048 149.116125 \nL 191.620995 149.021866 \nL 192.230943 149.19452 \nL 192.84089 149.630262 \nL 194.060784 149.964933 \nL 194.670731 149.346878 \nL 195.280678 149.773763 \nL 195.890626 149.679512 \nL 197.11052 150.006024 \nL 197.720467 150.422057 \nL 198.330414 150.072705 \nL 198.940361 150.231947 \nL 199.550309 150.641302 \nL 200.770203 150.451789 \nL 201.38015 150.854683 \nL 201.990097 150.512729 \nL 202.600044 150.911795 \nL 203.819939 150.236379 \nL 204.429886 150.631419 \nL 205.64978 150.44855 \nL 206.259727 150.118658 \nL 207.479622 150.417691 \nL 208.089569 149.618995 \nL 209.91941 150.066301 \nL 211.139305 149.895005 \nL 211.749252 150.0411 \nL 212.359199 149.726534 \nL 213.579093 150.01652 \nL 214.189041 149.705898 \nL 214.798988 149.171805 \nL 215.408935 149.092208 \nL 216.018882 149.237417 \nL 216.628829 149.604746 \nL 217.238776 149.746748 \nL 218.458671 149.586139 \nL 219.068618 149.28704 \nL 219.678565 149.646938 \nL 220.288512 149.349952 \nL 221.508407 149.628199 \nL 222.118354 149.981196 \nL 222.728301 149.902155 \nL 224.558142 150.305247 \nL 225.16809 150.648957 \nL 225.778037 150.779477 \nL 226.387984 150.489417 \nL 226.997931 150.619556 \nL 227.607878 150.124043 \nL 228.827773 149.970782 \nL 229.43772 150.100913 \nL 230.047667 149.819783 \nL 231.267561 149.670988 \nL 231.877508 149.394505 \nL 232.487456 149.524362 \nL 233.097403 149.048981 \nL 234.317297 149.308381 \nL 234.927244 149.237417 \nL 235.537191 148.968407 \nL 236.147139 149.097013 \nL 236.757086 149.027557 \nL 237.367033 149.155037 \nL 237.97698 148.890103 \nL 238.586927 149.017177 \nL 239.196874 148.948972 \nL 239.806822 149.074952 \nL 240.416769 149.00702 \nL 241.026716 148.747181 \nL 241.636663 148.872557 \nL 242.24661 148.614971 \nL 242.856557 148.549541 \nL 243.466505 148.294813 \nL 244.686399 148.921294 \nL 245.296346 148.855715 \nL 246.51624 149.099002 \nL 247.736135 149.709684 \nL 248.346082 149.82728 \nL 248.956029 149.575908 \nL 249.565976 149.509683 \nL 250.175923 149.261019 \nL 250.785871 149.19626 \nL 251.395818 149.313608 \nL 252.005765 149.61129 \nL 252.615712 149.185018 \nL 253.225659 149.301264 \nL 253.835606 149.596105 \nL 254.445554 149.531512 \nL 255.665448 149.758827 \nL 256.275395 150.048448 \nL 257.495289 150.270328 \nL 258.105237 150.20484 \nL 258.715184 150.314592 \nL 259.325131 150.249369 \nL 260.545025 149.773763 \nL 261.154972 149.88349 \nL 261.76492 149.820413 \nL 262.374867 150.100913 \nL 262.984814 150.037554 \nL 264.814655 150.3583 \nL 266.03455 150.231947 \nL 266.644497 150.505265 \nL 267.254444 150.442022 \nL 267.864391 150.546123 \nL 268.474338 150.483137 \nL 269.084286 150.586485 \nL 269.694233 150.523756 \nL 270.30418 150.131458 \nL 270.914127 150.399415 \nL 271.524074 150.337796 \nL 272.134021 150.440059 \nL 273.963863 151.229509 \nL 274.57381 151.004754 \nL 275.183757 151.264743 \nL 276.403652 151.139359 \nL 277.013599 151.236957 \nL 277.623546 151.174708 \nL 278.233493 151.271652 \nL 279.453387 151.779773 \nL 280.063335 151.559194 \nL 280.673282 151.811005 \nL 281.283229 151.904793 \nL 281.893176 151.841881 \nL 283.723018 152.119855 \nL 284.942912 151.994587 \nL 285.552859 152.086055 \nL 286.162806 152.023864 \nL 286.772753 151.809274 \nL 287.382701 151.443552 \nL 287.992648 151.231721 \nL 288.602595 151.324025 \nL 289.212542 151.56689 \nL 289.822489 151.507118 \nL 290.432436 151.748185 \nL 291.042384 151.838095 \nL 291.652331 152.076975 \nL 292.262278 152.165518 \nL 292.872225 152.402244 \nL 293.482172 152.341205 \nL 294.702067 152.809951 \nL 295.921961 152.39362 \nL 296.531908 152.479703 \nL 297.141855 151.981655 \nL 297.751802 152.213907 \nL 298.36175 152.299783 \nL 300.191591 152.986839 \nL 300.801538 153.069832 \nL 301.411485 153.295689 \nL 302.021433 153.377455 \nL 302.63138 153.601365 \nL 303.241327 153.681939 \nL 303.851274 153.903927 \nL 304.461221 153.983316 \nL 305.681116 153.577904 \nL 306.291063 153.797912 \nL 306.90101 153.876771 \nL 307.510957 153.815549 \nL 308.730851 153.972 \nL 309.340799 154.18828 \nL 310.560693 154.341714 \nL 311.17064 153.867418 \nL 311.780587 153.944545 \nL 313.000482 153.824471 \nL 313.610429 153.628621 \nL 315.44027 153.45257 \nL 316.660165 153.605855 \nL 317.270112 153.547649 \nL 318.490006 153.164796 \nL 319.7099 153.317626 \nL 320.319848 153.260803 \nL 320.929795 153.468998 \nL 321.539742 153.412084 \nL 322.759636 153.561932 \nL 323.369583 153.505208 \nL 324.589478 153.653565 \nL 325.199425 153.857427 \nL 326.419319 154.003107 \nL 327.029266 153.946144 \nL 327.639214 154.018442 \nL 328.859108 153.905236 \nL 329.469055 153.977128 \nL 330.079002 154.176491 \nL 330.688949 153.864891 \nL 331.298897 154.0636 \nL 331.908844 154.134473 \nL 332.518791 154.078379 \nL 333.128738 153.896189 \nL 333.738685 153.966963 \nL 335.568527 153.426068 \nL 336.178474 153.372319 \nL 336.788421 153.443473 \nL 338.008315 153.336622 \nL 339.22821 153.47782 \nL 340.448104 153.863764 \nL 341.058051 153.809999 \nL 341.667998 153.878933 \nL 342.277946 153.825374 \nL 343.49784 153.962265 \nL 344.107787 153.908881 \nL 345.327681 153.561078 \nL 346.547576 153.45696 \nL 347.157523 153.285167 \nL 347.76747 152.994287 \nL 348.377417 153.182905 \nL 348.987365 153.251409 \nL 350.207259 153.14995 \nL 350.817206 152.862466 \nL 351.427153 153.049353 \nL 352.0371 152.999373 \nL 352.647048 153.067396 \nL 353.256995 153.017591 \nL 353.866942 153.08529 \nL 354.476889 153.269742 \nL 355.086836 153.336622 \nL 356.306731 153.004311 \nL 356.916678 152.955267 \nL 358.136572 153.088944 \nL 358.746519 153.270711 \nL 359.966414 152.827928 \nL 360.576361 152.550592 \nL 361.186308 152.503181 \nL 361.796255 152.113493 \nL 362.406202 152.067175 \nL 363.626097 152.202028 \nL 364.845991 152.561776 \nL 366.065885 152.35591 \nL 366.675832 152.309749 \nL 367.28578 152.375875 \nL 367.895727 152.329864 \nL 369.725568 151.970562 \nL 369.725568 151.970562 \n\" style=\"fill:none;stroke:#8c564b;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_22\">\n    <path clip-path=\"url(#pc07f75842b)\" d=\"M 50.14375 147.856501 \nL 384.94375 147.856501 \n\" style=\"fill:none;stroke:#000000;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 50.14375 251.82 \nL 50.14375 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 384.94375 251.82 \nL 384.94375 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 50.14375 251.82 \nL 384.94375 251.82 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 50.14375 7.2 \nL 384.94375 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 302.089063 103.26875 \nL 377.94375 103.26875 \nQ 379.94375 103.26875 379.94375 101.26875 \nL 379.94375 14.2 \nQ 379.94375 12.2 377.94375 12.2 \nL 302.089063 12.2 \nQ 300.089063 12.2 300.089063 14.2 \nL 300.089063 101.26875 \nQ 300.089063 103.26875 302.089063 103.26875 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"line2d_23\">\n     <path d=\"M 304.089063 20.298437 \nL 324.089063 20.298437 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_24\"/>\n    <g id=\"text_18\">\n     <!-- P(die=1) -->\n     <defs>\n      <path d=\"M 19.671875 64.796875 \nL 19.671875 37.40625 \nL 32.078125 37.40625 \nQ 38.96875 37.40625 42.71875 40.96875 \nQ 46.484375 44.53125 46.484375 51.125 \nQ 46.484375 57.671875 42.71875 61.234375 \nQ 38.96875 64.796875 32.078125 64.796875 \nz\nM 9.8125 72.90625 \nL 32.078125 72.90625 \nQ 44.34375 72.90625 50.609375 67.359375 \nQ 56.890625 61.8125 56.890625 51.125 \nQ 56.890625 40.328125 50.609375 34.8125 \nQ 44.34375 29.296875 32.078125 29.296875 \nL 19.671875 29.296875 \nL 19.671875 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-80\"/>\n      <path d=\"M 31 75.875 \nQ 24.46875 64.65625 21.28125 53.65625 \nQ 18.109375 42.671875 18.109375 31.390625 \nQ 18.109375 20.125 21.3125 9.0625 \nQ 24.515625 -2 31 -13.1875 \nL 23.1875 -13.1875 \nQ 15.875 -1.703125 12.234375 9.375 \nQ 8.59375 20.453125 8.59375 31.390625 \nQ 8.59375 42.28125 12.203125 53.3125 \nQ 15.828125 64.359375 23.1875 75.875 \nz\n\" id=\"DejaVuSans-40\"/>\n      <path d=\"M 10.59375 45.40625 \nL 73.1875 45.40625 \nL 73.1875 37.203125 \nL 10.59375 37.203125 \nz\nM 10.59375 25.484375 \nL 73.1875 25.484375 \nL 73.1875 17.1875 \nL 10.59375 17.1875 \nz\n\" id=\"DejaVuSans-61\"/>\n      <path d=\"M 8.015625 75.875 \nL 15.828125 75.875 \nQ 23.140625 64.359375 26.78125 53.3125 \nQ 30.421875 42.28125 30.421875 31.390625 \nQ 30.421875 20.453125 26.78125 9.375 \nQ 23.140625 -1.703125 15.828125 -13.1875 \nL 8.015625 -13.1875 \nQ 14.5 -2 17.703125 9.0625 \nQ 20.90625 20.125 20.90625 31.390625 \nQ 20.90625 42.671875 17.703125 53.65625 \nQ 14.5 64.65625 8.015625 75.875 \nz\n\" id=\"DejaVuSans-41\"/>\n     </defs>\n     <g transform=\"translate(332.089063 23.798437)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-80\"/>\n      <use x=\"60.302734\" xlink:href=\"#DejaVuSans-40\"/>\n      <use x=\"99.316406\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"162.792969\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"190.576172\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"252.099609\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"335.888672\" xlink:href=\"#DejaVuSans-49\"/>\n      <use x=\"399.511719\" xlink:href=\"#DejaVuSans-41\"/>\n     </g>\n    </g>\n    <g id=\"line2d_25\">\n     <path d=\"M 304.089063 34.976562 \nL 324.089063 34.976562 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_26\"/>\n    <g id=\"text_19\">\n     <!-- P(die=2) -->\n     <g transform=\"translate(332.089063 38.476562)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-80\"/>\n      <use x=\"60.302734\" xlink:href=\"#DejaVuSans-40\"/>\n      <use x=\"99.316406\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"162.792969\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"190.576172\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"252.099609\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"335.888672\" xlink:href=\"#DejaVuSans-50\"/>\n      <use x=\"399.511719\" xlink:href=\"#DejaVuSans-41\"/>\n     </g>\n    </g>\n    <g id=\"line2d_27\">\n     <path d=\"M 304.089063 49.654687 \nL 324.089063 49.654687 \n\" style=\"fill:none;stroke:#2ca02c;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_28\"/>\n    <g id=\"text_20\">\n     <!-- P(die=3) -->\n     <g transform=\"translate(332.089063 53.154687)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-80\"/>\n      <use x=\"60.302734\" xlink:href=\"#DejaVuSans-40\"/>\n      <use x=\"99.316406\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"162.792969\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"190.576172\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"252.099609\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"335.888672\" xlink:href=\"#DejaVuSans-51\"/>\n      <use x=\"399.511719\" xlink:href=\"#DejaVuSans-41\"/>\n     </g>\n    </g>\n    <g id=\"line2d_29\">\n     <path d=\"M 304.089063 64.332812 \nL 324.089063 64.332812 \n\" style=\"fill:none;stroke:#d62728;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_30\"/>\n    <g id=\"text_21\">\n     <!-- P(die=4) -->\n     <g transform=\"translate(332.089063 67.832812)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-80\"/>\n      <use x=\"60.302734\" xlink:href=\"#DejaVuSans-40\"/>\n      <use x=\"99.316406\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"162.792969\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"190.576172\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"252.099609\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"335.888672\" xlink:href=\"#DejaVuSans-52\"/>\n      <use x=\"399.511719\" xlink:href=\"#DejaVuSans-41\"/>\n     </g>\n    </g>\n    <g id=\"line2d_31\">\n     <path d=\"M 304.089063 79.010937 \nL 324.089063 79.010937 \n\" style=\"fill:none;stroke:#9467bd;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_32\"/>\n    <g id=\"text_22\">\n     <!-- P(die=5) -->\n     <g transform=\"translate(332.089063 82.510937)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-80\"/>\n      <use x=\"60.302734\" xlink:href=\"#DejaVuSans-40\"/>\n      <use x=\"99.316406\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"162.792969\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"190.576172\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"252.099609\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"335.888672\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"399.511719\" xlink:href=\"#DejaVuSans-41\"/>\n     </g>\n    </g>\n    <g id=\"line2d_33\">\n     <path d=\"M 304.089063 93.689062 \nL 324.089063 93.689062 \n\" style=\"fill:none;stroke:#8c564b;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_34\"/>\n    <g id=\"text_23\">\n     <!-- P(die=6) -->\n     <defs>\n      <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n     </defs>\n     <g transform=\"translate(332.089063 97.189062)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-80\"/>\n      <use x=\"60.302734\" xlink:href=\"#DejaVuSans-40\"/>\n      <use x=\"99.316406\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"162.792969\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"190.576172\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"252.099609\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"335.888672\" xlink:href=\"#DejaVuSans-54\"/>\n      <use x=\"399.511719\" xlink:href=\"#DejaVuSans-41\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pc07f75842b\">\n   <rect height=\"244.62\" width=\"334.8\" x=\"50.14375\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
            "text/plain": [
              "<Figure size 432x324 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light",
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "counts = multinomial.Multinomial(10, fair_probs).sample((500,))\n",
        "cum_counts = counts.cumsum(dim=0)\n",
        "estimates = cum_counts / cum_counts.sum(dim=1, keepdims=True)\n",
        "\n",
        "d2l.set_figsize((6, 4.5))\n",
        "for i in range(6):\n",
        "    d2l.plt.plot(estimates[:, i].numpy(), label=(\"P(die=\" + str(i + 1) + \")\"))\n",
        "d2l.plt.axhline(y=0.167, color='black', linestyle='dashed')\n",
        "d2l.plt.gca().set_xlabel('Groups of experiments')\n",
        "d2l.plt.gca().set_ylabel('Estimated probability')\n",
        "d2l.plt.legend();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Prf8Y3N8IH9W",
        "outputId": "cee7c2bc-dd67-47a2-a244-2cf43d595d5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Help on class Multinomial in module torch.distributions.multinomial:\n",
            "\n",
            "class Multinomial(torch.distributions.distribution.Distribution)\n",
            " |  Multinomial(total_count=1, probs=None, logits=None, validate_args=None)\n",
            " |  \n",
            " |  Creates a Multinomial distribution parameterized by :attr:`total_count` and\n",
            " |  either :attr:`probs` or :attr:`logits` (but not both). The innermost dimension of\n",
            " |  :attr:`probs` indexes over categories. All other dimensions index over batches.\n",
            " |  \n",
            " |  Note that :attr:`total_count` need not be specified if only :meth:`log_prob` is\n",
            " |  called (see example below)\n",
            " |  \n",
            " |  .. note:: The `probs` argument must be non-negative, finite and have a non-zero sum,\n",
            " |            and it will be normalized to sum to 1 along the last dimension. attr:`probs`\n",
            " |            will return this normalized value.\n",
            " |            The `logits` argument will be interpreted as unnormalized log probabilities\n",
            " |            and can therefore be any real number. It will likewise be normalized so that\n",
            " |            the resulting probabilities sum to 1 along the last dimension. attr:`logits`\n",
            " |            will return this normalized value.\n",
            " |  \n",
            " |  -   :meth:`sample` requires a single shared `total_count` for all\n",
            " |      parameters and samples.\n",
            " |  -   :meth:`log_prob` allows different `total_count` for each parameter and\n",
            " |      sample.\n",
            " |  \n",
            " |  Example::\n",
            " |  \n",
            " |      >>> m = Multinomial(100, torch.tensor([ 1., 1., 1., 1.]))\n",
            " |      >>> x = m.sample()  # equal probability of 0, 1, 2, 3\n",
            " |      tensor([ 21.,  24.,  30.,  25.])\n",
            " |  \n",
            " |      >>> Multinomial(probs=torch.tensor([1., 1., 1., 1.])).log_prob(x)\n",
            " |      tensor([-4.1338])\n",
            " |  \n",
            " |  Args:\n",
            " |      total_count (int): number of trials\n",
            " |      probs (Tensor): event probabilities\n",
            " |      logits (Tensor): event log probabilities (unnormalized)\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      Multinomial\n",
            " |      torch.distributions.distribution.Distribution\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self, total_count=1, probs=None, logits=None, validate_args=None)\n",
            " |      Initialize self.  See help(type(self)) for accurate signature.\n",
            " |  \n",
            " |  expand(self, batch_shape, _instance=None)\n",
            " |      Returns a new distribution instance (or populates an existing instance\n",
            " |      provided by a derived class) with batch dimensions expanded to\n",
            " |      `batch_shape`. This method calls :class:`~torch.Tensor.expand` on\n",
            " |      the distribution's parameters. As such, this does not allocate new\n",
            " |      memory for the expanded distribution instance. Additionally,\n",
            " |      this does not repeat any args checking or parameter broadcasting in\n",
            " |      `__init__.py`, when an instance is first created.\n",
            " |      \n",
            " |      Args:\n",
            " |          batch_shape (torch.Size): the desired expanded size.\n",
            " |          _instance: new instance provided by subclasses that\n",
            " |              need to override `.expand`.\n",
            " |      \n",
            " |      Returns:\n",
            " |          New distribution instance with batch dimensions expanded to\n",
            " |          `batch_size`.\n",
            " |  \n",
            " |  log_prob(self, value)\n",
            " |      Returns the log of the probability density/mass function evaluated at\n",
            " |      `value`.\n",
            " |      \n",
            " |      Args:\n",
            " |          value (Tensor):\n",
            " |  \n",
            " |  sample(self, sample_shape=torch.Size([]))\n",
            " |      Generates a sample_shape shaped sample or sample_shape shaped batch of\n",
            " |      samples if the distribution parameters are batched.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors defined here:\n",
            " |  \n",
            " |  logits\n",
            " |  \n",
            " |  mean\n",
            " |      Returns the mean of the distribution.\n",
            " |  \n",
            " |  param_shape\n",
            " |  \n",
            " |  probs\n",
            " |  \n",
            " |  support\n",
            " |      Returns a :class:`~torch.distributions.constraints.Constraint` object\n",
            " |      representing this distribution's support.\n",
            " |  \n",
            " |  variance\n",
            " |      Returns the variance of the distribution.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data and other attributes defined here:\n",
            " |  \n",
            " |  __annotations__ = {'total_count': <class 'int'>}\n",
            " |  \n",
            " |  arg_constraints = {'logits': IndependentConstraint(Real(), 1), 'probs'...\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from torch.distributions.distribution.Distribution:\n",
            " |  \n",
            " |  __repr__(self)\n",
            " |      Return repr(self).\n",
            " |  \n",
            " |  cdf(self, value)\n",
            " |      Returns the cumulative density/mass function evaluated at\n",
            " |      `value`.\n",
            " |      \n",
            " |      Args:\n",
            " |          value (Tensor):\n",
            " |  \n",
            " |  entropy(self)\n",
            " |      Returns entropy of distribution, batched over batch_shape.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Tensor of shape batch_shape.\n",
            " |  \n",
            " |  enumerate_support(self, expand=True)\n",
            " |      Returns tensor containing all values supported by a discrete\n",
            " |      distribution. The result will enumerate over dimension 0, so the shape\n",
            " |      of the result will be `(cardinality,) + batch_shape + event_shape`\n",
            " |      (where `event_shape = ()` for univariate distributions).\n",
            " |      \n",
            " |      Note that this enumerates over all batched tensors in lock-step\n",
            " |      `[[0, 0], [1, 1], ...]`. With `expand=False`, enumeration happens\n",
            " |      along dim 0, but with the remaining batch dimensions being\n",
            " |      singleton dimensions, `[[0], [1], ..`.\n",
            " |      \n",
            " |      To iterate over the full Cartesian product use\n",
            " |      `itertools.product(m.enumerate_support())`.\n",
            " |      \n",
            " |      Args:\n",
            " |          expand (bool): whether to expand the support over the\n",
            " |              batch dims to match the distribution's `batch_shape`.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Tensor iterating over dimension 0.\n",
            " |  \n",
            " |  icdf(self, value)\n",
            " |      Returns the inverse cumulative density/mass function evaluated at\n",
            " |      `value`.\n",
            " |      \n",
            " |      Args:\n",
            " |          value (Tensor):\n",
            " |  \n",
            " |  perplexity(self)\n",
            " |      Returns perplexity of distribution, batched over batch_shape.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Tensor of shape batch_shape.\n",
            " |  \n",
            " |  rsample(self, sample_shape=torch.Size([]))\n",
            " |      Generates a sample_shape shaped reparameterized sample or sample_shape\n",
            " |      shaped batch of reparameterized samples if the distribution parameters\n",
            " |      are batched.\n",
            " |  \n",
            " |  sample_n(self, n)\n",
            " |      Generates n samples or n batches of samples if the distribution\n",
            " |      parameters are batched.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Static methods inherited from torch.distributions.distribution.Distribution:\n",
            " |  \n",
            " |  set_default_validate_args(value)\n",
            " |      Sets whether validation is enabled or disabled.\n",
            " |      \n",
            " |      The default behavior mimics Python's ``assert`` statement: validation\n",
            " |      is on by default, but is disabled if Python is run in optimized mode\n",
            " |      (via ``python -O``). Validation may be expensive, so you may want to\n",
            " |      disable it once a model is working.\n",
            " |      \n",
            " |      Args:\n",
            " |          value (bool): Whether to enable validation.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from torch.distributions.distribution.Distribution:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            " |  \n",
            " |  batch_shape\n",
            " |      Returns the shape over which parameters are batched.\n",
            " |  \n",
            " |  event_shape\n",
            " |      Returns the shape of a single sample (without batching).\n",
            " |  \n",
            " |  stddev\n",
            " |      Returns the standard deviation of the distribution.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data and other attributes inherited from torch.distributions.distribution.Distribution:\n",
            " |  \n",
            " |  has_enumerate_support = False\n",
            " |  \n",
            " |  has_rsample = False\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(multinomial.Multinomial)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SB4y7vIJALIG"
      },
      "source": [
        "다항분포를 만드는 multinomial.Multinomial().sample로부터 시행을 한 뒤 각각의 경우의 수가 tensor의 element값으로 나오는 것을 확인 할 수 있었고 그것을 통해 주사위 던지는 것을 1000번 시행하고서 그것을 1000으로 다시 나눠줌으로써 예상했던 각각 1/6에근사한 값이 나오는 결과를 확인할 수 있었습니다. 해당 내용을 자세히 공부하여 카테고리를 정의한 모델을 사용할 때 그 카테고리를 벗어난 입력이 들어왔을 때도 probability 개념을 잘 활용하여 해석하는데 도움이 되었으면 합니다."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Untitled0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
