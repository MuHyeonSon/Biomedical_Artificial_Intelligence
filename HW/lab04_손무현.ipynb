{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "UEkDCgnpN97T"
      },
      "source": [
        "바이오메디컬인공지능 개인과제6\n",
        "\n",
        "바이오메디컬공학부 2018----- 손무현"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vY0VnfgjHFwd"
      },
      "source": [
        "## Sequence-to-sequence model로 언어 번역하기\n",
        "\n",
        "\n",
        "- https://tutorials.pytorch.kr/beginner/torchtext_translation.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVnmsSeU8WA-",
        "outputId": "d66b7cd6-5809-45f4-d8e6-296986934b2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.7/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (57.0.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n",
            "Collecting de_core_news_sm==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.2.5/de_core_news_sm-2.2.5.tar.gz (14.9MB)\n",
            "\u001b[K     |████████████████████████████████| 14.9MB 8.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from de_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (57.0.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (4.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.4.1)\n",
            "Building wheels for collected packages: de-core-news-sm\n",
            "  Building wheel for de-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for de-core-news-sm: filename=de_core_news_sm-2.2.5-cp37-none-any.whl size=14907055 sha256=d2c565b0447c641e31f3d6b3d5a41a414ad2115f33fee5830024cf05cda8c1bc\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-evp8_lrl/wheels/ba/3f/ed/d4aa8e45e7191b7f32db4bfad565e7da1edbf05c916ca7a1ca\n",
            "Successfully built de-core-news-sm\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/de_core_news_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/de\n",
            "You can now load the model via spacy.load('de')\n"
          ]
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "!python -m spacy download en\n",
        "!python -m spacy download de"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5Fg8tCxX8k9I"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torchtext\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from collections import Counter\n",
        "from torchtext.vocab import Vocab\n",
        "from torchtext.utils import download_from_url, extract_archive\n",
        "from torch import Tensor\n",
        "import io\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "XorQICkEEB_E"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "en_tokenizer = get_tokenizer('spacy', language='en')\n",
        "de_tokenizer = get_tokenizer('spacy', language='de')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVmraSX6Gvhs"
      },
      "source": [
        "### 텍스트파일의 전처리\n",
        "- 아래의 코드는 text file을 전처리하는 과정을 담고 있으나, 실행시간이 길어 미리 처리한 파일을 불러오도록 주석처리를 하였습니다.\n",
        "- 다른 text파일을 활용하여 실습을 진행하고 싶은 경우, 아래의 코드를 이해하여 전처리 과정을 수행하여야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "id": "_MXJ1c7QGunm",
        "outputId": "ecb07ff8-c25f-4201-fccd-6069814d5c6c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n\\nurl_base = \\'https://raw.githubusercontent.com/multi30k/dataset/master/data/task1/raw/\\'\\ntrain_urls = (\\'train.de.gz\\', \\'train.en.gz\\')\\nval_urls = (\\'val.de.gz\\', \\'val.en.gz\\')\\ntest_urls = (\\'test_2016_flickr.de.gz\\', \\'test_2016_flickr.en.gz\\')\\n\\ntrain_filepaths = [extract_archive(download_from_url(url_base + url))[0] for url in train_urls]\\nval_filepaths = [extract_archive(download_from_url(url_base + url))[0] for url in val_urls]\\ntest_filepaths = [extract_archive(download_from_url(url_base + url))[0] for url in test_urls]\\n\\ndef build_vocab(filepath, tokenizer):\\n  counter = Counter()\\n  with io.open(filepath, encoding=\"utf8\") as f:\\n    for string_ in f:\\n      counter.update(tokenizer(string_))\\n  return Vocab(counter, specials=[\\'<unk>\\', \\'<pad>\\', \\'<bos>\\', \\'<eos>\\'])\\n\\ndef data_process(filepaths):\\n  raw_de_iter = iter(io.open(filepaths[0], encoding=\"utf8\"))\\n  raw_en_iter = iter(io.open(filepaths[1], encoding=\"utf8\"))\\n  data = []\\n  for (raw_de, raw_en) in zip(raw_de_iter, raw_en_iter):\\n    de_tensor_ = torch.tensor([de_vocab[token] for token in de_tokenizer(raw_de)],\\n                            dtype=torch.long)\\n    en_tensor_ = torch.tensor([en_vocab[token] for token in en_tokenizer(raw_en)],\\n                            dtype=torch.long)\\n    data.append((de_tensor_, en_tensor_))\\n  return data\\n\\n\\nde_vocab = build_vocab(train_filepaths[0], de_tokenizer)\\nen_vocab = build_vocab(train_filepaths[1], en_tokenizer)\\n\\ntrain_data = data_process(train_filepaths)\\nval_data = data_process(val_filepaths)\\n\\n'"
            ]
          },
          "execution_count": 6,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "\n",
        "url_base = 'https://raw.githubusercontent.com/multi30k/dataset/master/data/task1/raw/'\n",
        "train_urls = ('train.de.gz', 'train.en.gz')\n",
        "val_urls = ('val.de.gz', 'val.en.gz')\n",
        "test_urls = ('test_2016_flickr.de.gz', 'test_2016_flickr.en.gz')\n",
        "\n",
        "train_filepaths = [extract_archive(download_from_url(url_base + url))[0] for url in train_urls]\n",
        "val_filepaths = [extract_archive(download_from_url(url_base + url))[0] for url in val_urls]\n",
        "test_filepaths = [extract_archive(download_from_url(url_base + url))[0] for url in test_urls]\n",
        "\n",
        "def build_vocab(filepath, tokenizer):\n",
        "  counter = Counter()\n",
        "  with io.open(filepath, encoding=\"utf8\") as f:\n",
        "    for string_ in f:\n",
        "      counter.update(tokenizer(string_))\n",
        "  return Vocab(counter, specials=['<unk>', '<pad>', '<bos>', '<eos>'])\n",
        "\n",
        "def data_process(filepaths):\n",
        "  raw_de_iter = iter(io.open(filepaths[0], encoding=\"utf8\"))\n",
        "  raw_en_iter = iter(io.open(filepaths[1], encoding=\"utf8\"))\n",
        "  data = []\n",
        "  for (raw_de, raw_en) in zip(raw_de_iter, raw_en_iter):\n",
        "    de_tensor_ = torch.tensor([de_vocab[token] for token in de_tokenizer(raw_de)],\n",
        "                            dtype=torch.long)\n",
        "    en_tensor_ = torch.tensor([en_vocab[token] for token in en_tokenizer(raw_en)],\n",
        "                            dtype=torch.long)\n",
        "    data.append((de_tensor_, en_tensor_))\n",
        "  return data\n",
        "\n",
        "\n",
        "de_vocab = build_vocab(train_filepaths[0], de_tokenizer)\n",
        "en_vocab = build_vocab(train_filepaths[1], en_tokenizer)\n",
        "\n",
        "train_data = data_process(train_filepaths)\n",
        "val_data = data_process(val_filepaths)\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUqEffQ4HgnC"
      },
      "source": [
        "## 학습에 사용할 Data를 가져오기\n",
        "- 미리 만들어 놓은 vocab, tokenized data를 불러옵니다.\n",
        "- 실습데이터를 올려놓은 구글드라이브 경로를 설정하여 가져옵니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "70BIqwfK9Cq4"
      },
      "outputs": [],
      "source": [
        "path0 = '/content/drive/MyDrive/de2en/'\n",
        "de_vocab=torch.load(path0+'de_vocab.pt')\n",
        "en_vocab=torch.load(path0+'en_vocab.pt')\n",
        "train_data = torch.load(path0+'train_data.pt')\n",
        "val_data = torch.load(path0+'val_data.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_1H8bsBzwFl",
        "outputId": "4b61303b-eafc-40d7-dcdf-a15b3a7afc1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9UjN4YDHypA"
      },
      "source": [
        "## 모델 및 학습을 위한 함수들의 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5n0pkca9Mmu",
        "outputId": "f658be02-cb0f-45cd-e19b-1f1c19f1d65d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cMPo5rAA9rG4"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "PAD_IDX = de_vocab['<pad>']\n",
        "BOS_IDX = de_vocab['<bos>']\n",
        "EOS_IDX = de_vocab['<eos>']\n",
        "\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def generate_batch(data_batch):\n",
        "  de_batch, en_batch = [], []\n",
        "  for (de_item, en_item) in data_batch:\n",
        "    de_batch.append(torch.cat([torch.tensor([BOS_IDX]), de_item, torch.tensor([EOS_IDX])], dim=0))\n",
        "    en_batch.append(torch.cat([torch.tensor([BOS_IDX]), en_item, torch.tensor([EOS_IDX])], dim=0))\n",
        "  de_batch = pad_sequence(de_batch, padding_value=PAD_IDX)\n",
        "  en_batch = pad_sequence(en_batch, padding_value=PAD_IDX)\n",
        "  return en_batch, de_batch\n",
        "\n",
        "train_iter = DataLoader(train_data, batch_size=BATCH_SIZE,\n",
        "                        shuffle=True, collate_fn=generate_batch)\n",
        "valid_iter = DataLoader(val_data, batch_size=BATCH_SIZE,\n",
        "                        shuffle=True, collate_fn=generate_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "9TP76Afj92lo"
      },
      "outputs": [],
      "source": [
        "from torch.nn import (TransformerEncoder, TransformerDecoder,\n",
        "                      TransformerEncoderLayer, TransformerDecoderLayer)\n",
        "\n",
        "class Seq2SeqTransformer(nn.Module):\n",
        "    def __init__(self, num_encoder_layers: int, num_decoder_layers: int,\n",
        "                 emb_size: int, src_vocab_size: int, tgt_vocab_size: int,\n",
        "                 dim_feedforward:int = 512, dropout:float = 0.1):\n",
        "        super(Seq2SeqTransformer, self).__init__()\n",
        "        encoder_layer = TransformerEncoderLayer(d_model=emb_size, nhead=NHEAD,\n",
        "                                                dim_feedforward=dim_feedforward)\n",
        "        self.transformer_encoder = TransformerEncoder(encoder_layer, num_layers=num_encoder_layers)\n",
        "        decoder_layer = TransformerDecoderLayer(d_model=emb_size, nhead=NHEAD,\n",
        "                                                dim_feedforward=dim_feedforward)\n",
        "        self.transformer_decoder = TransformerDecoder(decoder_layer, num_layers=num_decoder_layers)\n",
        "                \n",
        "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
        "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
        "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
        "        self.positional_encoding = PositionalEncoding(emb_size, dropout=dropout)\n",
        "\n",
        "    def forward(self, src: Tensor, trg: Tensor, src_mask: Tensor,\n",
        "                tgt_mask: Tensor, src_padding_mask: Tensor,\n",
        "                tgt_padding_mask: Tensor, memory_key_padding_mask: Tensor):\n",
        "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
        "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
        "        memory = self.transformer_encoder(src_emb, src_mask, src_padding_mask)\n",
        "        outs = self.transformer_decoder(tgt_emb, memory, tgt_mask, None,\n",
        "                                        tgt_padding_mask, memory_key_padding_mask)\n",
        "        return self.generator(outs)\n",
        "\n",
        "    def encode(self, src: Tensor, src_mask: Tensor):\n",
        "        return self.transformer_encoder(self.positional_encoding(\n",
        "                            self.src_tok_emb(src)), src_mask)\n",
        "\n",
        "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
        "        return self.transformer_decoder(self.positional_encoding(\n",
        "                          self.tgt_tok_emb(tgt)), memory,\n",
        "                          tgt_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "fys-TREg-H_b"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, emb_size: int, dropout, maxlen: int = 5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        den = torch.exp(- torch.arange(0, emb_size, 2) * math.log(10000) / emb_size)\n",
        "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
        "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
        "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
        "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
        "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer('pos_embedding', pos_embedding)\n",
        "\n",
        "    def forward(self, token_embedding: Tensor):\n",
        "        return self.dropout(token_embedding + \n",
        "                            self.pos_embedding[:token_embedding.size(0),:])\n",
        "\n",
        "class TokenEmbedding(nn.Module):\n",
        "    def __init__(self, vocab_size: int, emb_size):\n",
        "        super(TokenEmbedding, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
        "        self.emb_size = emb_size\n",
        "    def forward(self, tokens: Tensor):\n",
        "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "CXJg3_ys-Vdd"
      },
      "outputs": [],
      "source": [
        "def generate_square_subsequent_mask(sz):\n",
        "    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n",
        "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "    return mask\n",
        "\n",
        "def create_mask(src, tgt):\n",
        "  src_seq_len = src.shape[0]\n",
        "  tgt_seq_len = tgt.shape[0]\n",
        "\n",
        "  tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
        "  src_mask = torch.zeros((src_seq_len, src_seq_len), device=DEVICE).type(torch.bool)\n",
        "\n",
        "  src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
        "  tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
        "  return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "ibRlojEt-XS5"
      },
      "outputs": [],
      "source": [
        "SRC_VOCAB_SIZE = len(en_vocab)\n",
        "TGT_VOCAB_SIZE = len(de_vocab)\n",
        "EMB_SIZE = 512\n",
        "NHEAD = 8\n",
        "FFN_HID_DIM = 512\n",
        "BATCH_SIZE = 64\n",
        "NUM_ENCODER_LAYERS = 3\n",
        "NUM_DECODER_LAYERS = 3\n",
        "NUM_EPOCHS = 10\n",
        "\n",
        "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, \n",
        "                                 EMB_SIZE, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE,\n",
        "                                 FFN_HID_DIM)\n",
        "\n",
        "for p in transformer.parameters():\n",
        "    if p.dim() > 1:\n",
        "        nn.init.xavier_uniform_(p)\n",
        "\n",
        "transformer = transformer.to(device)\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
        "\n",
        "optimizer = torch.optim.Adam(\n",
        "    transformer.parameters(), lr=0.000011, betas=(0.9, 0.98), eps=1e-9\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "k-Kw9qmK-ZgP"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model, train_iter, optimizer):\n",
        "  model.train()\n",
        "  losses = 0\n",
        "  for idx, (src, tgt) in enumerate(train_iter):\n",
        "      src = src.to(device)\n",
        "      tgt = tgt.to(device)\n",
        "            \n",
        "      tgt_input = tgt[:-1, :]\n",
        "\n",
        "      src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
        "\n",
        "      logits = model(src, tgt_input, src_mask, tgt_mask,\n",
        "                                src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
        "      \n",
        "      optimizer.zero_grad()\n",
        "      \n",
        "      tgt_out = tgt[1:,:]\n",
        "      loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
        "      loss.backward()\n",
        "\n",
        "      optimizer.step()\n",
        "      losses += loss.item()\n",
        "  return losses / len(train_iter)\n",
        "\n",
        "\n",
        "def evaluate(model, val_iter):\n",
        "  model.eval()\n",
        "  losses = 0\n",
        "  for idx, (src, tgt) in (enumerate(valid_iter)):\n",
        "    src = src.to(device)\n",
        "    tgt = tgt.to(device)\n",
        "\n",
        "    tgt_input = tgt[:-1, :]\n",
        "\n",
        "    src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
        "\n",
        "    logits = model(src, tgt_input, src_mask, tgt_mask,\n",
        "                              src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
        "    tgt_out = tgt[1:,:]\n",
        "    loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
        "    losses += loss.item()\n",
        "  return losses / len(val_iter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "SopNzBza-hi6"
      },
      "outputs": [],
      "source": [
        "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
        "    src = src.to(device)\n",
        "    src_mask = src_mask.to(device)\n",
        "\n",
        "    memory = model.encode(src, src_mask)\n",
        "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(device)\n",
        "    for i in range(max_len-1):\n",
        "        memory = memory.to(device)\n",
        "        memory_mask = torch.zeros(ys.shape[0], memory.shape[0]).to(device).type(torch.bool)\n",
        "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
        "                                    .type(torch.bool)).to(device)\n",
        "        out = model.decode(ys, memory, tgt_mask)\n",
        "        out = out.transpose(0, 1)\n",
        "        prob = model.generator(out[:, -1])\n",
        "        _, next_word = torch.max(prob, dim = 1)\n",
        "        next_word = next_word.item()\n",
        "\n",
        "        ys = torch.cat([ys,\n",
        "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
        "        if next_word == EOS_IDX:\n",
        "          break\n",
        "    return ys\n",
        "\n",
        "\n",
        "def translate(model, src, src_vocab, tgt_vocab, src_tokenizer):\n",
        "  model.eval()\n",
        "  tokens = [BOS_IDX] + [src_vocab.stoi[tok] for tok in src_tokenizer(src)]+ [EOS_IDX]\n",
        "  num_tokens = len(tokens)\n",
        "  src = (torch.LongTensor(tokens).reshape(num_tokens, 1) )\n",
        "  src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
        "  tgt_tokens = greedy_decode(model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
        "  return \" \".join([tgt_vocab.itos[tok] for tok in tgt_tokens]).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "secvtKhTH4cK"
      },
      "source": [
        "학습이 진행되기 전에 결과를 확인해 봅니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "pcKCHqU2-sVf",
        "outputId": "281149c5-7a34-4ef3-bd3e-2f9d0feb2a45"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' Bühnenmitte Fußböden backen backen backen backen backen backen Bewässerungsschlauch Bühnenmitte Fußböden backen backen backen backen'"
            ]
          },
          "execution_count": 24,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "translate(transformer, \"Eine Gruppe von Menschen steht vor einem Iglu .\", en_vocab, de_vocab, en_tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atL9kvRPH_ZH"
      },
      "source": [
        "## 모델을 학습시키기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8eYSHpx-dE-",
        "outputId": "ef8d1540-18f5-4919-f4f5-73291ff31144"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1, Train loss: 2.286, Val loss: 2.510, Epoch time = 49.139s\n",
            "Epoch: 2, Train loss: 2.251, Val loss: 2.478, Epoch time = 48.451s\n",
            "Epoch: 3, Train loss: 2.217, Val loss: 2.453, Epoch time = 48.824s\n",
            "Epoch: 4, Train loss: 2.186, Val loss: 2.434, Epoch time = 48.669s\n",
            "Epoch: 5, Train loss: 2.155, Val loss: 2.407, Epoch time = 48.761s\n",
            "Epoch: 6, Train loss: 2.125, Val loss: 2.378, Epoch time = 48.655s\n",
            "Epoch: 7, Train loss: 2.094, Val loss: 2.366, Epoch time = 48.673s\n",
            "Epoch: 8, Train loss: 2.067, Val loss: 2.349, Epoch time = 48.752s\n",
            "Epoch: 9, Train loss: 2.042, Val loss: 2.323, Epoch time = 48.730s\n",
            "Epoch: 10, Train loss: 2.013, Val loss: 2.307, Epoch time = 48.647s\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(1, NUM_EPOCHS+1):\n",
        "  start_time = time.time()\n",
        "  train_loss = train_epoch(transformer, train_iter, optimizer)\n",
        "  end_time = time.time()\n",
        "  val_loss = evaluate(transformer, valid_iter)\n",
        "  print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"\n",
        "          f\"Epoch time = {(end_time - start_time):.3f}s\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KyFq8hXQLsgx"
      },
      "outputs": [],
      "source": [
        "#torch.save(transformer.state_dict(),path0+'en2de.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMhp9U_HL5Ck"
      },
      "outputs": [],
      "source": [
        "#transformer.load_state_dict(torch.load(path0+'en2de.pth'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_F7z_eOICz3"
      },
      "source": [
        "## 학습이 완료된 모델을 활용하여 독일어에 대한 영어번역결과를 확인하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "1dOrlcofPUUP",
        "outputId": "3d502e69-4ee8-4ce5-caab-3433ad6f22b9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' Ein Surfer , der einen Jungen auf der Junge klettert'"
            ]
          },
          "execution_count": 48,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "translate(transformer, \"I am a boy\", en_vocab, de_vocab, en_tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQk9u32vNqkI"
      },
      "source": [
        "- 최종 모델에 사용한 Hyperparameter의 값들\n",
        "\n",
        "EMB_SIZE = 512\n",
        "\n",
        "NHEAD = 8\n",
        "\n",
        "FFN_HID_DIM = 512\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "NUM_ENCODER_LAYERS = 3\n",
        "\n",
        "NUM_DECODER_LAYERS = 3\n",
        "\n",
        "NUM_EPOCHS = 10\n",
        "\n",
        "lr=0.000011\n",
        "\n",
        "BATCH_SIZE와 인코더 디코더의 layer number, 그리고 NHEAD를 변경해가며 training을 시도했지만 loss값이 적절하게 나오지 않아 learning rate를 변경해가며 parameter를 update하였습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZpTCyhVNsl8"
      },
      "source": [
        "- Training 과정에서의 epoch별 loss 변화\n",
        "\n",
        "Epoch: 1, Train loss: 2.286, Val loss: 2.510, Epoch time = 49.139s\n",
        "\n",
        "Epoch: 2, Train loss: 2.251, Val loss: 2.478, Epoch time = 48.451s\n",
        "\n",
        "Epoch: 3, Train loss: 2.217, Val loss: 2.453, Epoch time = 48.824s\n",
        "\n",
        "Epoch: 4, Train loss: 2.186, Val loss: 2.434, Epoch time = 48.669s\n",
        "\n",
        "Epoch: 5, Train loss: 2.155, Val loss: 2.407, Epoch time = 48.761s\n",
        "\n",
        "Epoch: 6, Train loss: 2.125, Val loss: 2.378, Epoch time = 48.655s\n",
        "\n",
        "Epoch: 7, Train loss: 2.094, Val loss: 2.366, Epoch time = 48.673s\n",
        "\n",
        "Epoch: 8, Train loss: 2.067, Val loss: 2.349, Epoch time = 48.752s\n",
        "\n",
        "Epoch: 9, Train loss: 2.042, Val loss: 2.323, Epoch time = 48.730s\n",
        "\n",
        "Epoch: 10, Train loss: 2.013, Val loss: 2.307, Epoch time = 48.647s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJwAowNjNxfG"
      },
      "source": [
        "- 비교적 번역이 괜찮은 문장을 최소 2개 이상 (구글번역과 결과 비교)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "kFsvFU7gI7x7",
        "outputId": "ad7e09d5-dcb8-4f5a-e55f-1987ed74b9c1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' Ein Arzt rollt einen Jungen . \\n '"
            ]
          },
          "execution_count": 39,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "translate(transformer, \"I am a boy\", en_vocab, de_vocab, en_tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "gMS-G0TTkO-n",
        "outputId": "2d4bfab8-967c-4a72-dd2a-ce54c7c485a0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' Ein Hügel befindet sich einem Apfel . \\n '"
            ]
          },
          "execution_count": 37,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "translate(transformer, \"it is an apple\", en_vocab, de_vocab, en_tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dJVcbvGN1U2"
      },
      "source": [
        "- 번역이 매우 좋지 않은 문장을 최소 2개 이상 (구글번역과 결과 비교)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "l77SW0qcMXB9",
        "outputId": "335aa8ba-33e3-4059-c7a0-5bfbbd11f872"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' Das Bild , die wie man ein Schäferhund unter dem Fell machen , was es schneit .'"
            ]
          },
          "execution_count": 36,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "translate(transformer, \"If you don't risk anything you risk even more.\", en_vocab, de_vocab, en_tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "xNaUl_dHGz2y",
        "outputId": "8c035980-a5af-4acf-a832-8697b0de0733"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' Ein Ein Ein Ein Ein Ein Ein Ein Ein Ein Ein Ein Ein Ein Ein Ein Ein Ein Ein Ein Ein Ein Ein Ein Ein Ein Ein Ein Ein Ein Ein Ein Ein Ein Ein Ein Ein Ein Ein Ein Ein Ein Ein Ein Ein'"
            ]
          },
          "execution_count": 29,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "translate(transformer, \" Attempt easy tasks as if they were difficult, and difficult as if they were easy; in the one case that confidence may not fall asleep, in the other that it may not be dismayed.\", en_vocab, de_vocab, en_tokenizer)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "translation_transformer_ipynb의_사본.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
